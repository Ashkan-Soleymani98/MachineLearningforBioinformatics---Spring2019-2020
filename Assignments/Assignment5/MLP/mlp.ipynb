{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = torch.tensor(iris.data).float()\n",
    "y = torch.tensor(iris.target).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([150, 4]), torch.Size([150]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "#### Complete the MLP.py, and then import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a68e31b76346b887a50466d74a6a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss: tensor(1.3734) acc: 0.3333333333333333\n",
      "2 loss: tensor(1.3726) acc: 0.3333333333333333\n",
      "3 loss: tensor(1.3719) acc: 0.3333333333333333\n",
      "4 loss: tensor(1.3711) acc: 0.3333333333333333\n",
      "5 loss: tensor(1.3704) acc: 0.3333333333333333\n",
      "6 loss: tensor(1.3696) acc: 0.3333333333333333\n",
      "7 loss: tensor(1.3689) acc: 0.3333333333333333\n",
      "8 loss: tensor(1.3682) acc: 0.3333333333333333\n",
      "9 loss: tensor(1.3675) acc: 0.3333333333333333\n",
      "10 loss: tensor(1.3667) acc: 0.3333333333333333\n",
      "11 loss: tensor(1.3660) acc: 0.3333333333333333\n",
      "12 loss: tensor(1.3653) acc: 0.3333333333333333\n",
      "13 loss: tensor(1.3646) acc: 0.3333333333333333\n",
      "14 loss: tensor(1.3639) acc: 0.3333333333333333\n",
      "15 loss: tensor(1.3632) acc: 0.3333333333333333\n",
      "16 loss: tensor(1.3625) acc: 0.3333333333333333\n",
      "17 loss: tensor(1.3618) acc: 0.3333333333333333\n",
      "18 loss: tensor(1.3612) acc: 0.3333333333333333\n",
      "19 loss: tensor(1.3605) acc: 0.3333333333333333\n",
      "20 loss: tensor(1.3598) acc: 0.3333333333333333\n",
      "21 loss: tensor(1.3591) acc: 0.3333333333333333\n",
      "22 loss: tensor(1.3585) acc: 0.3333333333333333\n",
      "23 loss: tensor(1.3578) acc: 0.3333333333333333\n",
      "24 loss: tensor(1.3572) acc: 0.3333333333333333\n",
      "25 loss: tensor(1.3565) acc: 0.3333333333333333\n",
      "26 loss: tensor(1.3559) acc: 0.3333333333333333\n",
      "27 loss: tensor(1.3552) acc: 0.3333333333333333\n",
      "28 loss: tensor(1.3546) acc: 0.3333333333333333\n",
      "29 loss: tensor(1.3540) acc: 0.3333333333333333\n",
      "30 loss: tensor(1.3533) acc: 0.3333333333333333\n",
      "31 loss: tensor(1.3527) acc: 0.3333333333333333\n",
      "32 loss: tensor(1.3521) acc: 0.3333333333333333\n",
      "33 loss: tensor(1.3515) acc: 0.3333333333333333\n",
      "34 loss: tensor(1.3509) acc: 0.3333333333333333\n",
      "35 loss: tensor(1.3503) acc: 0.3333333333333333\n",
      "36 loss: tensor(1.3497) acc: 0.3333333333333333\n",
      "37 loss: tensor(1.3491) acc: 0.3333333333333333\n",
      "38 loss: tensor(1.3485) acc: 0.3333333333333333\n",
      "39 loss: tensor(1.3479) acc: 0.3333333333333333\n",
      "40 loss: tensor(1.3474) acc: 0.3333333333333333\n",
      "41 loss: tensor(1.3468) acc: 0.3333333333333333\n",
      "42 loss: tensor(1.3462) acc: 0.3333333333333333\n",
      "43 loss: tensor(1.3457) acc: 0.3333333333333333\n",
      "44 loss: tensor(1.3451) acc: 0.3333333333333333\n",
      "45 loss: tensor(1.3445) acc: 0.3333333333333333\n",
      "46 loss: tensor(1.3440) acc: 0.3333333333333333\n",
      "47 loss: tensor(1.3434) acc: 0.3333333333333333\n",
      "48 loss: tensor(1.3429) acc: 0.3333333333333333\n",
      "49 loss: tensor(1.3424) acc: 0.3333333333333333\n",
      "50 loss: tensor(1.3418) acc: 0.3333333333333333\n",
      "51 loss: tensor(1.3413) acc: 0.3333333333333333\n",
      "52 loss: tensor(1.3408) acc: 0.3333333333333333\n",
      "53 loss: tensor(1.3403) acc: 0.3333333333333333\n",
      "54 loss: tensor(1.3398) acc: 0.3333333333333333\n",
      "55 loss: tensor(1.3393) acc: 0.3333333333333333\n",
      "56 loss: tensor(1.3388) acc: 0.3333333333333333\n",
      "57 loss: tensor(1.3383) acc: 0.3333333333333333\n",
      "58 loss: tensor(1.3378) acc: 0.3333333333333333\n",
      "59 loss: tensor(1.3373) acc: 0.3333333333333333\n",
      "60 loss: tensor(1.3368) acc: 0.3333333333333333\n",
      "61 loss: tensor(1.3363) acc: 0.3333333333333333\n",
      "62 loss: tensor(1.3359) acc: 0.3333333333333333\n",
      "63 loss: tensor(1.3354) acc: 0.3333333333333333\n",
      "64 loss: tensor(1.3349) acc: 0.3333333333333333\n",
      "65 loss: tensor(1.3345) acc: 0.3333333333333333\n",
      "66 loss: tensor(1.3340) acc: 0.3333333333333333\n",
      "67 loss: tensor(1.3336) acc: 0.3333333333333333\n",
      "68 loss: tensor(1.3331) acc: 0.3333333333333333\n",
      "69 loss: tensor(1.3327) acc: 0.3333333333333333\n",
      "70 loss: tensor(1.3323) acc: 0.3333333333333333\n",
      "71 loss: tensor(1.3318) acc: 0.3333333333333333\n",
      "72 loss: tensor(1.3314) acc: 0.3333333333333333\n",
      "73 loss: tensor(1.3310) acc: 0.3333333333333333\n",
      "74 loss: tensor(1.3306) acc: 0.3333333333333333\n",
      "75 loss: tensor(1.3301) acc: 0.3333333333333333\n",
      "76 loss: tensor(1.3297) acc: 0.3333333333333333\n",
      "77 loss: tensor(1.3293) acc: 0.3333333333333333\n",
      "78 loss: tensor(1.3289) acc: 0.3333333333333333\n",
      "79 loss: tensor(1.3285) acc: 0.3333333333333333\n",
      "80 loss: tensor(1.3282) acc: 0.3333333333333333\n",
      "81 loss: tensor(1.3278) acc: 0.3333333333333333\n",
      "82 loss: tensor(1.3274) acc: 0.3333333333333333\n",
      "83 loss: tensor(1.3270) acc: 0.3333333333333333\n",
      "84 loss: tensor(1.3266) acc: 0.3333333333333333\n",
      "85 loss: tensor(1.3263) acc: 0.3333333333333333\n",
      "86 loss: tensor(1.3259) acc: 0.3333333333333333\n",
      "87 loss: tensor(1.3256) acc: 0.3333333333333333\n",
      "88 loss: tensor(1.3252) acc: 0.3333333333333333\n",
      "89 loss: tensor(1.3248) acc: 0.3333333333333333\n",
      "90 loss: tensor(1.3245) acc: 0.3333333333333333\n",
      "91 loss: tensor(1.3242) acc: 0.3333333333333333\n",
      "92 loss: tensor(1.3238) acc: 0.3333333333333333\n",
      "93 loss: tensor(1.3235) acc: 0.3333333333333333\n",
      "94 loss: tensor(1.3232) acc: 0.3333333333333333\n",
      "95 loss: tensor(1.3228) acc: 0.3333333333333333\n",
      "96 loss: tensor(1.3225) acc: 0.3333333333333333\n",
      "97 loss: tensor(1.3222) acc: 0.3333333333333333\n",
      "98 loss: tensor(1.3219) acc: 0.3333333333333333\n",
      "99 loss: tensor(1.3216) acc: 0.3333333333333333\n",
      "100 loss: tensor(1.3213) acc: 0.3333333333333333\n",
      "101 loss: tensor(1.3210) acc: 0.3333333333333333\n",
      "102 loss: tensor(1.3207) acc: 0.3333333333333333\n",
      "103 loss: tensor(1.3204) acc: 0.3333333333333333\n",
      "104 loss: tensor(1.3201) acc: 0.3333333333333333\n",
      "105 loss: tensor(1.3198) acc: 0.3333333333333333\n",
      "106 loss: tensor(1.3195) acc: 0.3333333333333333\n",
      "107 loss: tensor(1.3192) acc: 0.3333333333333333\n",
      "108 loss: tensor(1.3190) acc: 0.3333333333333333\n",
      "109 loss: tensor(1.3187) acc: 0.3333333333333333\n",
      "110 loss: tensor(1.3184) acc: 0.3333333333333333\n",
      "111 loss: tensor(1.3182) acc: 0.3333333333333333\n",
      "112 loss: tensor(1.3179) acc: 0.3333333333333333\n",
      "113 loss: tensor(1.3176) acc: 0.3333333333333333\n",
      "114 loss: tensor(1.3174) acc: 0.3333333333333333\n",
      "115 loss: tensor(1.3171) acc: 0.3333333333333333\n",
      "116 loss: tensor(1.3169) acc: 0.3333333333333333\n",
      "117 loss: tensor(1.3167) acc: 0.3333333333333333\n",
      "118 loss: tensor(1.3164) acc: 0.3333333333333333\n",
      "119 loss: tensor(1.3162) acc: 0.3333333333333333\n",
      "120 loss: tensor(1.3159) acc: 0.3333333333333333\n",
      "121 loss: tensor(1.3157) acc: 0.3333333333333333\n",
      "122 loss: tensor(1.3155) acc: 0.3333333333333333\n",
      "123 loss: tensor(1.3153) acc: 0.3333333333333333\n",
      "124 loss: tensor(1.3150) acc: 0.3333333333333333\n",
      "125 loss: tensor(1.3148) acc: 0.3333333333333333\n",
      "126 loss: tensor(1.3146) acc: 0.3333333333333333\n",
      "127 loss: tensor(1.3144) acc: 0.3333333333333333\n",
      "128 loss: tensor(1.3142) acc: 0.3333333333333333\n",
      "129 loss: tensor(1.3140) acc: 0.3333333333333333\n",
      "130 loss: tensor(1.3138) acc: 0.3333333333333333\n",
      "131 loss: tensor(1.3136) acc: 0.3333333333333333\n",
      "132 loss: tensor(1.3134) acc: 0.3333333333333333\n",
      "133 loss: tensor(1.3132) acc: 0.3333333333333333\n",
      "134 loss: tensor(1.3130) acc: 0.3333333333333333\n",
      "135 loss: tensor(1.3128) acc: 0.3333333333333333\n",
      "136 loss: tensor(1.3126) acc: 0.3333333333333333\n",
      "137 loss: tensor(1.3124) acc: 0.3333333333333333\n",
      "138 loss: tensor(1.3122) acc: 0.3333333333333333\n",
      "139 loss: tensor(1.3120) acc: 0.3333333333333333\n",
      "140 loss: tensor(1.3119) acc: 0.3333333333333333\n",
      "141 loss: tensor(1.3117) acc: 0.3333333333333333\n",
      "142 loss: tensor(1.3115) acc: 0.3333333333333333\n",
      "143 loss: tensor(1.3113) acc: 0.3333333333333333\n",
      "144 loss: tensor(1.3112) acc: 0.3333333333333333\n",
      "145 loss: tensor(1.3110) acc: 0.3333333333333333\n",
      "146 loss: tensor(1.3108) acc: 0.3333333333333333\n",
      "147 loss: tensor(1.3107) acc: 0.3333333333333333\n",
      "148 loss: tensor(1.3105) acc: 0.3333333333333333\n",
      "149 loss: tensor(1.3103) acc: 0.3333333333333333\n",
      "150 loss: tensor(1.3102) acc: 0.3333333333333333\n",
      "151 loss: tensor(1.3100) acc: 0.3333333333333333\n",
      "152 loss: tensor(1.3099) acc: 0.3333333333333333\n",
      "153 loss: tensor(1.3097) acc: 0.3333333333333333\n",
      "154 loss: tensor(1.3096) acc: 0.3333333333333333\n",
      "155 loss: tensor(1.3094) acc: 0.3333333333333333\n",
      "156 loss: tensor(1.3093) acc: 0.3333333333333333\n",
      "157 loss: tensor(1.3091) acc: 0.3333333333333333\n",
      "158 loss: tensor(1.3090) acc: 0.3333333333333333\n",
      "159 loss: tensor(1.3089) acc: 0.3333333333333333\n",
      "160 loss: tensor(1.3087) acc: 0.3333333333333333\n",
      "161 loss: tensor(1.3086) acc: 0.3333333333333333\n",
      "162 loss: tensor(1.3084) acc: 0.3333333333333333\n",
      "163 loss: tensor(1.3083) acc: 0.3333333333333333\n",
      "164 loss: tensor(1.3082) acc: 0.3333333333333333\n",
      "165 loss: tensor(1.3080) acc: 0.3333333333333333\n",
      "166 loss: tensor(1.3079) acc: 0.3333333333333333\n",
      "167 loss: tensor(1.3078) acc: 0.3333333333333333\n",
      "168 loss: tensor(1.3076) acc: 0.3333333333333333\n",
      "169 loss: tensor(1.3075) acc: 0.3333333333333333\n",
      "170 loss: tensor(1.3074) acc: 0.3333333333333333\n",
      "171 loss: tensor(1.3073) acc: 0.3333333333333333\n",
      "172 loss: tensor(1.3071) acc: 0.3333333333333333\n",
      "173 loss: tensor(1.3070) acc: 0.3333333333333333\n",
      "174 loss: tensor(1.3069) acc: 0.3333333333333333\n",
      "175 loss: tensor(1.3068) acc: 0.3333333333333333\n",
      "176 loss: tensor(1.3066) acc: 0.3333333333333333\n",
      "177 loss: tensor(1.3065) acc: 0.3333333333333333\n",
      "178 loss: tensor(1.3064) acc: 0.3333333333333333\n",
      "179 loss: tensor(1.3063) acc: 0.3333333333333333\n",
      "180 loss: tensor(1.3062) acc: 0.3333333333333333\n",
      "181 loss: tensor(1.3061) acc: 0.3333333333333333\n",
      "182 loss: tensor(1.3059) acc: 0.3333333333333333\n",
      "183 loss: tensor(1.3058) acc: 0.3333333333333333\n",
      "184 loss: tensor(1.3057) acc: 0.3333333333333333\n",
      "185 loss: tensor(1.3056) acc: 0.3333333333333333\n",
      "186 loss: tensor(1.3055) acc: 0.3333333333333333\n",
      "187 loss: tensor(1.3054) acc: 0.3333333333333333\n",
      "188 loss: tensor(1.3053) acc: 0.3333333333333333\n",
      "189 loss: tensor(1.3052) acc: 0.3333333333333333\n",
      "190 loss: tensor(1.3050) acc: 0.3333333333333333\n",
      "191 loss: tensor(1.3049) acc: 0.3333333333333333\n",
      "192 loss: tensor(1.3048) acc: 0.3333333333333333\n",
      "193 loss: tensor(1.3047) acc: 0.3333333333333333\n",
      "194 loss: tensor(1.3046) acc: 0.3333333333333333\n",
      "195 loss: tensor(1.3045) acc: 0.3333333333333333\n",
      "196 loss: tensor(1.3044) acc: 0.3333333333333333\n",
      "197 loss: tensor(1.3043) acc: 0.3333333333333333\n",
      "198 loss: tensor(1.3042) acc: 0.3333333333333333\n",
      "199 loss: tensor(1.3041) acc: 0.3333333333333333\n",
      "200 loss: tensor(1.3040) acc: 0.3333333333333333\n",
      "201 loss: tensor(1.3039) acc: 0.3333333333333333\n",
      "202 loss: tensor(1.3038) acc: 0.3333333333333333\n",
      "203 loss: tensor(1.3037) acc: 0.3333333333333333\n",
      "204 loss: tensor(1.3035) acc: 0.3333333333333333\n",
      "205 loss: tensor(1.3034) acc: 0.3333333333333333\n",
      "206 loss: tensor(1.3033) acc: 0.3333333333333333\n",
      "207 loss: tensor(1.3032) acc: 0.3333333333333333\n",
      "208 loss: tensor(1.3031) acc: 0.3333333333333333\n",
      "209 loss: tensor(1.3030) acc: 0.3333333333333333\n",
      "210 loss: tensor(1.3029) acc: 0.3333333333333333\n",
      "211 loss: tensor(1.3028) acc: 0.3333333333333333\n",
      "212 loss: tensor(1.3027) acc: 0.3333333333333333\n",
      "213 loss: tensor(1.3026) acc: 0.3333333333333333\n",
      "214 loss: tensor(1.3025) acc: 0.3333333333333333\n",
      "215 loss: tensor(1.3024) acc: 0.3333333333333333\n",
      "216 loss: tensor(1.3023) acc: 0.3333333333333333\n",
      "217 loss: tensor(1.3022) acc: 0.3333333333333333\n",
      "218 loss: tensor(1.3021) acc: 0.3333333333333333\n",
      "219 loss: tensor(1.3020) acc: 0.3333333333333333\n",
      "220 loss: tensor(1.3019) acc: 0.3333333333333333\n",
      "221 loss: tensor(1.3018) acc: 0.3333333333333333\n",
      "222 loss: tensor(1.3017) acc: 0.3333333333333333\n",
      "223 loss: tensor(1.3016) acc: 0.3333333333333333\n",
      "224 loss: tensor(1.3015) acc: 0.3333333333333333\n",
      "225 loss: tensor(1.3014) acc: 0.3333333333333333\n",
      "226 loss: tensor(1.3013) acc: 0.3333333333333333\n",
      "227 loss: tensor(1.3012) acc: 0.3333333333333333\n",
      "228 loss: tensor(1.3011) acc: 0.3333333333333333\n",
      "229 loss: tensor(1.3010) acc: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 loss: tensor(1.3009) acc: 0.3333333333333333\n",
      "231 loss: tensor(1.3008) acc: 0.3333333333333333\n",
      "232 loss: tensor(1.3007) acc: 0.3333333333333333\n",
      "233 loss: tensor(1.3005) acc: 0.3333333333333333\n",
      "234 loss: tensor(1.3004) acc: 0.3333333333333333\n",
      "235 loss: tensor(1.3003) acc: 0.3333333333333333\n",
      "236 loss: tensor(1.3002) acc: 0.3333333333333333\n",
      "237 loss: tensor(1.3001) acc: 0.3333333333333333\n",
      "238 loss: tensor(1.3000) acc: 0.3333333333333333\n",
      "239 loss: tensor(1.2999) acc: 0.3333333333333333\n",
      "240 loss: tensor(1.2998) acc: 0.3333333333333333\n",
      "241 loss: tensor(1.2997) acc: 0.3333333333333333\n",
      "242 loss: tensor(1.2996) acc: 0.3333333333333333\n",
      "243 loss: tensor(1.2995) acc: 0.3333333333333333\n",
      "244 loss: tensor(1.2994) acc: 0.3333333333333333\n",
      "245 loss: tensor(1.2993) acc: 0.3333333333333333\n",
      "246 loss: tensor(1.2992) acc: 0.3333333333333333\n",
      "247 loss: tensor(1.2991) acc: 0.3333333333333333\n",
      "248 loss: tensor(1.2990) acc: 0.3333333333333333\n",
      "249 loss: tensor(1.2988) acc: 0.3333333333333333\n",
      "250 loss: tensor(1.2987) acc: 0.3333333333333333\n",
      "251 loss: tensor(1.2986) acc: 0.3333333333333333\n",
      "252 loss: tensor(1.2985) acc: 0.3333333333333333\n",
      "253 loss: tensor(1.2984) acc: 0.3333333333333333\n",
      "254 loss: tensor(1.2983) acc: 0.3333333333333333\n",
      "255 loss: tensor(1.2982) acc: 0.3333333333333333\n",
      "256 loss: tensor(1.2981) acc: 0.3333333333333333\n",
      "257 loss: tensor(1.2980) acc: 0.3333333333333333\n",
      "258 loss: tensor(1.2978) acc: 0.3333333333333333\n",
      "259 loss: tensor(1.2977) acc: 0.3333333333333333\n",
      "260 loss: tensor(1.2976) acc: 0.3333333333333333\n",
      "261 loss: tensor(1.2975) acc: 0.3333333333333333\n",
      "262 loss: tensor(1.2974) acc: 0.3333333333333333\n",
      "263 loss: tensor(1.2973) acc: 0.3333333333333333\n",
      "264 loss: tensor(1.2972) acc: 0.3333333333333333\n",
      "265 loss: tensor(1.2971) acc: 0.3333333333333333\n",
      "266 loss: tensor(1.2969) acc: 0.3333333333333333\n",
      "267 loss: tensor(1.2968) acc: 0.3333333333333333\n",
      "268 loss: tensor(1.2967) acc: 0.3333333333333333\n",
      "269 loss: tensor(1.2966) acc: 0.3333333333333333\n",
      "270 loss: tensor(1.2965) acc: 0.3333333333333333\n",
      "271 loss: tensor(1.2964) acc: 0.3333333333333333\n",
      "272 loss: tensor(1.2962) acc: 0.3333333333333333\n",
      "273 loss: tensor(1.2961) acc: 0.3333333333333333\n",
      "274 loss: tensor(1.2960) acc: 0.3333333333333333\n",
      "275 loss: tensor(1.2959) acc: 0.3333333333333333\n",
      "276 loss: tensor(1.2958) acc: 0.3333333333333333\n",
      "277 loss: tensor(1.2956) acc: 0.3333333333333333\n",
      "278 loss: tensor(1.2955) acc: 0.3333333333333333\n",
      "279 loss: tensor(1.2954) acc: 0.3333333333333333\n",
      "280 loss: tensor(1.2953) acc: 0.3333333333333333\n",
      "281 loss: tensor(1.2952) acc: 0.3333333333333333\n",
      "282 loss: tensor(1.2950) acc: 0.3333333333333333\n",
      "283 loss: tensor(1.2949) acc: 0.3333333333333333\n",
      "284 loss: tensor(1.2948) acc: 0.3333333333333333\n",
      "285 loss: tensor(1.2947) acc: 0.3333333333333333\n",
      "286 loss: tensor(1.2946) acc: 0.3333333333333333\n",
      "287 loss: tensor(1.2944) acc: 0.3333333333333333\n",
      "288 loss: tensor(1.2943) acc: 0.3333333333333333\n",
      "289 loss: tensor(1.2942) acc: 0.3333333333333333\n",
      "290 loss: tensor(1.2941) acc: 0.3333333333333333\n",
      "291 loss: tensor(1.2939) acc: 0.3333333333333333\n",
      "292 loss: tensor(1.2938) acc: 0.3333333333333333\n",
      "293 loss: tensor(1.2937) acc: 0.3333333333333333\n",
      "294 loss: tensor(1.2935) acc: 0.3333333333333333\n",
      "295 loss: tensor(1.2934) acc: 0.3333333333333333\n",
      "296 loss: tensor(1.2933) acc: 0.3333333333333333\n",
      "297 loss: tensor(1.2932) acc: 0.3333333333333333\n",
      "298 loss: tensor(1.2930) acc: 0.3333333333333333\n",
      "299 loss: tensor(1.2929) acc: 0.3333333333333333\n",
      "300 loss: tensor(1.2928) acc: 0.3333333333333333\n",
      "301 loss: tensor(1.2927) acc: 0.3333333333333333\n",
      "302 loss: tensor(1.2925) acc: 0.3333333333333333\n",
      "303 loss: tensor(1.2924) acc: 0.3333333333333333\n",
      "304 loss: tensor(1.2923) acc: 0.3333333333333333\n",
      "305 loss: tensor(1.2921) acc: 0.3333333333333333\n",
      "306 loss: tensor(1.2920) acc: 0.3333333333333333\n",
      "307 loss: tensor(1.2919) acc: 0.3333333333333333\n",
      "308 loss: tensor(1.2917) acc: 0.3333333333333333\n",
      "309 loss: tensor(1.2916) acc: 0.3333333333333333\n",
      "310 loss: tensor(1.2915) acc: 0.3333333333333333\n",
      "311 loss: tensor(1.2913) acc: 0.3333333333333333\n",
      "312 loss: tensor(1.2912) acc: 0.3333333333333333\n",
      "313 loss: tensor(1.2911) acc: 0.3333333333333333\n",
      "314 loss: tensor(1.2909) acc: 0.3333333333333333\n",
      "315 loss: tensor(1.2908) acc: 0.3333333333333333\n",
      "316 loss: tensor(1.2907) acc: 0.3333333333333333\n",
      "317 loss: tensor(1.2905) acc: 0.3333333333333333\n",
      "318 loss: tensor(1.2904) acc: 0.3333333333333333\n",
      "319 loss: tensor(1.2903) acc: 0.3333333333333333\n",
      "320 loss: tensor(1.2901) acc: 0.3333333333333333\n",
      "321 loss: tensor(1.2900) acc: 0.3333333333333333\n",
      "322 loss: tensor(1.2898) acc: 0.3333333333333333\n",
      "323 loss: tensor(1.2897) acc: 0.3333333333333333\n",
      "324 loss: tensor(1.2896) acc: 0.3333333333333333\n",
      "325 loss: tensor(1.2894) acc: 0.3333333333333333\n",
      "326 loss: tensor(1.2893) acc: 0.3333333333333333\n",
      "327 loss: tensor(1.2891) acc: 0.3333333333333333\n",
      "328 loss: tensor(1.2890) acc: 0.3333333333333333\n",
      "329 loss: tensor(1.2889) acc: 0.3333333333333333\n",
      "330 loss: tensor(1.2887) acc: 0.3333333333333333\n",
      "331 loss: tensor(1.2886) acc: 0.3333333333333333\n",
      "332 loss: tensor(1.2884) acc: 0.3333333333333333\n",
      "333 loss: tensor(1.2883) acc: 0.3333333333333333\n",
      "334 loss: tensor(1.2882) acc: 0.3333333333333333\n",
      "335 loss: tensor(1.2880) acc: 0.3333333333333333\n",
      "336 loss: tensor(1.2879) acc: 0.3333333333333333\n",
      "337 loss: tensor(1.2877) acc: 0.3333333333333333\n",
      "338 loss: tensor(1.2876) acc: 0.3333333333333333\n",
      "339 loss: tensor(1.2874) acc: 0.3333333333333333\n",
      "340 loss: tensor(1.2873) acc: 0.3333333333333333\n",
      "341 loss: tensor(1.2872) acc: 0.3333333333333333\n",
      "342 loss: tensor(1.2870) acc: 0.3333333333333333\n",
      "343 loss: tensor(1.2869) acc: 0.3333333333333333\n",
      "344 loss: tensor(1.2867) acc: 0.3333333333333333\n",
      "345 loss: tensor(1.2866) acc: 0.3333333333333333\n",
      "346 loss: tensor(1.2864) acc: 0.3333333333333333\n",
      "347 loss: tensor(1.2863) acc: 0.3333333333333333\n",
      "348 loss: tensor(1.2861) acc: 0.3333333333333333\n",
      "349 loss: tensor(1.2860) acc: 0.3333333333333333\n",
      "350 loss: tensor(1.2858) acc: 0.3333333333333333\n",
      "351 loss: tensor(1.2857) acc: 0.3333333333333333\n",
      "352 loss: tensor(1.2855) acc: 0.3333333333333333\n",
      "353 loss: tensor(1.2854) acc: 0.3333333333333333\n",
      "354 loss: tensor(1.2853) acc: 0.3333333333333333\n",
      "355 loss: tensor(1.2851) acc: 0.3333333333333333\n",
      "356 loss: tensor(1.2850) acc: 0.3333333333333333\n",
      "357 loss: tensor(1.2848) acc: 0.3333333333333333\n",
      "358 loss: tensor(1.2847) acc: 0.3333333333333333\n",
      "359 loss: tensor(1.2845) acc: 0.3333333333333333\n",
      "360 loss: tensor(1.2844) acc: 0.3333333333333333\n",
      "361 loss: tensor(1.2842) acc: 0.3333333333333333\n",
      "362 loss: tensor(1.2841) acc: 0.3333333333333333\n",
      "363 loss: tensor(1.2839) acc: 0.3333333333333333\n",
      "364 loss: tensor(1.2838) acc: 0.3333333333333333\n",
      "365 loss: tensor(1.2836) acc: 0.3333333333333333\n",
      "366 loss: tensor(1.2834) acc: 0.3333333333333333\n",
      "367 loss: tensor(1.2833) acc: 0.3333333333333333\n",
      "368 loss: tensor(1.2831) acc: 0.3333333333333333\n",
      "369 loss: tensor(1.2830) acc: 0.3333333333333333\n",
      "370 loss: tensor(1.2828) acc: 0.3333333333333333\n",
      "371 loss: tensor(1.2827) acc: 0.3333333333333333\n",
      "372 loss: tensor(1.2825) acc: 0.3333333333333333\n",
      "373 loss: tensor(1.2824) acc: 0.3333333333333333\n",
      "374 loss: tensor(1.2822) acc: 0.3333333333333333\n",
      "375 loss: tensor(1.2821) acc: 0.3333333333333333\n",
      "376 loss: tensor(1.2819) acc: 0.3333333333333333\n",
      "377 loss: tensor(1.2818) acc: 0.3333333333333333\n",
      "378 loss: tensor(1.2816) acc: 0.3333333333333333\n",
      "379 loss: tensor(1.2815) acc: 0.3333333333333333\n",
      "380 loss: tensor(1.2813) acc: 0.3333333333333333\n",
      "381 loss: tensor(1.2811) acc: 0.3333333333333333\n",
      "382 loss: tensor(1.2810) acc: 0.3333333333333333\n",
      "383 loss: tensor(1.2808) acc: 0.3333333333333333\n",
      "384 loss: tensor(1.2807) acc: 0.3333333333333333\n",
      "385 loss: tensor(1.2805) acc: 0.3333333333333333\n",
      "386 loss: tensor(1.2804) acc: 0.3333333333333333\n",
      "387 loss: tensor(1.2802) acc: 0.3333333333333333\n",
      "388 loss: tensor(1.2801) acc: 0.3333333333333333\n",
      "389 loss: tensor(1.2799) acc: 0.3333333333333333\n",
      "390 loss: tensor(1.2797) acc: 0.3333333333333333\n",
      "391 loss: tensor(1.2796) acc: 0.3333333333333333\n",
      "392 loss: tensor(1.2794) acc: 0.3333333333333333\n",
      "393 loss: tensor(1.2793) acc: 0.3333333333333333\n",
      "394 loss: tensor(1.2791) acc: 0.3333333333333333\n",
      "395 loss: tensor(1.2790) acc: 0.3333333333333333\n",
      "396 loss: tensor(1.2788) acc: 0.3333333333333333\n",
      "397 loss: tensor(1.2786) acc: 0.3333333333333333\n",
      "398 loss: tensor(1.2785) acc: 0.3333333333333333\n",
      "399 loss: tensor(1.2783) acc: 0.3333333333333333\n",
      "400 loss: tensor(1.2782) acc: 0.3333333333333333\n",
      "401 loss: tensor(1.2780) acc: 0.3333333333333333\n",
      "402 loss: tensor(1.2778) acc: 0.3333333333333333\n",
      "403 loss: tensor(1.2777) acc: 0.3333333333333333\n",
      "404 loss: tensor(1.2775) acc: 0.3333333333333333\n",
      "405 loss: tensor(1.2774) acc: 0.3333333333333333\n",
      "406 loss: tensor(1.2772) acc: 0.3333333333333333\n",
      "407 loss: tensor(1.2770) acc: 0.3333333333333333\n",
      "408 loss: tensor(1.2769) acc: 0.3333333333333333\n",
      "409 loss: tensor(1.2767) acc: 0.3333333333333333\n",
      "410 loss: tensor(1.2766) acc: 0.3333333333333333\n",
      "411 loss: tensor(1.2764) acc: 0.3333333333333333\n",
      "412 loss: tensor(1.2762) acc: 0.3333333333333333\n",
      "413 loss: tensor(1.2761) acc: 0.3333333333333333\n",
      "414 loss: tensor(1.2759) acc: 0.3333333333333333\n",
      "415 loss: tensor(1.2758) acc: 0.3333333333333333\n",
      "416 loss: tensor(1.2756) acc: 0.3333333333333333\n",
      "417 loss: tensor(1.2754) acc: 0.3333333333333333\n",
      "418 loss: tensor(1.2753) acc: 0.3333333333333333\n",
      "419 loss: tensor(1.2751) acc: 0.3333333333333333\n",
      "420 loss: tensor(1.2749) acc: 0.3333333333333333\n",
      "421 loss: tensor(1.2748) acc: 0.3333333333333333\n",
      "422 loss: tensor(1.2746) acc: 0.3333333333333333\n",
      "423 loss: tensor(1.2745) acc: 0.3333333333333333\n",
      "424 loss: tensor(1.2743) acc: 0.3333333333333333\n",
      "425 loss: tensor(1.2741) acc: 0.3333333333333333\n",
      "426 loss: tensor(1.2740) acc: 0.3333333333333333\n",
      "427 loss: tensor(1.2738) acc: 0.3333333333333333\n",
      "428 loss: tensor(1.2736) acc: 0.3333333333333333\n",
      "429 loss: tensor(1.2735) acc: 0.3333333333333333\n",
      "430 loss: tensor(1.2733) acc: 0.3333333333333333\n",
      "431 loss: tensor(1.2732) acc: 0.3333333333333333\n",
      "432 loss: tensor(1.2730) acc: 0.3333333333333333\n",
      "433 loss: tensor(1.2728) acc: 0.3333333333333333\n",
      "434 loss: tensor(1.2727) acc: 0.3333333333333333\n",
      "435 loss: tensor(1.2725) acc: 0.3333333333333333\n",
      "436 loss: tensor(1.2723) acc: 0.3333333333333333\n",
      "437 loss: tensor(1.2722) acc: 0.3333333333333333\n",
      "438 loss: tensor(1.2720) acc: 0.3333333333333333\n",
      "439 loss: tensor(1.2718) acc: 0.3333333333333333\n",
      "440 loss: tensor(1.2717) acc: 0.3333333333333333\n",
      "441 loss: tensor(1.2715) acc: 0.3333333333333333\n",
      "442 loss: tensor(1.2714) acc: 0.3333333333333333\n",
      "443 loss: tensor(1.2712) acc: 0.3333333333333333\n",
      "444 loss: tensor(1.2710) acc: 0.3333333333333333\n",
      "445 loss: tensor(1.2709) acc: 0.3333333333333333\n",
      "446 loss: tensor(1.2707) acc: 0.3333333333333333\n",
      "447 loss: tensor(1.2705) acc: 0.3333333333333333\n",
      "448 loss: tensor(1.2704) acc: 0.3333333333333333\n",
      "449 loss: tensor(1.2702) acc: 0.3333333333333333\n",
      "450 loss: tensor(1.2700) acc: 0.3333333333333333\n",
      "451 loss: tensor(1.2699) acc: 0.3333333333333333\n",
      "452 loss: tensor(1.2697) acc: 0.3333333333333333\n",
      "453 loss: tensor(1.2695) acc: 0.3333333333333333\n",
      "454 loss: tensor(1.2694) acc: 0.3333333333333333\n",
      "455 loss: tensor(1.2692) acc: 0.3333333333333333\n",
      "456 loss: tensor(1.2690) acc: 0.3333333333333333\n",
      "457 loss: tensor(1.2689) acc: 0.3333333333333333\n",
      "458 loss: tensor(1.2687) acc: 0.3333333333333333\n",
      "459 loss: tensor(1.2685) acc: 0.3333333333333333\n",
      "460 loss: tensor(1.2684) acc: 0.3333333333333333\n",
      "461 loss: tensor(1.2682) acc: 0.3333333333333333\n",
      "462 loss: tensor(1.2680) acc: 0.3333333333333333\n",
      "463 loss: tensor(1.2679) acc: 0.3333333333333333\n",
      "464 loss: tensor(1.2677) acc: 0.3333333333333333\n",
      "465 loss: tensor(1.2675) acc: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 loss: tensor(1.2674) acc: 0.3333333333333333\n",
      "467 loss: tensor(1.2672) acc: 0.3333333333333333\n",
      "468 loss: tensor(1.2671) acc: 0.3333333333333333\n",
      "469 loss: tensor(1.2669) acc: 0.3333333333333333\n",
      "470 loss: tensor(1.2667) acc: 0.3333333333333333\n",
      "471 loss: tensor(1.2666) acc: 0.3333333333333333\n",
      "472 loss: tensor(1.2664) acc: 0.3333333333333333\n",
      "473 loss: tensor(1.2662) acc: 0.3333333333333333\n",
      "474 loss: tensor(1.2661) acc: 0.3333333333333333\n",
      "475 loss: tensor(1.2659) acc: 0.3333333333333333\n",
      "476 loss: tensor(1.2657) acc: 0.3333333333333333\n",
      "477 loss: tensor(1.2656) acc: 0.3333333333333333\n",
      "478 loss: tensor(1.2654) acc: 0.3333333333333333\n",
      "479 loss: tensor(1.2652) acc: 0.3333333333333333\n",
      "480 loss: tensor(1.2651) acc: 0.3333333333333333\n",
      "481 loss: tensor(1.2649) acc: 0.3333333333333333\n",
      "482 loss: tensor(1.2647) acc: 0.3333333333333333\n",
      "483 loss: tensor(1.2646) acc: 0.3333333333333333\n",
      "484 loss: tensor(1.2644) acc: 0.3333333333333333\n",
      "485 loss: tensor(1.2642) acc: 0.3333333333333333\n",
      "486 loss: tensor(1.2641) acc: 0.3333333333333333\n",
      "487 loss: tensor(1.2639) acc: 0.3333333333333333\n",
      "488 loss: tensor(1.2637) acc: 0.3333333333333333\n",
      "489 loss: tensor(1.2636) acc: 0.3333333333333333\n",
      "490 loss: tensor(1.2634) acc: 0.3333333333333333\n",
      "491 loss: tensor(1.2632) acc: 0.3333333333333333\n",
      "492 loss: tensor(1.2631) acc: 0.3333333333333333\n",
      "493 loss: tensor(1.2629) acc: 0.3333333333333333\n",
      "494 loss: tensor(1.2627) acc: 0.3333333333333333\n",
      "495 loss: tensor(1.2625) acc: 0.3333333333333333\n",
      "496 loss: tensor(1.2624) acc: 0.3333333333333333\n",
      "497 loss: tensor(1.2622) acc: 0.3333333333333333\n",
      "498 loss: tensor(1.2620) acc: 0.3333333333333333\n",
      "499 loss: tensor(1.2619) acc: 0.3333333333333333\n",
      "500 loss: tensor(1.2617) acc: 0.3333333333333333\n",
      "501 loss: tensor(1.2615) acc: 0.3333333333333333\n",
      "502 loss: tensor(1.2614) acc: 0.3333333333333333\n",
      "503 loss: tensor(1.2612) acc: 0.3333333333333333\n",
      "504 loss: tensor(1.2610) acc: 0.3333333333333333\n",
      "505 loss: tensor(1.2609) acc: 0.3333333333333333\n",
      "506 loss: tensor(1.2607) acc: 0.3333333333333333\n",
      "507 loss: tensor(1.2605) acc: 0.3333333333333333\n",
      "508 loss: tensor(1.2604) acc: 0.3333333333333333\n",
      "509 loss: tensor(1.2602) acc: 0.3333333333333333\n",
      "510 loss: tensor(1.2600) acc: 0.3333333333333333\n",
      "511 loss: tensor(1.2599) acc: 0.3333333333333333\n",
      "512 loss: tensor(1.2597) acc: 0.3333333333333333\n",
      "513 loss: tensor(1.2595) acc: 0.3333333333333333\n",
      "514 loss: tensor(1.2594) acc: 0.3333333333333333\n",
      "515 loss: tensor(1.2592) acc: 0.3333333333333333\n",
      "516 loss: tensor(1.2590) acc: 0.3333333333333333\n",
      "517 loss: tensor(1.2589) acc: 0.3333333333333333\n",
      "518 loss: tensor(1.2587) acc: 0.3333333333333333\n",
      "519 loss: tensor(1.2585) acc: 0.3333333333333333\n",
      "520 loss: tensor(1.2584) acc: 0.3333333333333333\n",
      "521 loss: tensor(1.2582) acc: 0.3333333333333333\n",
      "522 loss: tensor(1.2580) acc: 0.3333333333333333\n",
      "523 loss: tensor(1.2579) acc: 0.3333333333333333\n",
      "524 loss: tensor(1.2577) acc: 0.3333333333333333\n",
      "525 loss: tensor(1.2575) acc: 0.3333333333333333\n",
      "526 loss: tensor(1.2574) acc: 0.3333333333333333\n",
      "527 loss: tensor(1.2572) acc: 0.3333333333333333\n",
      "528 loss: tensor(1.2570) acc: 0.3333333333333333\n",
      "529 loss: tensor(1.2569) acc: 0.3333333333333333\n",
      "530 loss: tensor(1.2567) acc: 0.3333333333333333\n",
      "531 loss: tensor(1.2565) acc: 0.3333333333333333\n",
      "532 loss: tensor(1.2564) acc: 0.3333333333333333\n",
      "533 loss: tensor(1.2562) acc: 0.3333333333333333\n",
      "534 loss: tensor(1.2560) acc: 0.3333333333333333\n",
      "535 loss: tensor(1.2559) acc: 0.3333333333333333\n",
      "536 loss: tensor(1.2557) acc: 0.3333333333333333\n",
      "537 loss: tensor(1.2555) acc: 0.3333333333333333\n",
      "538 loss: tensor(1.2554) acc: 0.3333333333333333\n",
      "539 loss: tensor(1.2552) acc: 0.3333333333333333\n",
      "540 loss: tensor(1.2550) acc: 0.3333333333333333\n",
      "541 loss: tensor(1.2549) acc: 0.3333333333333333\n",
      "542 loss: tensor(1.2547) acc: 0.3333333333333333\n",
      "543 loss: tensor(1.2545) acc: 0.3333333333333333\n",
      "544 loss: tensor(1.2544) acc: 0.3333333333333333\n",
      "545 loss: tensor(1.2542) acc: 0.3333333333333333\n",
      "546 loss: tensor(1.2540) acc: 0.3333333333333333\n",
      "547 loss: tensor(1.2539) acc: 0.3333333333333333\n",
      "548 loss: tensor(1.2537) acc: 0.3333333333333333\n",
      "549 loss: tensor(1.2535) acc: 0.3333333333333333\n",
      "550 loss: tensor(1.2534) acc: 0.3333333333333333\n",
      "551 loss: tensor(1.2532) acc: 0.3333333333333333\n",
      "552 loss: tensor(1.2530) acc: 0.3333333333333333\n",
      "553 loss: tensor(1.2529) acc: 0.3333333333333333\n",
      "554 loss: tensor(1.2527) acc: 0.3333333333333333\n",
      "555 loss: tensor(1.2525) acc: 0.3333333333333333\n",
      "556 loss: tensor(1.2524) acc: 0.3333333333333333\n",
      "557 loss: tensor(1.2522) acc: 0.3333333333333333\n",
      "558 loss: tensor(1.2520) acc: 0.3333333333333333\n",
      "559 loss: tensor(1.2519) acc: 0.3333333333333333\n",
      "560 loss: tensor(1.2517) acc: 0.3333333333333333\n",
      "561 loss: tensor(1.2515) acc: 0.3333333333333333\n",
      "562 loss: tensor(1.2514) acc: 0.3333333333333333\n",
      "563 loss: tensor(1.2512) acc: 0.3333333333333333\n",
      "564 loss: tensor(1.2510) acc: 0.3333333333333333\n",
      "565 loss: tensor(1.2509) acc: 0.3333333333333333\n",
      "566 loss: tensor(1.2507) acc: 0.3333333333333333\n",
      "567 loss: tensor(1.2505) acc: 0.3333333333333333\n",
      "568 loss: tensor(1.2504) acc: 0.3333333333333333\n",
      "569 loss: tensor(1.2502) acc: 0.3333333333333333\n",
      "570 loss: tensor(1.2500) acc: 0.3333333333333333\n",
      "571 loss: tensor(1.2499) acc: 0.3333333333333333\n",
      "572 loss: tensor(1.2497) acc: 0.3333333333333333\n",
      "573 loss: tensor(1.2495) acc: 0.3333333333333333\n",
      "574 loss: tensor(1.2494) acc: 0.3333333333333333\n",
      "575 loss: tensor(1.2492) acc: 0.3333333333333333\n",
      "576 loss: tensor(1.2490) acc: 0.3333333333333333\n",
      "577 loss: tensor(1.2489) acc: 0.3333333333333333\n",
      "578 loss: tensor(1.2487) acc: 0.3333333333333333\n",
      "579 loss: tensor(1.2486) acc: 0.3333333333333333\n",
      "580 loss: tensor(1.2484) acc: 0.3333333333333333\n",
      "581 loss: tensor(1.2482) acc: 0.3333333333333333\n",
      "582 loss: tensor(1.2481) acc: 0.3333333333333333\n",
      "583 loss: tensor(1.2479) acc: 0.3333333333333333\n",
      "584 loss: tensor(1.2477) acc: 0.3333333333333333\n",
      "585 loss: tensor(1.2476) acc: 0.3333333333333333\n",
      "586 loss: tensor(1.2474) acc: 0.3333333333333333\n",
      "587 loss: tensor(1.2472) acc: 0.3333333333333333\n",
      "588 loss: tensor(1.2471) acc: 0.3333333333333333\n",
      "589 loss: tensor(1.2469) acc: 0.3333333333333333\n",
      "590 loss: tensor(1.2467) acc: 0.3333333333333333\n",
      "591 loss: tensor(1.2466) acc: 0.3333333333333333\n",
      "592 loss: tensor(1.2464) acc: 0.3333333333333333\n",
      "593 loss: tensor(1.2462) acc: 0.3333333333333333\n",
      "594 loss: tensor(1.2461) acc: 0.3333333333333333\n",
      "595 loss: tensor(1.2459) acc: 0.3333333333333333\n",
      "596 loss: tensor(1.2457) acc: 0.3333333333333333\n",
      "597 loss: tensor(1.2456) acc: 0.3333333333333333\n",
      "598 loss: tensor(1.2454) acc: 0.3333333333333333\n",
      "599 loss: tensor(1.2453) acc: 0.3333333333333333\n",
      "600 loss: tensor(1.2451) acc: 0.3333333333333333\n",
      "601 loss: tensor(1.2449) acc: 0.3333333333333333\n",
      "602 loss: tensor(1.2448) acc: 0.3333333333333333\n",
      "603 loss: tensor(1.2446) acc: 0.3333333333333333\n",
      "604 loss: tensor(1.2444) acc: 0.3333333333333333\n",
      "605 loss: tensor(1.2443) acc: 0.3333333333333333\n",
      "606 loss: tensor(1.2441) acc: 0.3333333333333333\n",
      "607 loss: tensor(1.2439) acc: 0.3333333333333333\n",
      "608 loss: tensor(1.2438) acc: 0.3333333333333333\n",
      "609 loss: tensor(1.2436) acc: 0.3333333333333333\n",
      "610 loss: tensor(1.2435) acc: 0.3333333333333333\n",
      "611 loss: tensor(1.2433) acc: 0.3333333333333333\n",
      "612 loss: tensor(1.2431) acc: 0.3333333333333333\n",
      "613 loss: tensor(1.2430) acc: 0.3333333333333333\n",
      "614 loss: tensor(1.2428) acc: 0.3333333333333333\n",
      "615 loss: tensor(1.2426) acc: 0.3333333333333333\n",
      "616 loss: tensor(1.2425) acc: 0.3333333333333333\n",
      "617 loss: tensor(1.2423) acc: 0.3333333333333333\n",
      "618 loss: tensor(1.2421) acc: 0.3333333333333333\n",
      "619 loss: tensor(1.2420) acc: 0.3333333333333333\n",
      "620 loss: tensor(1.2418) acc: 0.3333333333333333\n",
      "621 loss: tensor(1.2417) acc: 0.3333333333333333\n",
      "622 loss: tensor(1.2415) acc: 0.3333333333333333\n",
      "623 loss: tensor(1.2413) acc: 0.3333333333333333\n",
      "624 loss: tensor(1.2412) acc: 0.3333333333333333\n",
      "625 loss: tensor(1.2410) acc: 0.3333333333333333\n",
      "626 loss: tensor(1.2408) acc: 0.3333333333333333\n",
      "627 loss: tensor(1.2407) acc: 0.3333333333333333\n",
      "628 loss: tensor(1.2405) acc: 0.3333333333333333\n",
      "629 loss: tensor(1.2404) acc: 0.3333333333333333\n",
      "630 loss: tensor(1.2402) acc: 0.3333333333333333\n",
      "631 loss: tensor(1.2400) acc: 0.3333333333333333\n",
      "632 loss: tensor(1.2399) acc: 0.3333333333333333\n",
      "633 loss: tensor(1.2397) acc: 0.3333333333333333\n",
      "634 loss: tensor(1.2395) acc: 0.3333333333333333\n",
      "635 loss: tensor(1.2394) acc: 0.3333333333333333\n",
      "636 loss: tensor(1.2392) acc: 0.3333333333333333\n",
      "637 loss: tensor(1.2391) acc: 0.3333333333333333\n",
      "638 loss: tensor(1.2389) acc: 0.3333333333333333\n",
      "639 loss: tensor(1.2387) acc: 0.3333333333333333\n",
      "640 loss: tensor(1.2386) acc: 0.3333333333333333\n",
      "641 loss: tensor(1.2384) acc: 0.3333333333333333\n",
      "642 loss: tensor(1.2383) acc: 0.3333333333333333\n",
      "643 loss: tensor(1.2381) acc: 0.3333333333333333\n",
      "644 loss: tensor(1.2379) acc: 0.3333333333333333\n",
      "645 loss: tensor(1.2378) acc: 0.3333333333333333\n",
      "646 loss: tensor(1.2376) acc: 0.3333333333333333\n",
      "647 loss: tensor(1.2374) acc: 0.3333333333333333\n",
      "648 loss: tensor(1.2373) acc: 0.3333333333333333\n",
      "649 loss: tensor(1.2371) acc: 0.3333333333333333\n",
      "650 loss: tensor(1.2370) acc: 0.3333333333333333\n",
      "651 loss: tensor(1.2368) acc: 0.3333333333333333\n",
      "652 loss: tensor(1.2366) acc: 0.3333333333333333\n",
      "653 loss: tensor(1.2365) acc: 0.3333333333333333\n",
      "654 loss: tensor(1.2363) acc: 0.3333333333333333\n",
      "655 loss: tensor(1.2362) acc: 0.3333333333333333\n",
      "656 loss: tensor(1.2360) acc: 0.3333333333333333\n",
      "657 loss: tensor(1.2358) acc: 0.3333333333333333\n",
      "658 loss: tensor(1.2357) acc: 0.3333333333333333\n",
      "659 loss: tensor(1.2355) acc: 0.3333333333333333\n",
      "660 loss: tensor(1.2354) acc: 0.3333333333333333\n",
      "661 loss: tensor(1.2352) acc: 0.3333333333333333\n",
      "662 loss: tensor(1.2350) acc: 0.3333333333333333\n",
      "663 loss: tensor(1.2349) acc: 0.3333333333333333\n",
      "664 loss: tensor(1.2347) acc: 0.3333333333333333\n",
      "665 loss: tensor(1.2346) acc: 0.3333333333333333\n",
      "666 loss: tensor(1.2344) acc: 0.3333333333333333\n",
      "667 loss: tensor(1.2342) acc: 0.3333333333333333\n",
      "668 loss: tensor(1.2341) acc: 0.3333333333333333\n",
      "669 loss: tensor(1.2339) acc: 0.3333333333333333\n",
      "670 loss: tensor(1.2338) acc: 0.3333333333333333\n",
      "671 loss: tensor(1.2336) acc: 0.3333333333333333\n",
      "672 loss: tensor(1.2334) acc: 0.3333333333333333\n",
      "673 loss: tensor(1.2333) acc: 0.3333333333333333\n",
      "674 loss: tensor(1.2331) acc: 0.3333333333333333\n",
      "675 loss: tensor(1.2330) acc: 0.3333333333333333\n",
      "676 loss: tensor(1.2328) acc: 0.3333333333333333\n",
      "677 loss: tensor(1.2326) acc: 0.3333333333333333\n",
      "678 loss: tensor(1.2325) acc: 0.3333333333333333\n",
      "679 loss: tensor(1.2323) acc: 0.3333333333333333\n",
      "680 loss: tensor(1.2322) acc: 0.3333333333333333\n",
      "681 loss: tensor(1.2320) acc: 0.3333333333333333\n",
      "682 loss: tensor(1.2319) acc: 0.3333333333333333\n",
      "683 loss: tensor(1.2317) acc: 0.3333333333333333\n",
      "684 loss: tensor(1.2315) acc: 0.3333333333333333\n",
      "685 loss: tensor(1.2314) acc: 0.3333333333333333\n",
      "686 loss: tensor(1.2312) acc: 0.3333333333333333\n",
      "687 loss: tensor(1.2311) acc: 0.3333333333333333\n",
      "688 loss: tensor(1.2309) acc: 0.3333333333333333\n",
      "689 loss: tensor(1.2307) acc: 0.3333333333333333\n",
      "690 loss: tensor(1.2306) acc: 0.3333333333333333\n",
      "691 loss: tensor(1.2304) acc: 0.3333333333333333\n",
      "692 loss: tensor(1.2303) acc: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 loss: tensor(1.2301) acc: 0.3333333333333333\n",
      "694 loss: tensor(1.2300) acc: 0.3333333333333333\n",
      "695 loss: tensor(1.2298) acc: 0.3333333333333333\n",
      "696 loss: tensor(1.2296) acc: 0.3333333333333333\n",
      "697 loss: tensor(1.2295) acc: 0.3333333333333333\n",
      "698 loss: tensor(1.2293) acc: 0.3333333333333333\n",
      "699 loss: tensor(1.2292) acc: 0.3333333333333333\n",
      "700 loss: tensor(1.2290) acc: 0.3333333333333333\n",
      "701 loss: tensor(1.2289) acc: 0.3333333333333333\n",
      "702 loss: tensor(1.2287) acc: 0.3333333333333333\n",
      "703 loss: tensor(1.2285) acc: 0.3333333333333333\n",
      "704 loss: tensor(1.2284) acc: 0.3333333333333333\n",
      "705 loss: tensor(1.2282) acc: 0.3333333333333333\n",
      "706 loss: tensor(1.2281) acc: 0.3333333333333333\n",
      "707 loss: tensor(1.2279) acc: 0.3333333333333333\n",
      "708 loss: tensor(1.2278) acc: 0.3333333333333333\n",
      "709 loss: tensor(1.2276) acc: 0.3333333333333333\n",
      "710 loss: tensor(1.2275) acc: 0.3333333333333333\n",
      "711 loss: tensor(1.2273) acc: 0.3333333333333333\n",
      "712 loss: tensor(1.2271) acc: 0.3333333333333333\n",
      "713 loss: tensor(1.2270) acc: 0.3333333333333333\n",
      "714 loss: tensor(1.2268) acc: 0.3333333333333333\n",
      "715 loss: tensor(1.2267) acc: 0.3333333333333333\n",
      "716 loss: tensor(1.2265) acc: 0.3333333333333333\n",
      "717 loss: tensor(1.2264) acc: 0.3333333333333333\n",
      "718 loss: tensor(1.2262) acc: 0.3333333333333333\n",
      "719 loss: tensor(1.2261) acc: 0.3333333333333333\n",
      "720 loss: tensor(1.2259) acc: 0.3333333333333333\n",
      "721 loss: tensor(1.2257) acc: 0.3333333333333333\n",
      "722 loss: tensor(1.2256) acc: 0.3333333333333333\n",
      "723 loss: tensor(1.2254) acc: 0.3333333333333333\n",
      "724 loss: tensor(1.2253) acc: 0.3333333333333333\n",
      "725 loss: tensor(1.2251) acc: 0.3333333333333333\n",
      "726 loss: tensor(1.2250) acc: 0.3333333333333333\n",
      "727 loss: tensor(1.2248) acc: 0.3333333333333333\n",
      "728 loss: tensor(1.2247) acc: 0.3333333333333333\n",
      "729 loss: tensor(1.2245) acc: 0.3333333333333333\n",
      "730 loss: tensor(1.2244) acc: 0.3333333333333333\n",
      "731 loss: tensor(1.2242) acc: 0.3333333333333333\n",
      "732 loss: tensor(1.2240) acc: 0.3333333333333333\n",
      "733 loss: tensor(1.2239) acc: 0.3333333333333333\n",
      "734 loss: tensor(1.2237) acc: 0.3333333333333333\n",
      "735 loss: tensor(1.2236) acc: 0.3333333333333333\n",
      "736 loss: tensor(1.2234) acc: 0.3333333333333333\n",
      "737 loss: tensor(1.2233) acc: 0.3333333333333333\n",
      "738 loss: tensor(1.2231) acc: 0.3333333333333333\n",
      "739 loss: tensor(1.2230) acc: 0.3333333333333333\n",
      "740 loss: tensor(1.2228) acc: 0.3333333333333333\n",
      "741 loss: tensor(1.2227) acc: 0.3333333333333333\n",
      "742 loss: tensor(1.2225) acc: 0.3333333333333333\n",
      "743 loss: tensor(1.2224) acc: 0.3333333333333333\n",
      "744 loss: tensor(1.2222) acc: 0.3333333333333333\n",
      "745 loss: tensor(1.2220) acc: 0.3333333333333333\n",
      "746 loss: tensor(1.2219) acc: 0.3333333333333333\n",
      "747 loss: tensor(1.2217) acc: 0.3333333333333333\n",
      "748 loss: tensor(1.2216) acc: 0.3333333333333333\n",
      "749 loss: tensor(1.2214) acc: 0.3333333333333333\n",
      "750 loss: tensor(1.2213) acc: 0.3333333333333333\n",
      "751 loss: tensor(1.2211) acc: 0.3333333333333333\n",
      "752 loss: tensor(1.2210) acc: 0.3333333333333333\n",
      "753 loss: tensor(1.2208) acc: 0.3333333333333333\n",
      "754 loss: tensor(1.2207) acc: 0.3333333333333333\n",
      "755 loss: tensor(1.2205) acc: 0.3333333333333333\n",
      "756 loss: tensor(1.2204) acc: 0.3333333333333333\n",
      "757 loss: tensor(1.2202) acc: 0.3333333333333333\n",
      "758 loss: tensor(1.2201) acc: 0.3333333333333333\n",
      "759 loss: tensor(1.2199) acc: 0.3333333333333333\n",
      "760 loss: tensor(1.2198) acc: 0.3333333333333333\n",
      "761 loss: tensor(1.2196) acc: 0.3333333333333333\n",
      "762 loss: tensor(1.2195) acc: 0.3333333333333333\n",
      "763 loss: tensor(1.2193) acc: 0.3333333333333333\n",
      "764 loss: tensor(1.2192) acc: 0.3333333333333333\n",
      "765 loss: tensor(1.2190) acc: 0.3333333333333333\n",
      "766 loss: tensor(1.2189) acc: 0.3333333333333333\n",
      "767 loss: tensor(1.2187) acc: 0.3333333333333333\n",
      "768 loss: tensor(1.2186) acc: 0.3333333333333333\n",
      "769 loss: tensor(1.2184) acc: 0.3333333333333333\n",
      "770 loss: tensor(1.2183) acc: 0.3333333333333333\n",
      "771 loss: tensor(1.2181) acc: 0.3333333333333333\n",
      "772 loss: tensor(1.2180) acc: 0.3333333333333333\n",
      "773 loss: tensor(1.2178) acc: 0.3333333333333333\n",
      "774 loss: tensor(1.2176) acc: 0.3333333333333333\n",
      "775 loss: tensor(1.2175) acc: 0.3333333333333333\n",
      "776 loss: tensor(1.2173) acc: 0.3333333333333333\n",
      "777 loss: tensor(1.2172) acc: 0.3333333333333333\n",
      "778 loss: tensor(1.2170) acc: 0.3333333333333333\n",
      "779 loss: tensor(1.2169) acc: 0.3333333333333333\n",
      "780 loss: tensor(1.2167) acc: 0.3333333333333333\n",
      "781 loss: tensor(1.2166) acc: 0.3333333333333333\n",
      "782 loss: tensor(1.2165) acc: 0.3333333333333333\n",
      "783 loss: tensor(1.2163) acc: 0.3333333333333333\n",
      "784 loss: tensor(1.2162) acc: 0.3333333333333333\n",
      "785 loss: tensor(1.2160) acc: 0.3333333333333333\n",
      "786 loss: tensor(1.2159) acc: 0.3333333333333333\n",
      "787 loss: tensor(1.2157) acc: 0.3333333333333333\n",
      "788 loss: tensor(1.2156) acc: 0.3333333333333333\n",
      "789 loss: tensor(1.2154) acc: 0.3333333333333333\n",
      "790 loss: tensor(1.2153) acc: 0.3333333333333333\n",
      "791 loss: tensor(1.2151) acc: 0.3333333333333333\n",
      "792 loss: tensor(1.2150) acc: 0.3333333333333333\n",
      "793 loss: tensor(1.2148) acc: 0.3333333333333333\n",
      "794 loss: tensor(1.2147) acc: 0.3333333333333333\n",
      "795 loss: tensor(1.2145) acc: 0.3333333333333333\n",
      "796 loss: tensor(1.2144) acc: 0.3333333333333333\n",
      "797 loss: tensor(1.2142) acc: 0.3333333333333333\n",
      "798 loss: tensor(1.2141) acc: 0.3333333333333333\n",
      "799 loss: tensor(1.2139) acc: 0.3333333333333333\n",
      "800 loss: tensor(1.2138) acc: 0.3333333333333333\n",
      "801 loss: tensor(1.2136) acc: 0.3333333333333333\n",
      "802 loss: tensor(1.2135) acc: 0.3333333333333333\n",
      "803 loss: tensor(1.2133) acc: 0.3333333333333333\n",
      "804 loss: tensor(1.2132) acc: 0.3333333333333333\n",
      "805 loss: tensor(1.2130) acc: 0.3333333333333333\n",
      "806 loss: tensor(1.2129) acc: 0.3333333333333333\n",
      "807 loss: tensor(1.2127) acc: 0.3333333333333333\n",
      "808 loss: tensor(1.2126) acc: 0.3333333333333333\n",
      "809 loss: tensor(1.2124) acc: 0.3333333333333333\n",
      "810 loss: tensor(1.2123) acc: 0.3333333333333333\n",
      "811 loss: tensor(1.2122) acc: 0.3333333333333333\n",
      "812 loss: tensor(1.2120) acc: 0.3333333333333333\n",
      "813 loss: tensor(1.2119) acc: 0.3333333333333333\n",
      "814 loss: tensor(1.2117) acc: 0.3333333333333333\n",
      "815 loss: tensor(1.2116) acc: 0.3333333333333333\n",
      "816 loss: tensor(1.2114) acc: 0.3333333333333333\n",
      "817 loss: tensor(1.2113) acc: 0.3333333333333333\n",
      "818 loss: tensor(1.2111) acc: 0.3333333333333333\n",
      "819 loss: tensor(1.2110) acc: 0.3333333333333333\n",
      "820 loss: tensor(1.2108) acc: 0.3333333333333333\n",
      "821 loss: tensor(1.2107) acc: 0.3333333333333333\n",
      "822 loss: tensor(1.2105) acc: 0.3333333333333333\n",
      "823 loss: tensor(1.2104) acc: 0.3333333333333333\n",
      "824 loss: tensor(1.2102) acc: 0.3333333333333333\n",
      "825 loss: tensor(1.2101) acc: 0.3333333333333333\n",
      "826 loss: tensor(1.2100) acc: 0.3333333333333333\n",
      "827 loss: tensor(1.2098) acc: 0.3333333333333333\n",
      "828 loss: tensor(1.2097) acc: 0.3333333333333333\n",
      "829 loss: tensor(1.2095) acc: 0.3333333333333333\n",
      "830 loss: tensor(1.2094) acc: 0.3333333333333333\n",
      "831 loss: tensor(1.2092) acc: 0.3333333333333333\n",
      "832 loss: tensor(1.2091) acc: 0.3333333333333333\n",
      "833 loss: tensor(1.2089) acc: 0.3333333333333333\n",
      "834 loss: tensor(1.2088) acc: 0.3333333333333333\n",
      "835 loss: tensor(1.2087) acc: 0.3333333333333333\n",
      "836 loss: tensor(1.2085) acc: 0.3333333333333333\n",
      "837 loss: tensor(1.2084) acc: 0.3333333333333333\n",
      "838 loss: tensor(1.2082) acc: 0.3333333333333333\n",
      "839 loss: tensor(1.2081) acc: 0.3333333333333333\n",
      "840 loss: tensor(1.2079) acc: 0.3333333333333333\n",
      "841 loss: tensor(1.2078) acc: 0.3333333333333333\n",
      "842 loss: tensor(1.2076) acc: 0.3333333333333333\n",
      "843 loss: tensor(1.2075) acc: 0.3333333333333333\n",
      "844 loss: tensor(1.2074) acc: 0.3333333333333333\n",
      "845 loss: tensor(1.2072) acc: 0.3333333333333333\n",
      "846 loss: tensor(1.2071) acc: 0.3333333333333333\n",
      "847 loss: tensor(1.2069) acc: 0.3333333333333333\n",
      "848 loss: tensor(1.2068) acc: 0.3333333333333333\n",
      "849 loss: tensor(1.2066) acc: 0.3333333333333333\n",
      "850 loss: tensor(1.2065) acc: 0.3333333333333333\n",
      "851 loss: tensor(1.2064) acc: 0.3333333333333333\n",
      "852 loss: tensor(1.2062) acc: 0.3333333333333333\n",
      "853 loss: tensor(1.2061) acc: 0.3333333333333333\n",
      "854 loss: tensor(1.2059) acc: 0.3333333333333333\n",
      "855 loss: tensor(1.2058) acc: 0.3333333333333333\n",
      "856 loss: tensor(1.2056) acc: 0.3333333333333333\n",
      "857 loss: tensor(1.2055) acc: 0.3333333333333333\n",
      "858 loss: tensor(1.2054) acc: 0.3333333333333333\n",
      "859 loss: tensor(1.2052) acc: 0.3333333333333333\n",
      "860 loss: tensor(1.2051) acc: 0.3333333333333333\n",
      "861 loss: tensor(1.2049) acc: 0.3333333333333333\n",
      "862 loss: tensor(1.2048) acc: 0.3333333333333333\n",
      "863 loss: tensor(1.2046) acc: 0.3333333333333333\n",
      "864 loss: tensor(1.2045) acc: 0.3333333333333333\n",
      "865 loss: tensor(1.2044) acc: 0.3333333333333333\n",
      "866 loss: tensor(1.2042) acc: 0.3333333333333333\n",
      "867 loss: tensor(1.2041) acc: 0.3333333333333333\n",
      "868 loss: tensor(1.2039) acc: 0.3333333333333333\n",
      "869 loss: tensor(1.2038) acc: 0.3333333333333333\n",
      "870 loss: tensor(1.2036) acc: 0.3333333333333333\n",
      "871 loss: tensor(1.2035) acc: 0.3333333333333333\n",
      "872 loss: tensor(1.2034) acc: 0.3333333333333333\n",
      "873 loss: tensor(1.2032) acc: 0.3333333333333333\n",
      "874 loss: tensor(1.2031) acc: 0.3333333333333333\n",
      "875 loss: tensor(1.2029) acc: 0.3333333333333333\n",
      "876 loss: tensor(1.2028) acc: 0.3333333333333333\n",
      "877 loss: tensor(1.2027) acc: 0.3333333333333333\n",
      "878 loss: tensor(1.2025) acc: 0.3333333333333333\n",
      "879 loss: tensor(1.2024) acc: 0.3333333333333333\n",
      "880 loss: tensor(1.2022) acc: 0.3333333333333333\n",
      "881 loss: tensor(1.2021) acc: 0.3333333333333333\n",
      "882 loss: tensor(1.2020) acc: 0.3333333333333333\n",
      "883 loss: tensor(1.2018) acc: 0.3333333333333333\n",
      "884 loss: tensor(1.2017) acc: 0.3333333333333333\n",
      "885 loss: tensor(1.2015) acc: 0.3333333333333333\n",
      "886 loss: tensor(1.2014) acc: 0.3333333333333333\n",
      "887 loss: tensor(1.2013) acc: 0.3333333333333333\n",
      "888 loss: tensor(1.2011) acc: 0.3333333333333333\n",
      "889 loss: tensor(1.2010) acc: 0.3333333333333333\n",
      "890 loss: tensor(1.2008) acc: 0.3333333333333333\n",
      "891 loss: tensor(1.2007) acc: 0.3333333333333333\n",
      "892 loss: tensor(1.2006) acc: 0.3333333333333333\n",
      "893 loss: tensor(1.2004) acc: 0.3333333333333333\n",
      "894 loss: tensor(1.2003) acc: 0.3333333333333333\n",
      "895 loss: tensor(1.2001) acc: 0.3333333333333333\n",
      "896 loss: tensor(1.2000) acc: 0.3333333333333333\n",
      "897 loss: tensor(1.1999) acc: 0.3333333333333333\n",
      "898 loss: tensor(1.1997) acc: 0.3333333333333333\n",
      "899 loss: tensor(1.1996) acc: 0.3333333333333333\n",
      "900 loss: tensor(1.1994) acc: 0.3333333333333333\n",
      "901 loss: tensor(1.1993) acc: 0.3333333333333333\n",
      "902 loss: tensor(1.1992) acc: 0.3333333333333333\n",
      "903 loss: tensor(1.1990) acc: 0.3333333333333333\n",
      "904 loss: tensor(1.1989) acc: 0.3333333333333333\n",
      "905 loss: tensor(1.1988) acc: 0.3333333333333333\n",
      "906 loss: tensor(1.1986) acc: 0.3333333333333333\n",
      "907 loss: tensor(1.1985) acc: 0.3333333333333333\n",
      "908 loss: tensor(1.1983) acc: 0.3333333333333333\n",
      "909 loss: tensor(1.1982) acc: 0.3333333333333333\n",
      "910 loss: tensor(1.1981) acc: 0.3333333333333333\n",
      "911 loss: tensor(1.1979) acc: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912 loss: tensor(1.1978) acc: 0.3333333333333333\n",
      "913 loss: tensor(1.1977) acc: 0.3333333333333333\n",
      "914 loss: tensor(1.1975) acc: 0.3333333333333333\n",
      "915 loss: tensor(1.1974) acc: 0.3333333333333333\n",
      "916 loss: tensor(1.1972) acc: 0.3333333333333333\n",
      "917 loss: tensor(1.1971) acc: 0.3333333333333333\n",
      "918 loss: tensor(1.1970) acc: 0.3333333333333333\n",
      "919 loss: tensor(1.1968) acc: 0.3333333333333333\n",
      "920 loss: tensor(1.1967) acc: 0.3333333333333333\n",
      "921 loss: tensor(1.1966) acc: 0.3333333333333333\n",
      "922 loss: tensor(1.1964) acc: 0.3333333333333333\n",
      "923 loss: tensor(1.1963) acc: 0.3333333333333333\n",
      "924 loss: tensor(1.1961) acc: 0.3333333333333333\n",
      "925 loss: tensor(1.1960) acc: 0.3333333333333333\n",
      "926 loss: tensor(1.1959) acc: 0.3333333333333333\n",
      "927 loss: tensor(1.1957) acc: 0.3333333333333333\n",
      "928 loss: tensor(1.1956) acc: 0.3333333333333333\n",
      "929 loss: tensor(1.1955) acc: 0.3333333333333333\n",
      "930 loss: tensor(1.1953) acc: 0.3333333333333333\n",
      "931 loss: tensor(1.1952) acc: 0.3333333333333333\n",
      "932 loss: tensor(1.1951) acc: 0.3333333333333333\n",
      "933 loss: tensor(1.1949) acc: 0.3333333333333333\n",
      "934 loss: tensor(1.1948) acc: 0.3333333333333333\n",
      "935 loss: tensor(1.1947) acc: 0.3333333333333333\n",
      "936 loss: tensor(1.1945) acc: 0.3333333333333333\n",
      "937 loss: tensor(1.1944) acc: 0.3333333333333333\n",
      "938 loss: tensor(1.1943) acc: 0.3333333333333333\n",
      "939 loss: tensor(1.1941) acc: 0.3333333333333333\n",
      "940 loss: tensor(1.1940) acc: 0.3333333333333333\n",
      "941 loss: tensor(1.1938) acc: 0.3333333333333333\n",
      "942 loss: tensor(1.1937) acc: 0.3333333333333333\n",
      "943 loss: tensor(1.1936) acc: 0.3333333333333333\n",
      "944 loss: tensor(1.1934) acc: 0.3333333333333333\n",
      "945 loss: tensor(1.1933) acc: 0.3333333333333333\n",
      "946 loss: tensor(1.1932) acc: 0.3333333333333333\n",
      "947 loss: tensor(1.1930) acc: 0.3333333333333333\n",
      "948 loss: tensor(1.1929) acc: 0.3333333333333333\n",
      "949 loss: tensor(1.1928) acc: 0.3333333333333333\n",
      "950 loss: tensor(1.1926) acc: 0.3333333333333333\n",
      "951 loss: tensor(1.1925) acc: 0.3333333333333333\n",
      "952 loss: tensor(1.1924) acc: 0.3333333333333333\n",
      "953 loss: tensor(1.1922) acc: 0.3333333333333333\n",
      "954 loss: tensor(1.1921) acc: 0.3333333333333333\n",
      "955 loss: tensor(1.1920) acc: 0.3333333333333333\n",
      "956 loss: tensor(1.1918) acc: 0.3333333333333333\n",
      "957 loss: tensor(1.1917) acc: 0.3333333333333333\n",
      "958 loss: tensor(1.1916) acc: 0.3333333333333333\n",
      "959 loss: tensor(1.1914) acc: 0.3333333333333333\n",
      "960 loss: tensor(1.1913) acc: 0.3333333333333333\n",
      "961 loss: tensor(1.1912) acc: 0.3333333333333333\n",
      "962 loss: tensor(1.1910) acc: 0.3333333333333333\n",
      "963 loss: tensor(1.1909) acc: 0.3333333333333333\n",
      "964 loss: tensor(1.1908) acc: 0.3333333333333333\n",
      "965 loss: tensor(1.1906) acc: 0.3333333333333333\n",
      "966 loss: tensor(1.1905) acc: 0.3333333333333333\n",
      "967 loss: tensor(1.1904) acc: 0.3333333333333333\n",
      "968 loss: tensor(1.1902) acc: 0.3333333333333333\n",
      "969 loss: tensor(1.1901) acc: 0.3333333333333333\n",
      "970 loss: tensor(1.1900) acc: 0.34\n",
      "971 loss: tensor(1.1898) acc: 0.34\n",
      "972 loss: tensor(1.1897) acc: 0.34\n",
      "973 loss: tensor(1.1896) acc: 0.34\n",
      "974 loss: tensor(1.1894) acc: 0.34\n",
      "975 loss: tensor(1.1893) acc: 0.34\n",
      "976 loss: tensor(1.1892) acc: 0.34\n",
      "977 loss: tensor(1.1891) acc: 0.34\n",
      "978 loss: tensor(1.1889) acc: 0.34\n",
      "979 loss: tensor(1.1888) acc: 0.34\n",
      "980 loss: tensor(1.1887) acc: 0.34\n",
      "981 loss: tensor(1.1885) acc: 0.34\n",
      "982 loss: tensor(1.1884) acc: 0.34\n",
      "983 loss: tensor(1.1883) acc: 0.34\n",
      "984 loss: tensor(1.1881) acc: 0.34\n",
      "985 loss: tensor(1.1880) acc: 0.34\n",
      "986 loss: tensor(1.1879) acc: 0.34\n",
      "987 loss: tensor(1.1877) acc: 0.34\n",
      "988 loss: tensor(1.1876) acc: 0.34\n",
      "989 loss: tensor(1.1875) acc: 0.34\n",
      "990 loss: tensor(1.1874) acc: 0.34\n",
      "991 loss: tensor(1.1872) acc: 0.34\n",
      "992 loss: tensor(1.1871) acc: 0.34\n",
      "993 loss: tensor(1.1870) acc: 0.34\n",
      "994 loss: tensor(1.1868) acc: 0.34\n",
      "995 loss: tensor(1.1867) acc: 0.34\n",
      "996 loss: tensor(1.1866) acc: 0.34\n",
      "997 loss: tensor(1.1864) acc: 0.34\n",
      "998 loss: tensor(1.1863) acc: 0.34\n",
      "999 loss: tensor(1.1862) acc: 0.34\n",
      "1000 loss: tensor(1.1861) acc: 0.34\n",
      "1001 loss: tensor(1.1859) acc: 0.34\n",
      "1002 loss: tensor(1.1858) acc: 0.34\n",
      "1003 loss: tensor(1.1857) acc: 0.34\n",
      "1004 loss: tensor(1.1855) acc: 0.34\n",
      "1005 loss: tensor(1.1854) acc: 0.34\n",
      "1006 loss: tensor(1.1853) acc: 0.34\n",
      "1007 loss: tensor(1.1852) acc: 0.34\n",
      "1008 loss: tensor(1.1850) acc: 0.34\n",
      "1009 loss: tensor(1.1849) acc: 0.34\n",
      "1010 loss: tensor(1.1848) acc: 0.34\n",
      "1011 loss: tensor(1.1846) acc: 0.34\n",
      "1012 loss: tensor(1.1845) acc: 0.34\n",
      "1013 loss: tensor(1.1844) acc: 0.34\n",
      "1014 loss: tensor(1.1843) acc: 0.34\n",
      "1015 loss: tensor(1.1841) acc: 0.34\n",
      "1016 loss: tensor(1.1840) acc: 0.34\n",
      "1017 loss: tensor(1.1839) acc: 0.34\n",
      "1018 loss: tensor(1.1837) acc: 0.3466666666666667\n",
      "1019 loss: tensor(1.1836) acc: 0.3466666666666667\n",
      "1020 loss: tensor(1.1835) acc: 0.3466666666666667\n",
      "1021 loss: tensor(1.1834) acc: 0.3466666666666667\n",
      "1022 loss: tensor(1.1832) acc: 0.3466666666666667\n",
      "1023 loss: tensor(1.1831) acc: 0.3466666666666667\n",
      "1024 loss: tensor(1.1830) acc: 0.3466666666666667\n",
      "1025 loss: tensor(1.1829) acc: 0.3466666666666667\n",
      "1026 loss: tensor(1.1827) acc: 0.3466666666666667\n",
      "1027 loss: tensor(1.1826) acc: 0.3466666666666667\n",
      "1028 loss: tensor(1.1825) acc: 0.3466666666666667\n",
      "1029 loss: tensor(1.1823) acc: 0.3466666666666667\n",
      "1030 loss: tensor(1.1822) acc: 0.3466666666666667\n",
      "1031 loss: tensor(1.1821) acc: 0.3466666666666667\n",
      "1032 loss: tensor(1.1820) acc: 0.34\n",
      "1033 loss: tensor(1.1818) acc: 0.34\n",
      "1034 loss: tensor(1.1817) acc: 0.34\n",
      "1035 loss: tensor(1.1816) acc: 0.34\n",
      "1036 loss: tensor(1.1815) acc: 0.34\n",
      "1037 loss: tensor(1.1813) acc: 0.34\n",
      "1038 loss: tensor(1.1812) acc: 0.34\n",
      "1039 loss: tensor(1.1811) acc: 0.34\n",
      "1040 loss: tensor(1.1810) acc: 0.34\n",
      "1041 loss: tensor(1.1808) acc: 0.34\n",
      "1042 loss: tensor(1.1807) acc: 0.34\n",
      "1043 loss: tensor(1.1806) acc: 0.3333333333333333\n",
      "1044 loss: tensor(1.1805) acc: 0.3333333333333333\n",
      "1045 loss: tensor(1.1803) acc: 0.3333333333333333\n",
      "1046 loss: tensor(1.1802) acc: 0.3333333333333333\n",
      "1047 loss: tensor(1.1801) acc: 0.34\n",
      "1048 loss: tensor(1.1800) acc: 0.34\n",
      "1049 loss: tensor(1.1798) acc: 0.34\n",
      "1050 loss: tensor(1.1797) acc: 0.34\n",
      "1051 loss: tensor(1.1796) acc: 0.34\n",
      "1052 loss: tensor(1.1795) acc: 0.3333333333333333\n",
      "1053 loss: tensor(1.1793) acc: 0.3333333333333333\n",
      "1054 loss: tensor(1.1792) acc: 0.3333333333333333\n",
      "1055 loss: tensor(1.1791) acc: 0.3333333333333333\n",
      "1056 loss: tensor(1.1790) acc: 0.3333333333333333\n",
      "1057 loss: tensor(1.1788) acc: 0.3333333333333333\n",
      "1058 loss: tensor(1.1787) acc: 0.3333333333333333\n",
      "1059 loss: tensor(1.1786) acc: 0.3333333333333333\n",
      "1060 loss: tensor(1.1785) acc: 0.3333333333333333\n",
      "1061 loss: tensor(1.1783) acc: 0.3333333333333333\n",
      "1062 loss: tensor(1.1782) acc: 0.3333333333333333\n",
      "1063 loss: tensor(1.1781) acc: 0.3333333333333333\n",
      "1064 loss: tensor(1.1780) acc: 0.3333333333333333\n",
      "1065 loss: tensor(1.1778) acc: 0.3333333333333333\n",
      "1066 loss: tensor(1.1777) acc: 0.3333333333333333\n",
      "1067 loss: tensor(1.1776) acc: 0.34\n",
      "1068 loss: tensor(1.1775) acc: 0.34\n",
      "1069 loss: tensor(1.1773) acc: 0.34\n",
      "1070 loss: tensor(1.1772) acc: 0.34\n",
      "1071 loss: tensor(1.1771) acc: 0.34\n",
      "1072 loss: tensor(1.1770) acc: 0.34\n",
      "1073 loss: tensor(1.1769) acc: 0.34\n",
      "1074 loss: tensor(1.1767) acc: 0.34\n",
      "1075 loss: tensor(1.1766) acc: 0.34\n",
      "1076 loss: tensor(1.1765) acc: 0.34\n",
      "1077 loss: tensor(1.1764) acc: 0.34\n",
      "1078 loss: tensor(1.1762) acc: 0.34\n",
      "1079 loss: tensor(1.1761) acc: 0.34\n",
      "1080 loss: tensor(1.1760) acc: 0.34\n",
      "1081 loss: tensor(1.1759) acc: 0.34\n",
      "1082 loss: tensor(1.1758) acc: 0.34\n",
      "1083 loss: tensor(1.1756) acc: 0.34\n",
      "1084 loss: tensor(1.1755) acc: 0.34\n",
      "1085 loss: tensor(1.1754) acc: 0.34\n",
      "1086 loss: tensor(1.1753) acc: 0.34\n",
      "1087 loss: tensor(1.1751) acc: 0.34\n",
      "1088 loss: tensor(1.1750) acc: 0.34\n",
      "1089 loss: tensor(1.1749) acc: 0.34\n",
      "1090 loss: tensor(1.1748) acc: 0.34\n",
      "1091 loss: tensor(1.1747) acc: 0.34\n",
      "1092 loss: tensor(1.1745) acc: 0.34\n",
      "1093 loss: tensor(1.1744) acc: 0.34\n",
      "1094 loss: tensor(1.1743) acc: 0.34\n",
      "1095 loss: tensor(1.1742) acc: 0.34\n",
      "1096 loss: tensor(1.1741) acc: 0.34\n",
      "1097 loss: tensor(1.1739) acc: 0.34\n",
      "1098 loss: tensor(1.1738) acc: 0.34\n",
      "1099 loss: tensor(1.1737) acc: 0.34\n",
      "1100 loss: tensor(1.1736) acc: 0.34\n",
      "1101 loss: tensor(1.1734) acc: 0.34\n",
      "1102 loss: tensor(1.1733) acc: 0.34\n",
      "1103 loss: tensor(1.1732) acc: 0.34\n",
      "1104 loss: tensor(1.1731) acc: 0.34\n",
      "1105 loss: tensor(1.1730) acc: 0.34\n",
      "1106 loss: tensor(1.1728) acc: 0.34\n",
      "1107 loss: tensor(1.1727) acc: 0.34\n",
      "1108 loss: tensor(1.1726) acc: 0.34\n",
      "1109 loss: tensor(1.1725) acc: 0.34\n",
      "1110 loss: tensor(1.1724) acc: 0.34\n",
      "1111 loss: tensor(1.1722) acc: 0.34\n",
      "1112 loss: tensor(1.1721) acc: 0.34\n",
      "1113 loss: tensor(1.1720) acc: 0.34\n",
      "1114 loss: tensor(1.1719) acc: 0.34\n",
      "1115 loss: tensor(1.1718) acc: 0.34\n",
      "1116 loss: tensor(1.1717) acc: 0.34\n",
      "1117 loss: tensor(1.1715) acc: 0.34\n",
      "1118 loss: tensor(1.1714) acc: 0.34\n",
      "1119 loss: tensor(1.1713) acc: 0.34\n",
      "1120 loss: tensor(1.1712) acc: 0.34\n",
      "1121 loss: tensor(1.1711) acc: 0.34\n",
      "1122 loss: tensor(1.1709) acc: 0.34\n",
      "1123 loss: tensor(1.1708) acc: 0.34\n",
      "1124 loss: tensor(1.1707) acc: 0.34\n",
      "1125 loss: tensor(1.1706) acc: 0.34\n",
      "1126 loss: tensor(1.1705) acc: 0.34\n",
      "1127 loss: tensor(1.1703) acc: 0.34\n",
      "1128 loss: tensor(1.1702) acc: 0.34\n",
      "1129 loss: tensor(1.1701) acc: 0.34\n",
      "1130 loss: tensor(1.1700) acc: 0.34\n",
      "1131 loss: tensor(1.1699) acc: 0.34\n",
      "1132 loss: tensor(1.1698) acc: 0.34\n",
      "1133 loss: tensor(1.1696) acc: 0.34\n",
      "1134 loss: tensor(1.1695) acc: 0.34\n",
      "1135 loss: tensor(1.1694) acc: 0.34\n",
      "1136 loss: tensor(1.1693) acc: 0.34\n",
      "1137 loss: tensor(1.1692) acc: 0.34\n",
      "1138 loss: tensor(1.1691) acc: 0.34\n",
      "1139 loss: tensor(1.1689) acc: 0.34\n",
      "1140 loss: tensor(1.1688) acc: 0.34\n",
      "1141 loss: tensor(1.1687) acc: 0.34\n",
      "1142 loss: tensor(1.1686) acc: 0.34\n",
      "1143 loss: tensor(1.1685) acc: 0.34\n",
      "1144 loss: tensor(1.1684) acc: 0.34\n",
      "1145 loss: tensor(1.1682) acc: 0.34\n",
      "1146 loss: tensor(1.1681) acc: 0.34\n",
      "1147 loss: tensor(1.1680) acc: 0.34\n",
      "1148 loss: tensor(1.1679) acc: 0.34\n",
      "1149 loss: tensor(1.1678) acc: 0.34\n",
      "1150 loss: tensor(1.1677) acc: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151 loss: tensor(1.1675) acc: 0.34\n",
      "1152 loss: tensor(1.1674) acc: 0.34\n",
      "1153 loss: tensor(1.1673) acc: 0.34\n",
      "1154 loss: tensor(1.1672) acc: 0.34\n",
      "1155 loss: tensor(1.1671) acc: 0.34\n",
      "1156 loss: tensor(1.1670) acc: 0.34\n",
      "1157 loss: tensor(1.1668) acc: 0.34\n",
      "1158 loss: tensor(1.1667) acc: 0.34\n",
      "1159 loss: tensor(1.1666) acc: 0.34\n",
      "1160 loss: tensor(1.1665) acc: 0.34\n",
      "1161 loss: tensor(1.1664) acc: 0.34\n",
      "1162 loss: tensor(1.1663) acc: 0.34\n",
      "1163 loss: tensor(1.1662) acc: 0.34\n",
      "1164 loss: tensor(1.1660) acc: 0.34\n",
      "1165 loss: tensor(1.1659) acc: 0.34\n",
      "1166 loss: tensor(1.1658) acc: 0.3466666666666667\n",
      "1167 loss: tensor(1.1657) acc: 0.3466666666666667\n",
      "1168 loss: tensor(1.1656) acc: 0.3466666666666667\n",
      "1169 loss: tensor(1.1655) acc: 0.3466666666666667\n",
      "1170 loss: tensor(1.1653) acc: 0.3466666666666667\n",
      "1171 loss: tensor(1.1652) acc: 0.3466666666666667\n",
      "1172 loss: tensor(1.1651) acc: 0.3466666666666667\n",
      "1173 loss: tensor(1.1650) acc: 0.3466666666666667\n",
      "1174 loss: tensor(1.1649) acc: 0.3466666666666667\n",
      "1175 loss: tensor(1.1648) acc: 0.3466666666666667\n",
      "1176 loss: tensor(1.1647) acc: 0.3466666666666667\n",
      "1177 loss: tensor(1.1645) acc: 0.3466666666666667\n",
      "1178 loss: tensor(1.1644) acc: 0.3466666666666667\n",
      "1179 loss: tensor(1.1643) acc: 0.3466666666666667\n",
      "1180 loss: tensor(1.1642) acc: 0.3466666666666667\n",
      "1181 loss: tensor(1.1641) acc: 0.3466666666666667\n",
      "1182 loss: tensor(1.1640) acc: 0.3466666666666667\n",
      "1183 loss: tensor(1.1639) acc: 0.3466666666666667\n",
      "1184 loss: tensor(1.1638) acc: 0.3466666666666667\n",
      "1185 loss: tensor(1.1636) acc: 0.3466666666666667\n",
      "1186 loss: tensor(1.1635) acc: 0.3466666666666667\n",
      "1187 loss: tensor(1.1634) acc: 0.3466666666666667\n",
      "1188 loss: tensor(1.1633) acc: 0.3466666666666667\n",
      "1189 loss: tensor(1.1632) acc: 0.3466666666666667\n",
      "1190 loss: tensor(1.1631) acc: 0.3466666666666667\n",
      "1191 loss: tensor(1.1630) acc: 0.3466666666666667\n",
      "1192 loss: tensor(1.1628) acc: 0.3466666666666667\n",
      "1193 loss: tensor(1.1627) acc: 0.3466666666666667\n",
      "1194 loss: tensor(1.1626) acc: 0.3466666666666667\n",
      "1195 loss: tensor(1.1625) acc: 0.35333333333333333\n",
      "1196 loss: tensor(1.1624) acc: 0.36\n",
      "1197 loss: tensor(1.1623) acc: 0.36\n",
      "1198 loss: tensor(1.1622) acc: 0.36\n",
      "1199 loss: tensor(1.1621) acc: 0.36\n",
      "1200 loss: tensor(1.1619) acc: 0.36\n",
      "1201 loss: tensor(1.1618) acc: 0.36\n",
      "1202 loss: tensor(1.1617) acc: 0.36\n",
      "1203 loss: tensor(1.1616) acc: 0.36\n",
      "1204 loss: tensor(1.1615) acc: 0.36\n",
      "1205 loss: tensor(1.1614) acc: 0.36\n",
      "1206 loss: tensor(1.1613) acc: 0.36\n",
      "1207 loss: tensor(1.1612) acc: 0.36\n",
      "1208 loss: tensor(1.1611) acc: 0.36\n",
      "1209 loss: tensor(1.1609) acc: 0.36\n",
      "1210 loss: tensor(1.1608) acc: 0.36\n",
      "1211 loss: tensor(1.1607) acc: 0.36\n",
      "1212 loss: tensor(1.1606) acc: 0.36\n",
      "1213 loss: tensor(1.1605) acc: 0.36\n",
      "1214 loss: tensor(1.1604) acc: 0.36\n",
      "1215 loss: tensor(1.1603) acc: 0.36\n",
      "1216 loss: tensor(1.1602) acc: 0.36\n",
      "1217 loss: tensor(1.1601) acc: 0.36\n",
      "1218 loss: tensor(1.1599) acc: 0.36\n",
      "1219 loss: tensor(1.1598) acc: 0.36\n",
      "1220 loss: tensor(1.1597) acc: 0.36\n",
      "1221 loss: tensor(1.1596) acc: 0.36666666666666664\n",
      "1222 loss: tensor(1.1595) acc: 0.36666666666666664\n",
      "1223 loss: tensor(1.1594) acc: 0.36666666666666664\n",
      "1224 loss: tensor(1.1593) acc: 0.36666666666666664\n",
      "1225 loss: tensor(1.1592) acc: 0.36666666666666664\n",
      "1226 loss: tensor(1.1591) acc: 0.36666666666666664\n",
      "1227 loss: tensor(1.1590) acc: 0.36666666666666664\n",
      "1228 loss: tensor(1.1588) acc: 0.36666666666666664\n",
      "1229 loss: tensor(1.1587) acc: 0.36666666666666664\n",
      "1230 loss: tensor(1.1586) acc: 0.36666666666666664\n",
      "1231 loss: tensor(1.1585) acc: 0.36666666666666664\n",
      "1232 loss: tensor(1.1584) acc: 0.36666666666666664\n",
      "1233 loss: tensor(1.1583) acc: 0.36666666666666664\n",
      "1234 loss: tensor(1.1582) acc: 0.36666666666666664\n",
      "1235 loss: tensor(1.1581) acc: 0.36666666666666664\n",
      "1236 loss: tensor(1.1580) acc: 0.36666666666666664\n",
      "1237 loss: tensor(1.1579) acc: 0.36666666666666664\n",
      "1238 loss: tensor(1.1577) acc: 0.36666666666666664\n",
      "1239 loss: tensor(1.1576) acc: 0.36666666666666664\n",
      "1240 loss: tensor(1.1575) acc: 0.36666666666666664\n",
      "1241 loss: tensor(1.1574) acc: 0.36666666666666664\n",
      "1242 loss: tensor(1.1573) acc: 0.36666666666666664\n",
      "1243 loss: tensor(1.1572) acc: 0.36666666666666664\n",
      "1244 loss: tensor(1.1571) acc: 0.36666666666666664\n",
      "1245 loss: tensor(1.1570) acc: 0.36666666666666664\n",
      "1246 loss: tensor(1.1569) acc: 0.36666666666666664\n",
      "1247 loss: tensor(1.1568) acc: 0.36666666666666664\n",
      "1248 loss: tensor(1.1567) acc: 0.36666666666666664\n",
      "1249 loss: tensor(1.1566) acc: 0.36666666666666664\n",
      "1250 loss: tensor(1.1564) acc: 0.36666666666666664\n",
      "1251 loss: tensor(1.1563) acc: 0.36666666666666664\n",
      "1252 loss: tensor(1.1562) acc: 0.36666666666666664\n",
      "1253 loss: tensor(1.1561) acc: 0.36666666666666664\n",
      "1254 loss: tensor(1.1560) acc: 0.36666666666666664\n",
      "1255 loss: tensor(1.1559) acc: 0.36666666666666664\n",
      "1256 loss: tensor(1.1558) acc: 0.36666666666666664\n",
      "1257 loss: tensor(1.1557) acc: 0.36666666666666664\n",
      "1258 loss: tensor(1.1556) acc: 0.36666666666666664\n",
      "1259 loss: tensor(1.1555) acc: 0.36666666666666664\n",
      "1260 loss: tensor(1.1554) acc: 0.36666666666666664\n",
      "1261 loss: tensor(1.1553) acc: 0.37333333333333335\n",
      "1262 loss: tensor(1.1552) acc: 0.37333333333333335\n",
      "1263 loss: tensor(1.1550) acc: 0.37333333333333335\n",
      "1264 loss: tensor(1.1549) acc: 0.37333333333333335\n",
      "1265 loss: tensor(1.1548) acc: 0.37333333333333335\n",
      "1266 loss: tensor(1.1547) acc: 0.37333333333333335\n",
      "1267 loss: tensor(1.1546) acc: 0.37333333333333335\n",
      "1268 loss: tensor(1.1545) acc: 0.37333333333333335\n",
      "1269 loss: tensor(1.1544) acc: 0.37333333333333335\n",
      "1270 loss: tensor(1.1543) acc: 0.37333333333333335\n",
      "1271 loss: tensor(1.1542) acc: 0.37333333333333335\n",
      "1272 loss: tensor(1.1541) acc: 0.37333333333333335\n",
      "1273 loss: tensor(1.1540) acc: 0.37333333333333335\n",
      "1274 loss: tensor(1.1539) acc: 0.37333333333333335\n",
      "1275 loss: tensor(1.1538) acc: 0.37333333333333335\n",
      "1276 loss: tensor(1.1537) acc: 0.37333333333333335\n",
      "1277 loss: tensor(1.1536) acc: 0.37333333333333335\n",
      "1278 loss: tensor(1.1535) acc: 0.37333333333333335\n",
      "1279 loss: tensor(1.1533) acc: 0.37333333333333335\n",
      "1280 loss: tensor(1.1532) acc: 0.37333333333333335\n",
      "1281 loss: tensor(1.1531) acc: 0.37333333333333335\n",
      "1282 loss: tensor(1.1530) acc: 0.37333333333333335\n",
      "1283 loss: tensor(1.1529) acc: 0.37333333333333335\n",
      "1284 loss: tensor(1.1528) acc: 0.37333333333333335\n",
      "1285 loss: tensor(1.1527) acc: 0.37333333333333335\n",
      "1286 loss: tensor(1.1526) acc: 0.37333333333333335\n",
      "1287 loss: tensor(1.1525) acc: 0.37333333333333335\n",
      "1288 loss: tensor(1.1524) acc: 0.37333333333333335\n",
      "1289 loss: tensor(1.1523) acc: 0.37333333333333335\n",
      "1290 loss: tensor(1.1522) acc: 0.37333333333333335\n",
      "1291 loss: tensor(1.1521) acc: 0.37333333333333335\n",
      "1292 loss: tensor(1.1520) acc: 0.37333333333333335\n",
      "1293 loss: tensor(1.1519) acc: 0.37333333333333335\n",
      "1294 loss: tensor(1.1518) acc: 0.37333333333333335\n",
      "1295 loss: tensor(1.1517) acc: 0.37333333333333335\n",
      "1296 loss: tensor(1.1516) acc: 0.37333333333333335\n",
      "1297 loss: tensor(1.1515) acc: 0.37333333333333335\n",
      "1298 loss: tensor(1.1513) acc: 0.37333333333333335\n",
      "1299 loss: tensor(1.1512) acc: 0.37333333333333335\n",
      "1300 loss: tensor(1.1511) acc: 0.36666666666666664\n",
      "1301 loss: tensor(1.1510) acc: 0.37333333333333335\n",
      "1302 loss: tensor(1.1509) acc: 0.37333333333333335\n",
      "1303 loss: tensor(1.1508) acc: 0.37333333333333335\n",
      "1304 loss: tensor(1.1507) acc: 0.37333333333333335\n",
      "1305 loss: tensor(1.1506) acc: 0.37333333333333335\n",
      "1306 loss: tensor(1.1505) acc: 0.37333333333333335\n",
      "1307 loss: tensor(1.1504) acc: 0.37333333333333335\n",
      "1308 loss: tensor(1.1503) acc: 0.37333333333333335\n",
      "1309 loss: tensor(1.1502) acc: 0.37333333333333335\n",
      "1310 loss: tensor(1.1501) acc: 0.37333333333333335\n",
      "1311 loss: tensor(1.1500) acc: 0.37333333333333335\n",
      "1312 loss: tensor(1.1499) acc: 0.37333333333333335\n",
      "1313 loss: tensor(1.1498) acc: 0.37333333333333335\n",
      "1314 loss: tensor(1.1497) acc: 0.37333333333333335\n",
      "1315 loss: tensor(1.1496) acc: 0.37333333333333335\n",
      "1316 loss: tensor(1.1495) acc: 0.37333333333333335\n",
      "1317 loss: tensor(1.1494) acc: 0.37333333333333335\n",
      "1318 loss: tensor(1.1493) acc: 0.37333333333333335\n",
      "1319 loss: tensor(1.1492) acc: 0.37333333333333335\n",
      "1320 loss: tensor(1.1491) acc: 0.37333333333333335\n",
      "1321 loss: tensor(1.1490) acc: 0.37333333333333335\n",
      "1322 loss: tensor(1.1489) acc: 0.37333333333333335\n",
      "1323 loss: tensor(1.1488) acc: 0.37333333333333335\n",
      "1324 loss: tensor(1.1487) acc: 0.37333333333333335\n",
      "1325 loss: tensor(1.1486) acc: 0.37333333333333335\n",
      "1326 loss: tensor(1.1485) acc: 0.37333333333333335\n",
      "1327 loss: tensor(1.1484) acc: 0.37333333333333335\n",
      "1328 loss: tensor(1.1483) acc: 0.37333333333333335\n",
      "1329 loss: tensor(1.1482) acc: 0.37333333333333335\n",
      "1330 loss: tensor(1.1480) acc: 0.37333333333333335\n",
      "1331 loss: tensor(1.1479) acc: 0.37333333333333335\n",
      "1332 loss: tensor(1.1478) acc: 0.37333333333333335\n",
      "1333 loss: tensor(1.1477) acc: 0.37333333333333335\n",
      "1334 loss: tensor(1.1476) acc: 0.37333333333333335\n",
      "1335 loss: tensor(1.1475) acc: 0.37333333333333335\n",
      "1336 loss: tensor(1.1474) acc: 0.37333333333333335\n",
      "1337 loss: tensor(1.1473) acc: 0.37333333333333335\n",
      "1338 loss: tensor(1.1472) acc: 0.37333333333333335\n",
      "1339 loss: tensor(1.1471) acc: 0.37333333333333335\n",
      "1340 loss: tensor(1.1470) acc: 0.37333333333333335\n",
      "1341 loss: tensor(1.1469) acc: 0.37333333333333335\n",
      "1342 loss: tensor(1.1468) acc: 0.37333333333333335\n",
      "1343 loss: tensor(1.1467) acc: 0.37333333333333335\n",
      "1344 loss: tensor(1.1466) acc: 0.37333333333333335\n",
      "1345 loss: tensor(1.1465) acc: 0.37333333333333335\n",
      "1346 loss: tensor(1.1464) acc: 0.37333333333333335\n",
      "1347 loss: tensor(1.1463) acc: 0.37333333333333335\n",
      "1348 loss: tensor(1.1462) acc: 0.37333333333333335\n",
      "1349 loss: tensor(1.1461) acc: 0.37333333333333335\n",
      "1350 loss: tensor(1.1460) acc: 0.37333333333333335\n",
      "1351 loss: tensor(1.1459) acc: 0.37333333333333335\n",
      "1352 loss: tensor(1.1458) acc: 0.37333333333333335\n",
      "1353 loss: tensor(1.1457) acc: 0.37333333333333335\n",
      "1354 loss: tensor(1.1456) acc: 0.37333333333333335\n",
      "1355 loss: tensor(1.1455) acc: 0.37333333333333335\n",
      "1356 loss: tensor(1.1454) acc: 0.37333333333333335\n",
      "1357 loss: tensor(1.1453) acc: 0.37333333333333335\n",
      "1358 loss: tensor(1.1452) acc: 0.37333333333333335\n",
      "1359 loss: tensor(1.1451) acc: 0.37333333333333335\n",
      "1360 loss: tensor(1.1450) acc: 0.37333333333333335\n",
      "1361 loss: tensor(1.1449) acc: 0.37333333333333335\n",
      "1362 loss: tensor(1.1448) acc: 0.37333333333333335\n",
      "1363 loss: tensor(1.1447) acc: 0.37333333333333335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364 loss: tensor(1.1446) acc: 0.37333333333333335\n",
      "1365 loss: tensor(1.1445) acc: 0.37333333333333335\n",
      "1366 loss: tensor(1.1444) acc: 0.37333333333333335\n",
      "1367 loss: tensor(1.1443) acc: 0.37333333333333335\n",
      "1368 loss: tensor(1.1442) acc: 0.37333333333333335\n",
      "1369 loss: tensor(1.1441) acc: 0.37333333333333335\n",
      "1370 loss: tensor(1.1440) acc: 0.37333333333333335\n",
      "1371 loss: tensor(1.1439) acc: 0.37333333333333335\n",
      "1372 loss: tensor(1.1438) acc: 0.37333333333333335\n",
      "1373 loss: tensor(1.1437) acc: 0.37333333333333335\n",
      "1374 loss: tensor(1.1436) acc: 0.37333333333333335\n",
      "1375 loss: tensor(1.1435) acc: 0.37333333333333335\n",
      "1376 loss: tensor(1.1434) acc: 0.37333333333333335\n",
      "1377 loss: tensor(1.1433) acc: 0.37333333333333335\n",
      "1378 loss: tensor(1.1432) acc: 0.37333333333333335\n",
      "1379 loss: tensor(1.1431) acc: 0.37333333333333335\n",
      "1380 loss: tensor(1.1430) acc: 0.37333333333333335\n",
      "1381 loss: tensor(1.1429) acc: 0.37333333333333335\n",
      "1382 loss: tensor(1.1428) acc: 0.37333333333333335\n",
      "1383 loss: tensor(1.1427) acc: 0.37333333333333335\n",
      "1384 loss: tensor(1.1426) acc: 0.37333333333333335\n",
      "1385 loss: tensor(1.1425) acc: 0.37333333333333335\n",
      "1386 loss: tensor(1.1425) acc: 0.37333333333333335\n",
      "1387 loss: tensor(1.1424) acc: 0.37333333333333335\n",
      "1388 loss: tensor(1.1423) acc: 0.37333333333333335\n",
      "1389 loss: tensor(1.1422) acc: 0.37333333333333335\n",
      "1390 loss: tensor(1.1421) acc: 0.37333333333333335\n",
      "1391 loss: tensor(1.1420) acc: 0.37333333333333335\n",
      "1392 loss: tensor(1.1419) acc: 0.37333333333333335\n",
      "1393 loss: tensor(1.1418) acc: 0.37333333333333335\n",
      "1394 loss: tensor(1.1417) acc: 0.37333333333333335\n",
      "1395 loss: tensor(1.1416) acc: 0.37333333333333335\n",
      "1396 loss: tensor(1.1415) acc: 0.37333333333333335\n",
      "1397 loss: tensor(1.1414) acc: 0.37333333333333335\n",
      "1398 loss: tensor(1.1413) acc: 0.37333333333333335\n",
      "1399 loss: tensor(1.1412) acc: 0.37333333333333335\n",
      "1400 loss: tensor(1.1411) acc: 0.37333333333333335\n",
      "1401 loss: tensor(1.1410) acc: 0.37333333333333335\n",
      "1402 loss: tensor(1.1409) acc: 0.37333333333333335\n",
      "1403 loss: tensor(1.1408) acc: 0.37333333333333335\n",
      "1404 loss: tensor(1.1407) acc: 0.37333333333333335\n",
      "1405 loss: tensor(1.1406) acc: 0.37333333333333335\n",
      "1406 loss: tensor(1.1405) acc: 0.37333333333333335\n",
      "1407 loss: tensor(1.1404) acc: 0.37333333333333335\n",
      "1408 loss: tensor(1.1403) acc: 0.37333333333333335\n",
      "1409 loss: tensor(1.1402) acc: 0.37333333333333335\n",
      "1410 loss: tensor(1.1401) acc: 0.37333333333333335\n",
      "1411 loss: tensor(1.1400) acc: 0.37333333333333335\n",
      "1412 loss: tensor(1.1399) acc: 0.37333333333333335\n",
      "1413 loss: tensor(1.1398) acc: 0.37333333333333335\n",
      "1414 loss: tensor(1.1397) acc: 0.37333333333333335\n",
      "1415 loss: tensor(1.1396) acc: 0.37333333333333335\n",
      "1416 loss: tensor(1.1395) acc: 0.37333333333333335\n",
      "1417 loss: tensor(1.1394) acc: 0.37333333333333335\n",
      "1418 loss: tensor(1.1394) acc: 0.37333333333333335\n",
      "1419 loss: tensor(1.1393) acc: 0.37333333333333335\n",
      "1420 loss: tensor(1.1392) acc: 0.37333333333333335\n",
      "1421 loss: tensor(1.1391) acc: 0.37333333333333335\n",
      "1422 loss: tensor(1.1390) acc: 0.37333333333333335\n",
      "1423 loss: tensor(1.1389) acc: 0.37333333333333335\n",
      "1424 loss: tensor(1.1388) acc: 0.37333333333333335\n",
      "1425 loss: tensor(1.1387) acc: 0.37333333333333335\n",
      "1426 loss: tensor(1.1386) acc: 0.37333333333333335\n",
      "1427 loss: tensor(1.1385) acc: 0.37333333333333335\n",
      "1428 loss: tensor(1.1384) acc: 0.37333333333333335\n",
      "1429 loss: tensor(1.1383) acc: 0.37333333333333335\n",
      "1430 loss: tensor(1.1382) acc: 0.37333333333333335\n",
      "1431 loss: tensor(1.1381) acc: 0.37333333333333335\n",
      "1432 loss: tensor(1.1380) acc: 0.37333333333333335\n",
      "1433 loss: tensor(1.1379) acc: 0.37333333333333335\n",
      "1434 loss: tensor(1.1378) acc: 0.37333333333333335\n",
      "1435 loss: tensor(1.1377) acc: 0.37333333333333335\n",
      "1436 loss: tensor(1.1376) acc: 0.37333333333333335\n",
      "1437 loss: tensor(1.1375) acc: 0.37333333333333335\n",
      "1438 loss: tensor(1.1375) acc: 0.37333333333333335\n",
      "1439 loss: tensor(1.1374) acc: 0.37333333333333335\n",
      "1440 loss: tensor(1.1373) acc: 0.37333333333333335\n",
      "1441 loss: tensor(1.1372) acc: 0.37333333333333335\n",
      "1442 loss: tensor(1.1371) acc: 0.37333333333333335\n",
      "1443 loss: tensor(1.1370) acc: 0.37333333333333335\n",
      "1444 loss: tensor(1.1369) acc: 0.37333333333333335\n",
      "1445 loss: tensor(1.1368) acc: 0.37333333333333335\n",
      "1446 loss: tensor(1.1367) acc: 0.37333333333333335\n",
      "1447 loss: tensor(1.1366) acc: 0.37333333333333335\n",
      "1448 loss: tensor(1.1365) acc: 0.37333333333333335\n",
      "1449 loss: tensor(1.1364) acc: 0.38\n",
      "1450 loss: tensor(1.1363) acc: 0.38\n",
      "1451 loss: tensor(1.1362) acc: 0.38\n",
      "1452 loss: tensor(1.1361) acc: 0.38\n",
      "1453 loss: tensor(1.1360) acc: 0.38\n",
      "1454 loss: tensor(1.1359) acc: 0.38\n",
      "1455 loss: tensor(1.1359) acc: 0.38\n",
      "1456 loss: tensor(1.1358) acc: 0.38\n",
      "1457 loss: tensor(1.1357) acc: 0.38\n",
      "1458 loss: tensor(1.1356) acc: 0.38\n",
      "1459 loss: tensor(1.1355) acc: 0.38\n",
      "1460 loss: tensor(1.1354) acc: 0.38\n",
      "1461 loss: tensor(1.1353) acc: 0.38\n",
      "1462 loss: tensor(1.1352) acc: 0.38\n",
      "1463 loss: tensor(1.1351) acc: 0.38\n",
      "1464 loss: tensor(1.1350) acc: 0.38\n",
      "1465 loss: tensor(1.1349) acc: 0.38\n",
      "1466 loss: tensor(1.1348) acc: 0.38\n",
      "1467 loss: tensor(1.1347) acc: 0.38\n",
      "1468 loss: tensor(1.1346) acc: 0.38\n",
      "1469 loss: tensor(1.1346) acc: 0.38\n",
      "1470 loss: tensor(1.1345) acc: 0.38\n",
      "1471 loss: tensor(1.1344) acc: 0.38\n",
      "1472 loss: tensor(1.1343) acc: 0.38\n",
      "1473 loss: tensor(1.1342) acc: 0.38666666666666666\n",
      "1474 loss: tensor(1.1341) acc: 0.38666666666666666\n",
      "1475 loss: tensor(1.1340) acc: 0.38666666666666666\n",
      "1476 loss: tensor(1.1339) acc: 0.38666666666666666\n",
      "1477 loss: tensor(1.1338) acc: 0.38666666666666666\n",
      "1478 loss: tensor(1.1337) acc: 0.38666666666666666\n",
      "1479 loss: tensor(1.1336) acc: 0.38666666666666666\n",
      "1480 loss: tensor(1.1335) acc: 0.38666666666666666\n",
      "1481 loss: tensor(1.1335) acc: 0.38666666666666666\n",
      "1482 loss: tensor(1.1334) acc: 0.38666666666666666\n",
      "1483 loss: tensor(1.1333) acc: 0.38666666666666666\n",
      "1484 loss: tensor(1.1332) acc: 0.38666666666666666\n",
      "1485 loss: tensor(1.1331) acc: 0.38666666666666666\n",
      "1486 loss: tensor(1.1330) acc: 0.38666666666666666\n",
      "1487 loss: tensor(1.1329) acc: 0.38666666666666666\n",
      "1488 loss: tensor(1.1328) acc: 0.38666666666666666\n",
      "1489 loss: tensor(1.1327) acc: 0.38666666666666666\n",
      "1490 loss: tensor(1.1326) acc: 0.38666666666666666\n",
      "1491 loss: tensor(1.1325) acc: 0.38666666666666666\n",
      "1492 loss: tensor(1.1324) acc: 0.38666666666666666\n",
      "1493 loss: tensor(1.1324) acc: 0.38666666666666666\n",
      "1494 loss: tensor(1.1323) acc: 0.38666666666666666\n",
      "1495 loss: tensor(1.1322) acc: 0.38666666666666666\n",
      "1496 loss: tensor(1.1321) acc: 0.3933333333333333\n",
      "1497 loss: tensor(1.1320) acc: 0.3933333333333333\n",
      "1498 loss: tensor(1.1319) acc: 0.3933333333333333\n",
      "1499 loss: tensor(1.1318) acc: 0.3933333333333333\n",
      "1500 loss: tensor(1.1317) acc: 0.3933333333333333\n",
      "1501 loss: tensor(1.1316) acc: 0.3933333333333333\n",
      "1502 loss: tensor(1.1315) acc: 0.3933333333333333\n",
      "1503 loss: tensor(1.1315) acc: 0.3933333333333333\n",
      "1504 loss: tensor(1.1314) acc: 0.3933333333333333\n",
      "1505 loss: tensor(1.1313) acc: 0.3933333333333333\n",
      "1506 loss: tensor(1.1312) acc: 0.3933333333333333\n",
      "1507 loss: tensor(1.1311) acc: 0.3933333333333333\n",
      "1508 loss: tensor(1.1310) acc: 0.3933333333333333\n",
      "1509 loss: tensor(1.1309) acc: 0.3933333333333333\n",
      "1510 loss: tensor(1.1308) acc: 0.3933333333333333\n",
      "1511 loss: tensor(1.1307) acc: 0.3933333333333333\n",
      "1512 loss: tensor(1.1306) acc: 0.3933333333333333\n",
      "1513 loss: tensor(1.1306) acc: 0.3933333333333333\n",
      "1514 loss: tensor(1.1305) acc: 0.3933333333333333\n",
      "1515 loss: tensor(1.1304) acc: 0.3933333333333333\n",
      "1516 loss: tensor(1.1303) acc: 0.3933333333333333\n",
      "1517 loss: tensor(1.1302) acc: 0.3933333333333333\n",
      "1518 loss: tensor(1.1301) acc: 0.3933333333333333\n",
      "1519 loss: tensor(1.1300) acc: 0.3933333333333333\n",
      "1520 loss: tensor(1.1299) acc: 0.3933333333333333\n",
      "1521 loss: tensor(1.1298) acc: 0.3933333333333333\n",
      "1522 loss: tensor(1.1297) acc: 0.3933333333333333\n",
      "1523 loss: tensor(1.1297) acc: 0.3933333333333333\n",
      "1524 loss: tensor(1.1296) acc: 0.3933333333333333\n",
      "1525 loss: tensor(1.1295) acc: 0.3933333333333333\n",
      "1526 loss: tensor(1.1294) acc: 0.3933333333333333\n",
      "1527 loss: tensor(1.1293) acc: 0.3933333333333333\n",
      "1528 loss: tensor(1.1292) acc: 0.3933333333333333\n",
      "1529 loss: tensor(1.1291) acc: 0.3933333333333333\n",
      "1530 loss: tensor(1.1290) acc: 0.3933333333333333\n",
      "1531 loss: tensor(1.1289) acc: 0.38666666666666666\n",
      "1532 loss: tensor(1.1289) acc: 0.38666666666666666\n",
      "1533 loss: tensor(1.1288) acc: 0.38666666666666666\n",
      "1534 loss: tensor(1.1287) acc: 0.38666666666666666\n",
      "1535 loss: tensor(1.1286) acc: 0.38666666666666666\n",
      "1536 loss: tensor(1.1285) acc: 0.38666666666666666\n",
      "1537 loss: tensor(1.1284) acc: 0.38666666666666666\n",
      "1538 loss: tensor(1.1283) acc: 0.38666666666666666\n",
      "1539 loss: tensor(1.1282) acc: 0.38666666666666666\n",
      "1540 loss: tensor(1.1282) acc: 0.38666666666666666\n",
      "1541 loss: tensor(1.1281) acc: 0.38666666666666666\n",
      "1542 loss: tensor(1.1280) acc: 0.38666666666666666\n",
      "1543 loss: tensor(1.1279) acc: 0.38666666666666666\n",
      "1544 loss: tensor(1.1278) acc: 0.38666666666666666\n",
      "1545 loss: tensor(1.1277) acc: 0.38666666666666666\n",
      "1546 loss: tensor(1.1276) acc: 0.38666666666666666\n",
      "1547 loss: tensor(1.1275) acc: 0.38666666666666666\n",
      "1548 loss: tensor(1.1275) acc: 0.38666666666666666\n",
      "1549 loss: tensor(1.1274) acc: 0.38666666666666666\n",
      "1550 loss: tensor(1.1273) acc: 0.38666666666666666\n",
      "1551 loss: tensor(1.1272) acc: 0.38666666666666666\n",
      "1552 loss: tensor(1.1271) acc: 0.38666666666666666\n",
      "1553 loss: tensor(1.1270) acc: 0.38666666666666666\n",
      "1554 loss: tensor(1.1269) acc: 0.38666666666666666\n",
      "1555 loss: tensor(1.1268) acc: 0.38666666666666666\n",
      "1556 loss: tensor(1.1268) acc: 0.38666666666666666\n",
      "1557 loss: tensor(1.1267) acc: 0.3933333333333333\n",
      "1558 loss: tensor(1.1266) acc: 0.3933333333333333\n",
      "1559 loss: tensor(1.1265) acc: 0.3933333333333333\n",
      "1560 loss: tensor(1.1264) acc: 0.3933333333333333\n",
      "1561 loss: tensor(1.1263) acc: 0.3933333333333333\n",
      "1562 loss: tensor(1.1262) acc: 0.3933333333333333\n",
      "1563 loss: tensor(1.1261) acc: 0.3933333333333333\n",
      "1564 loss: tensor(1.1261) acc: 0.3933333333333333\n",
      "1565 loss: tensor(1.1260) acc: 0.3933333333333333\n",
      "1566 loss: tensor(1.1259) acc: 0.3933333333333333\n",
      "1567 loss: tensor(1.1258) acc: 0.3933333333333333\n",
      "1568 loss: tensor(1.1257) acc: 0.3933333333333333\n",
      "1569 loss: tensor(1.1256) acc: 0.3933333333333333\n",
      "1570 loss: tensor(1.1255) acc: 0.3933333333333333\n",
      "1571 loss: tensor(1.1255) acc: 0.3933333333333333\n",
      "1572 loss: tensor(1.1254) acc: 0.3933333333333333\n",
      "1573 loss: tensor(1.1253) acc: 0.3933333333333333\n",
      "1574 loss: tensor(1.1252) acc: 0.3933333333333333\n",
      "1575 loss: tensor(1.1251) acc: 0.3933333333333333\n",
      "1576 loss: tensor(1.1250) acc: 0.3933333333333333\n",
      "1577 loss: tensor(1.1249) acc: 0.3933333333333333\n",
      "1578 loss: tensor(1.1249) acc: 0.3933333333333333\n",
      "1579 loss: tensor(1.1248) acc: 0.3933333333333333\n",
      "1580 loss: tensor(1.1247) acc: 0.3933333333333333\n",
      "1581 loss: tensor(1.1246) acc: 0.3933333333333333\n",
      "1582 loss: tensor(1.1245) acc: 0.3933333333333333\n",
      "1583 loss: tensor(1.1244) acc: 0.3933333333333333\n",
      "1584 loss: tensor(1.1243) acc: 0.3933333333333333\n",
      "1585 loss: tensor(1.1243) acc: 0.38666666666666666\n",
      "1586 loss: tensor(1.1242) acc: 0.38666666666666666\n",
      "1587 loss: tensor(1.1241) acc: 0.38666666666666666\n",
      "1588 loss: tensor(1.1240) acc: 0.38666666666666666\n",
      "1589 loss: tensor(1.1239) acc: 0.38666666666666666\n",
      "1590 loss: tensor(1.1238) acc: 0.38666666666666666\n",
      "1591 loss: tensor(1.1237) acc: 0.38666666666666666\n",
      "1592 loss: tensor(1.1237) acc: 0.38666666666666666\n",
      "1593 loss: tensor(1.1236) acc: 0.38666666666666666\n",
      "1594 loss: tensor(1.1235) acc: 0.38666666666666666\n",
      "1595 loss: tensor(1.1234) acc: 0.38666666666666666\n",
      "1596 loss: tensor(1.1233) acc: 0.38666666666666666\n",
      "1597 loss: tensor(1.1232) acc: 0.38666666666666666\n",
      "1598 loss: tensor(1.1231) acc: 0.38666666666666666\n",
      "1599 loss: tensor(1.1231) acc: 0.38666666666666666\n",
      "1600 loss: tensor(1.1230) acc: 0.38666666666666666\n",
      "1601 loss: tensor(1.1229) acc: 0.38666666666666666\n",
      "1602 loss: tensor(1.1228) acc: 0.38666666666666666\n",
      "1603 loss: tensor(1.1227) acc: 0.38666666666666666\n",
      "1604 loss: tensor(1.1226) acc: 0.38666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605 loss: tensor(1.1226) acc: 0.38666666666666666\n",
      "1606 loss: tensor(1.1225) acc: 0.38666666666666666\n",
      "1607 loss: tensor(1.1224) acc: 0.38666666666666666\n",
      "1608 loss: tensor(1.1223) acc: 0.38666666666666666\n",
      "1609 loss: tensor(1.1222) acc: 0.38666666666666666\n",
      "1610 loss: tensor(1.1221) acc: 0.38666666666666666\n",
      "1611 loss: tensor(1.1221) acc: 0.38666666666666666\n",
      "1612 loss: tensor(1.1220) acc: 0.38666666666666666\n",
      "1613 loss: tensor(1.1219) acc: 0.38666666666666666\n",
      "1614 loss: tensor(1.1218) acc: 0.38666666666666666\n",
      "1615 loss: tensor(1.1217) acc: 0.38666666666666666\n",
      "1616 loss: tensor(1.1216) acc: 0.38666666666666666\n",
      "1617 loss: tensor(1.1215) acc: 0.38666666666666666\n",
      "1618 loss: tensor(1.1215) acc: 0.38666666666666666\n",
      "1619 loss: tensor(1.1214) acc: 0.38666666666666666\n",
      "1620 loss: tensor(1.1213) acc: 0.38666666666666666\n",
      "1621 loss: tensor(1.1212) acc: 0.38666666666666666\n",
      "1622 loss: tensor(1.1211) acc: 0.38666666666666666\n",
      "1623 loss: tensor(1.1210) acc: 0.38666666666666666\n",
      "1624 loss: tensor(1.1210) acc: 0.38666666666666666\n",
      "1625 loss: tensor(1.1209) acc: 0.38666666666666666\n",
      "1626 loss: tensor(1.1208) acc: 0.38666666666666666\n",
      "1627 loss: tensor(1.1207) acc: 0.38666666666666666\n",
      "1628 loss: tensor(1.1206) acc: 0.38666666666666666\n",
      "1629 loss: tensor(1.1205) acc: 0.38666666666666666\n",
      "1630 loss: tensor(1.1205) acc: 0.38666666666666666\n",
      "1631 loss: tensor(1.1204) acc: 0.38666666666666666\n",
      "1632 loss: tensor(1.1203) acc: 0.38666666666666666\n",
      "1633 loss: tensor(1.1202) acc: 0.38666666666666666\n",
      "1634 loss: tensor(1.1201) acc: 0.38666666666666666\n",
      "1635 loss: tensor(1.1201) acc: 0.38666666666666666\n",
      "1636 loss: tensor(1.1200) acc: 0.38666666666666666\n",
      "1637 loss: tensor(1.1199) acc: 0.38666666666666666\n",
      "1638 loss: tensor(1.1198) acc: 0.38666666666666666\n",
      "1639 loss: tensor(1.1197) acc: 0.38666666666666666\n",
      "1640 loss: tensor(1.1196) acc: 0.38666666666666666\n",
      "1641 loss: tensor(1.1196) acc: 0.38666666666666666\n",
      "1642 loss: tensor(1.1195) acc: 0.38666666666666666\n",
      "1643 loss: tensor(1.1194) acc: 0.38666666666666666\n",
      "1644 loss: tensor(1.1193) acc: 0.38666666666666666\n",
      "1645 loss: tensor(1.1192) acc: 0.38666666666666666\n",
      "1646 loss: tensor(1.1191) acc: 0.38666666666666666\n",
      "1647 loss: tensor(1.1191) acc: 0.38666666666666666\n",
      "1648 loss: tensor(1.1190) acc: 0.38666666666666666\n",
      "1649 loss: tensor(1.1189) acc: 0.38666666666666666\n",
      "1650 loss: tensor(1.1188) acc: 0.38666666666666666\n",
      "1651 loss: tensor(1.1187) acc: 0.38666666666666666\n",
      "1652 loss: tensor(1.1187) acc: 0.38666666666666666\n",
      "1653 loss: tensor(1.1186) acc: 0.38666666666666666\n",
      "1654 loss: tensor(1.1185) acc: 0.38666666666666666\n",
      "1655 loss: tensor(1.1184) acc: 0.38666666666666666\n",
      "1656 loss: tensor(1.1183) acc: 0.38666666666666666\n",
      "1657 loss: tensor(1.1182) acc: 0.38666666666666666\n",
      "1658 loss: tensor(1.1182) acc: 0.38666666666666666\n",
      "1659 loss: tensor(1.1181) acc: 0.38666666666666666\n",
      "1660 loss: tensor(1.1180) acc: 0.38666666666666666\n",
      "1661 loss: tensor(1.1179) acc: 0.38666666666666666\n",
      "1662 loss: tensor(1.1178) acc: 0.38666666666666666\n",
      "1663 loss: tensor(1.1178) acc: 0.38666666666666666\n",
      "1664 loss: tensor(1.1177) acc: 0.38666666666666666\n",
      "1665 loss: tensor(1.1176) acc: 0.38666666666666666\n",
      "1666 loss: tensor(1.1175) acc: 0.38666666666666666\n",
      "1667 loss: tensor(1.1174) acc: 0.38666666666666666\n",
      "1668 loss: tensor(1.1174) acc: 0.38666666666666666\n",
      "1669 loss: tensor(1.1173) acc: 0.38666666666666666\n",
      "1670 loss: tensor(1.1172) acc: 0.38666666666666666\n",
      "1671 loss: tensor(1.1171) acc: 0.38666666666666666\n",
      "1672 loss: tensor(1.1170) acc: 0.38666666666666666\n",
      "1673 loss: tensor(1.1169) acc: 0.38666666666666666\n",
      "1674 loss: tensor(1.1169) acc: 0.38666666666666666\n",
      "1675 loss: tensor(1.1168) acc: 0.38666666666666666\n",
      "1676 loss: tensor(1.1167) acc: 0.38666666666666666\n",
      "1677 loss: tensor(1.1166) acc: 0.38666666666666666\n",
      "1678 loss: tensor(1.1165) acc: 0.38666666666666666\n",
      "1679 loss: tensor(1.1165) acc: 0.38666666666666666\n",
      "1680 loss: tensor(1.1164) acc: 0.38666666666666666\n",
      "1681 loss: tensor(1.1163) acc: 0.38666666666666666\n",
      "1682 loss: tensor(1.1162) acc: 0.38666666666666666\n",
      "1683 loss: tensor(1.1161) acc: 0.38666666666666666\n",
      "1684 loss: tensor(1.1161) acc: 0.38666666666666666\n",
      "1685 loss: tensor(1.1160) acc: 0.38666666666666666\n",
      "1686 loss: tensor(1.1159) acc: 0.38666666666666666\n",
      "1687 loss: tensor(1.1158) acc: 0.38666666666666666\n",
      "1688 loss: tensor(1.1157) acc: 0.38666666666666666\n",
      "1689 loss: tensor(1.1157) acc: 0.38666666666666666\n",
      "1690 loss: tensor(1.1156) acc: 0.38666666666666666\n",
      "1691 loss: tensor(1.1155) acc: 0.38666666666666666\n",
      "1692 loss: tensor(1.1154) acc: 0.38666666666666666\n",
      "1693 loss: tensor(1.1153) acc: 0.38666666666666666\n",
      "1694 loss: tensor(1.1153) acc: 0.38666666666666666\n",
      "1695 loss: tensor(1.1152) acc: 0.38666666666666666\n",
      "1696 loss: tensor(1.1151) acc: 0.38666666666666666\n",
      "1697 loss: tensor(1.1150) acc: 0.38666666666666666\n",
      "1698 loss: tensor(1.1149) acc: 0.38666666666666666\n",
      "1699 loss: tensor(1.1149) acc: 0.38666666666666666\n",
      "1700 loss: tensor(1.1148) acc: 0.38666666666666666\n",
      "1701 loss: tensor(1.1147) acc: 0.38666666666666666\n",
      "1702 loss: tensor(1.1146) acc: 0.38666666666666666\n",
      "1703 loss: tensor(1.1145) acc: 0.38666666666666666\n",
      "1704 loss: tensor(1.1145) acc: 0.38666666666666666\n",
      "1705 loss: tensor(1.1144) acc: 0.38666666666666666\n",
      "1706 loss: tensor(1.1143) acc: 0.38666666666666666\n",
      "1707 loss: tensor(1.1142) acc: 0.38666666666666666\n",
      "1708 loss: tensor(1.1141) acc: 0.38666666666666666\n",
      "1709 loss: tensor(1.1141) acc: 0.38666666666666666\n",
      "1710 loss: tensor(1.1140) acc: 0.38666666666666666\n",
      "1711 loss: tensor(1.1139) acc: 0.38666666666666666\n",
      "1712 loss: tensor(1.1138) acc: 0.38666666666666666\n",
      "1713 loss: tensor(1.1138) acc: 0.38666666666666666\n",
      "1714 loss: tensor(1.1137) acc: 0.38666666666666666\n",
      "1715 loss: tensor(1.1136) acc: 0.38666666666666666\n",
      "1716 loss: tensor(1.1135) acc: 0.38666666666666666\n",
      "1717 loss: tensor(1.1134) acc: 0.38666666666666666\n",
      "1718 loss: tensor(1.1134) acc: 0.38666666666666666\n",
      "1719 loss: tensor(1.1133) acc: 0.38666666666666666\n",
      "1720 loss: tensor(1.1132) acc: 0.38666666666666666\n",
      "1721 loss: tensor(1.1131) acc: 0.38666666666666666\n",
      "1722 loss: tensor(1.1130) acc: 0.38666666666666666\n",
      "1723 loss: tensor(1.1130) acc: 0.38666666666666666\n",
      "1724 loss: tensor(1.1129) acc: 0.38666666666666666\n",
      "1725 loss: tensor(1.1128) acc: 0.38666666666666666\n",
      "1726 loss: tensor(1.1127) acc: 0.38666666666666666\n",
      "1727 loss: tensor(1.1127) acc: 0.38666666666666666\n",
      "1728 loss: tensor(1.1126) acc: 0.38666666666666666\n",
      "1729 loss: tensor(1.1125) acc: 0.38666666666666666\n",
      "1730 loss: tensor(1.1124) acc: 0.38666666666666666\n",
      "1731 loss: tensor(1.1123) acc: 0.38666666666666666\n",
      "1732 loss: tensor(1.1123) acc: 0.38666666666666666\n",
      "1733 loss: tensor(1.1122) acc: 0.38666666666666666\n",
      "1734 loss: tensor(1.1121) acc: 0.38666666666666666\n",
      "1735 loss: tensor(1.1120) acc: 0.38666666666666666\n",
      "1736 loss: tensor(1.1120) acc: 0.38666666666666666\n",
      "1737 loss: tensor(1.1119) acc: 0.38666666666666666\n",
      "1738 loss: tensor(1.1118) acc: 0.38666666666666666\n",
      "1739 loss: tensor(1.1117) acc: 0.38666666666666666\n",
      "1740 loss: tensor(1.1116) acc: 0.38666666666666666\n",
      "1741 loss: tensor(1.1116) acc: 0.38666666666666666\n",
      "1742 loss: tensor(1.1115) acc: 0.38666666666666666\n",
      "1743 loss: tensor(1.1114) acc: 0.38666666666666666\n",
      "1744 loss: tensor(1.1113) acc: 0.38666666666666666\n",
      "1745 loss: tensor(1.1113) acc: 0.38666666666666666\n",
      "1746 loss: tensor(1.1112) acc: 0.38666666666666666\n",
      "1747 loss: tensor(1.1111) acc: 0.38666666666666666\n",
      "1748 loss: tensor(1.1110) acc: 0.38666666666666666\n",
      "1749 loss: tensor(1.1109) acc: 0.38666666666666666\n",
      "1750 loss: tensor(1.1109) acc: 0.38666666666666666\n",
      "1751 loss: tensor(1.1108) acc: 0.38666666666666666\n",
      "1752 loss: tensor(1.1107) acc: 0.38666666666666666\n",
      "1753 loss: tensor(1.1106) acc: 0.38666666666666666\n",
      "1754 loss: tensor(1.1106) acc: 0.38666666666666666\n",
      "1755 loss: tensor(1.1105) acc: 0.38666666666666666\n",
      "1756 loss: tensor(1.1104) acc: 0.38666666666666666\n",
      "1757 loss: tensor(1.1103) acc: 0.38666666666666666\n",
      "1758 loss: tensor(1.1102) acc: 0.38666666666666666\n",
      "1759 loss: tensor(1.1102) acc: 0.38666666666666666\n",
      "1760 loss: tensor(1.1101) acc: 0.38666666666666666\n",
      "1761 loss: tensor(1.1100) acc: 0.38666666666666666\n",
      "1762 loss: tensor(1.1099) acc: 0.38666666666666666\n",
      "1763 loss: tensor(1.1099) acc: 0.38666666666666666\n",
      "1764 loss: tensor(1.1098) acc: 0.38666666666666666\n",
      "1765 loss: tensor(1.1097) acc: 0.38666666666666666\n",
      "1766 loss: tensor(1.1096) acc: 0.38666666666666666\n",
      "1767 loss: tensor(1.1096) acc: 0.38666666666666666\n",
      "1768 loss: tensor(1.1095) acc: 0.38666666666666666\n",
      "1769 loss: tensor(1.1094) acc: 0.38666666666666666\n",
      "1770 loss: tensor(1.1093) acc: 0.38666666666666666\n",
      "1771 loss: tensor(1.1093) acc: 0.38666666666666666\n",
      "1772 loss: tensor(1.1092) acc: 0.38666666666666666\n",
      "1773 loss: tensor(1.1091) acc: 0.38666666666666666\n",
      "1774 loss: tensor(1.1090) acc: 0.38666666666666666\n",
      "1775 loss: tensor(1.1089) acc: 0.38666666666666666\n",
      "1776 loss: tensor(1.1089) acc: 0.38666666666666666\n",
      "1777 loss: tensor(1.1088) acc: 0.38666666666666666\n",
      "1778 loss: tensor(1.1087) acc: 0.38666666666666666\n",
      "1779 loss: tensor(1.1086) acc: 0.38666666666666666\n",
      "1780 loss: tensor(1.1086) acc: 0.38666666666666666\n",
      "1781 loss: tensor(1.1085) acc: 0.38666666666666666\n",
      "1782 loss: tensor(1.1084) acc: 0.38666666666666666\n",
      "1783 loss: tensor(1.1083) acc: 0.38666666666666666\n",
      "1784 loss: tensor(1.1083) acc: 0.38666666666666666\n",
      "1785 loss: tensor(1.1082) acc: 0.38666666666666666\n",
      "1786 loss: tensor(1.1081) acc: 0.38666666666666666\n",
      "1787 loss: tensor(1.1080) acc: 0.38666666666666666\n",
      "1788 loss: tensor(1.1080) acc: 0.38666666666666666\n",
      "1789 loss: tensor(1.1079) acc: 0.38666666666666666\n",
      "1790 loss: tensor(1.1078) acc: 0.38666666666666666\n",
      "1791 loss: tensor(1.1077) acc: 0.38666666666666666\n",
      "1792 loss: tensor(1.1077) acc: 0.38666666666666666\n",
      "1793 loss: tensor(1.1076) acc: 0.38666666666666666\n",
      "1794 loss: tensor(1.1075) acc: 0.38666666666666666\n",
      "1795 loss: tensor(1.1074) acc: 0.38666666666666666\n",
      "1796 loss: tensor(1.1074) acc: 0.38666666666666666\n",
      "1797 loss: tensor(1.1073) acc: 0.38666666666666666\n",
      "1798 loss: tensor(1.1072) acc: 0.38666666666666666\n",
      "1799 loss: tensor(1.1071) acc: 0.38666666666666666\n",
      "1800 loss: tensor(1.1071) acc: 0.38666666666666666\n",
      "1801 loss: tensor(1.1070) acc: 0.38666666666666666\n",
      "1802 loss: tensor(1.1069) acc: 0.38666666666666666\n",
      "1803 loss: tensor(1.1068) acc: 0.38666666666666666\n",
      "1804 loss: tensor(1.1068) acc: 0.38666666666666666\n",
      "1805 loss: tensor(1.1067) acc: 0.38666666666666666\n",
      "1806 loss: tensor(1.1066) acc: 0.38666666666666666\n",
      "1807 loss: tensor(1.1065) acc: 0.38666666666666666\n",
      "1808 loss: tensor(1.1065) acc: 0.38666666666666666\n",
      "1809 loss: tensor(1.1064) acc: 0.38666666666666666\n",
      "1810 loss: tensor(1.1063) acc: 0.38666666666666666\n",
      "1811 loss: tensor(1.1062) acc: 0.38666666666666666\n",
      "1812 loss: tensor(1.1062) acc: 0.38666666666666666\n",
      "1813 loss: tensor(1.1061) acc: 0.38666666666666666\n",
      "1814 loss: tensor(1.1060) acc: 0.38666666666666666\n",
      "1815 loss: tensor(1.1059) acc: 0.38666666666666666\n",
      "1816 loss: tensor(1.1059) acc: 0.38666666666666666\n",
      "1817 loss: tensor(1.1058) acc: 0.38666666666666666\n",
      "1818 loss: tensor(1.1057) acc: 0.38666666666666666\n",
      "1819 loss: tensor(1.1056) acc: 0.38666666666666666\n",
      "1820 loss: tensor(1.1056) acc: 0.38666666666666666\n",
      "1821 loss: tensor(1.1055) acc: 0.38666666666666666\n",
      "1822 loss: tensor(1.1054) acc: 0.38666666666666666\n",
      "1823 loss: tensor(1.1053) acc: 0.38666666666666666\n",
      "1824 loss: tensor(1.1053) acc: 0.38666666666666666\n",
      "1825 loss: tensor(1.1052) acc: 0.38666666666666666\n",
      "1826 loss: tensor(1.1051) acc: 0.38666666666666666\n",
      "1827 loss: tensor(1.1050) acc: 0.38666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1828 loss: tensor(1.1050) acc: 0.38666666666666666\n",
      "1829 loss: tensor(1.1049) acc: 0.38666666666666666\n",
      "1830 loss: tensor(1.1048) acc: 0.38666666666666666\n",
      "1831 loss: tensor(1.1047) acc: 0.38666666666666666\n",
      "1832 loss: tensor(1.1047) acc: 0.38666666666666666\n",
      "1833 loss: tensor(1.1046) acc: 0.38666666666666666\n",
      "1834 loss: tensor(1.1045) acc: 0.38666666666666666\n",
      "1835 loss: tensor(1.1044) acc: 0.38666666666666666\n",
      "1836 loss: tensor(1.1044) acc: 0.38666666666666666\n",
      "1837 loss: tensor(1.1043) acc: 0.38666666666666666\n",
      "1838 loss: tensor(1.1042) acc: 0.38666666666666666\n",
      "1839 loss: tensor(1.1042) acc: 0.38666666666666666\n",
      "1840 loss: tensor(1.1041) acc: 0.38666666666666666\n",
      "1841 loss: tensor(1.1040) acc: 0.38666666666666666\n",
      "1842 loss: tensor(1.1039) acc: 0.38666666666666666\n",
      "1843 loss: tensor(1.1039) acc: 0.38666666666666666\n",
      "1844 loss: tensor(1.1038) acc: 0.38666666666666666\n",
      "1845 loss: tensor(1.1037) acc: 0.38666666666666666\n",
      "1846 loss: tensor(1.1036) acc: 0.38666666666666666\n",
      "1847 loss: tensor(1.1036) acc: 0.38666666666666666\n",
      "1848 loss: tensor(1.1035) acc: 0.38666666666666666\n",
      "1849 loss: tensor(1.1034) acc: 0.38666666666666666\n",
      "1850 loss: tensor(1.1033) acc: 0.38666666666666666\n",
      "1851 loss: tensor(1.1033) acc: 0.38666666666666666\n",
      "1852 loss: tensor(1.1032) acc: 0.38666666666666666\n",
      "1853 loss: tensor(1.1031) acc: 0.38666666666666666\n",
      "1854 loss: tensor(1.1031) acc: 0.38666666666666666\n",
      "1855 loss: tensor(1.1030) acc: 0.38666666666666666\n",
      "1856 loss: tensor(1.1029) acc: 0.38666666666666666\n",
      "1857 loss: tensor(1.1028) acc: 0.38666666666666666\n",
      "1858 loss: tensor(1.1028) acc: 0.38666666666666666\n",
      "1859 loss: tensor(1.1027) acc: 0.38666666666666666\n",
      "1860 loss: tensor(1.1026) acc: 0.38666666666666666\n",
      "1861 loss: tensor(1.1025) acc: 0.38666666666666666\n",
      "1862 loss: tensor(1.1025) acc: 0.38666666666666666\n",
      "1863 loss: tensor(1.1024) acc: 0.38666666666666666\n",
      "1864 loss: tensor(1.1023) acc: 0.38666666666666666\n",
      "1865 loss: tensor(1.1022) acc: 0.38666666666666666\n",
      "1866 loss: tensor(1.1022) acc: 0.38666666666666666\n",
      "1867 loss: tensor(1.1021) acc: 0.38666666666666666\n",
      "1868 loss: tensor(1.1020) acc: 0.38666666666666666\n",
      "1869 loss: tensor(1.1020) acc: 0.38666666666666666\n",
      "1870 loss: tensor(1.1019) acc: 0.38666666666666666\n",
      "1871 loss: tensor(1.1018) acc: 0.38666666666666666\n",
      "1872 loss: tensor(1.1017) acc: 0.38666666666666666\n",
      "1873 loss: tensor(1.1017) acc: 0.38666666666666666\n",
      "1874 loss: tensor(1.1016) acc: 0.38666666666666666\n",
      "1875 loss: tensor(1.1015) acc: 0.38666666666666666\n",
      "1876 loss: tensor(1.1014) acc: 0.38666666666666666\n",
      "1877 loss: tensor(1.1014) acc: 0.38666666666666666\n",
      "1878 loss: tensor(1.1013) acc: 0.38666666666666666\n",
      "1879 loss: tensor(1.1012) acc: 0.38666666666666666\n",
      "1880 loss: tensor(1.1012) acc: 0.38666666666666666\n",
      "1881 loss: tensor(1.1011) acc: 0.38666666666666666\n",
      "1882 loss: tensor(1.1010) acc: 0.38666666666666666\n",
      "1883 loss: tensor(1.1009) acc: 0.38666666666666666\n",
      "1884 loss: tensor(1.1009) acc: 0.38666666666666666\n",
      "1885 loss: tensor(1.1008) acc: 0.38666666666666666\n",
      "1886 loss: tensor(1.1007) acc: 0.38666666666666666\n",
      "1887 loss: tensor(1.1007) acc: 0.38666666666666666\n",
      "1888 loss: tensor(1.1006) acc: 0.38666666666666666\n",
      "1889 loss: tensor(1.1005) acc: 0.38666666666666666\n",
      "1890 loss: tensor(1.1004) acc: 0.38666666666666666\n",
      "1891 loss: tensor(1.1004) acc: 0.38666666666666666\n",
      "1892 loss: tensor(1.1003) acc: 0.38666666666666666\n",
      "1893 loss: tensor(1.1002) acc: 0.38666666666666666\n",
      "1894 loss: tensor(1.1002) acc: 0.38666666666666666\n",
      "1895 loss: tensor(1.1001) acc: 0.38666666666666666\n",
      "1896 loss: tensor(1.1000) acc: 0.38666666666666666\n",
      "1897 loss: tensor(1.0999) acc: 0.38666666666666666\n",
      "1898 loss: tensor(1.0999) acc: 0.38666666666666666\n",
      "1899 loss: tensor(1.0998) acc: 0.38666666666666666\n",
      "1900 loss: tensor(1.0997) acc: 0.38666666666666666\n",
      "1901 loss: tensor(1.0996) acc: 0.38666666666666666\n",
      "1902 loss: tensor(1.0996) acc: 0.38666666666666666\n",
      "1903 loss: tensor(1.0995) acc: 0.38666666666666666\n",
      "1904 loss: tensor(1.0994) acc: 0.38666666666666666\n",
      "1905 loss: tensor(1.0994) acc: 0.38666666666666666\n",
      "1906 loss: tensor(1.0993) acc: 0.38666666666666666\n",
      "1907 loss: tensor(1.0992) acc: 0.38666666666666666\n",
      "1908 loss: tensor(1.0991) acc: 0.38666666666666666\n",
      "1909 loss: tensor(1.0991) acc: 0.38666666666666666\n",
      "1910 loss: tensor(1.0990) acc: 0.38666666666666666\n",
      "1911 loss: tensor(1.0989) acc: 0.38666666666666666\n",
      "1912 loss: tensor(1.0989) acc: 0.38666666666666666\n",
      "1913 loss: tensor(1.0988) acc: 0.38666666666666666\n",
      "1914 loss: tensor(1.0987) acc: 0.38666666666666666\n",
      "1915 loss: tensor(1.0986) acc: 0.38666666666666666\n",
      "1916 loss: tensor(1.0986) acc: 0.38666666666666666\n",
      "1917 loss: tensor(1.0985) acc: 0.38666666666666666\n",
      "1918 loss: tensor(1.0984) acc: 0.38666666666666666\n",
      "1919 loss: tensor(1.0984) acc: 0.38666666666666666\n",
      "1920 loss: tensor(1.0983) acc: 0.38666666666666666\n",
      "1921 loss: tensor(1.0982) acc: 0.38666666666666666\n",
      "1922 loss: tensor(1.0981) acc: 0.38666666666666666\n",
      "1923 loss: tensor(1.0981) acc: 0.38666666666666666\n",
      "1924 loss: tensor(1.0980) acc: 0.38666666666666666\n",
      "1925 loss: tensor(1.0979) acc: 0.38666666666666666\n",
      "1926 loss: tensor(1.0979) acc: 0.38666666666666666\n",
      "1927 loss: tensor(1.0978) acc: 0.38666666666666666\n",
      "1928 loss: tensor(1.0977) acc: 0.38666666666666666\n",
      "1929 loss: tensor(1.0977) acc: 0.38666666666666666\n",
      "1930 loss: tensor(1.0976) acc: 0.38666666666666666\n",
      "1931 loss: tensor(1.0975) acc: 0.38666666666666666\n",
      "1932 loss: tensor(1.0974) acc: 0.38666666666666666\n",
      "1933 loss: tensor(1.0974) acc: 0.38666666666666666\n",
      "1934 loss: tensor(1.0973) acc: 0.38666666666666666\n",
      "1935 loss: tensor(1.0972) acc: 0.38666666666666666\n",
      "1936 loss: tensor(1.0972) acc: 0.38666666666666666\n",
      "1937 loss: tensor(1.0971) acc: 0.38666666666666666\n",
      "1938 loss: tensor(1.0970) acc: 0.38666666666666666\n",
      "1939 loss: tensor(1.0969) acc: 0.38666666666666666\n",
      "1940 loss: tensor(1.0969) acc: 0.38666666666666666\n",
      "1941 loss: tensor(1.0968) acc: 0.38666666666666666\n",
      "1942 loss: tensor(1.0967) acc: 0.38666666666666666\n",
      "1943 loss: tensor(1.0967) acc: 0.38666666666666666\n",
      "1944 loss: tensor(1.0966) acc: 0.38666666666666666\n",
      "1945 loss: tensor(1.0965) acc: 0.38666666666666666\n",
      "1946 loss: tensor(1.0965) acc: 0.38666666666666666\n",
      "1947 loss: tensor(1.0964) acc: 0.38666666666666666\n",
      "1948 loss: tensor(1.0963) acc: 0.38666666666666666\n",
      "1949 loss: tensor(1.0962) acc: 0.38666666666666666\n",
      "1950 loss: tensor(1.0962) acc: 0.38666666666666666\n",
      "1951 loss: tensor(1.0961) acc: 0.38666666666666666\n",
      "1952 loss: tensor(1.0960) acc: 0.38666666666666666\n",
      "1953 loss: tensor(1.0960) acc: 0.38666666666666666\n",
      "1954 loss: tensor(1.0959) acc: 0.38666666666666666\n",
      "1955 loss: tensor(1.0958) acc: 0.38666666666666666\n",
      "1956 loss: tensor(1.0957) acc: 0.38666666666666666\n",
      "1957 loss: tensor(1.0957) acc: 0.38666666666666666\n",
      "1958 loss: tensor(1.0956) acc: 0.38666666666666666\n",
      "1959 loss: tensor(1.0955) acc: 0.38666666666666666\n",
      "1960 loss: tensor(1.0955) acc: 0.38666666666666666\n",
      "1961 loss: tensor(1.0954) acc: 0.38666666666666666\n",
      "1962 loss: tensor(1.0953) acc: 0.38666666666666666\n",
      "1963 loss: tensor(1.0953) acc: 0.38666666666666666\n",
      "1964 loss: tensor(1.0952) acc: 0.38666666666666666\n",
      "1965 loss: tensor(1.0951) acc: 0.38666666666666666\n",
      "1966 loss: tensor(1.0950) acc: 0.38666666666666666\n",
      "1967 loss: tensor(1.0950) acc: 0.38666666666666666\n",
      "1968 loss: tensor(1.0949) acc: 0.38666666666666666\n",
      "1969 loss: tensor(1.0948) acc: 0.38666666666666666\n",
      "1970 loss: tensor(1.0948) acc: 0.38666666666666666\n",
      "1971 loss: tensor(1.0947) acc: 0.38666666666666666\n",
      "1972 loss: tensor(1.0946) acc: 0.38666666666666666\n",
      "1973 loss: tensor(1.0946) acc: 0.38666666666666666\n",
      "1974 loss: tensor(1.0945) acc: 0.38666666666666666\n",
      "1975 loss: tensor(1.0944) acc: 0.38666666666666666\n",
      "1976 loss: tensor(1.0944) acc: 0.38666666666666666\n",
      "1977 loss: tensor(1.0943) acc: 0.38666666666666666\n",
      "1978 loss: tensor(1.0942) acc: 0.38666666666666666\n",
      "1979 loss: tensor(1.0941) acc: 0.38666666666666666\n",
      "1980 loss: tensor(1.0941) acc: 0.38666666666666666\n",
      "1981 loss: tensor(1.0940) acc: 0.38666666666666666\n",
      "1982 loss: tensor(1.0939) acc: 0.38666666666666666\n",
      "1983 loss: tensor(1.0939) acc: 0.38666666666666666\n",
      "1984 loss: tensor(1.0938) acc: 0.38666666666666666\n",
      "1985 loss: tensor(1.0937) acc: 0.38666666666666666\n",
      "1986 loss: tensor(1.0937) acc: 0.38666666666666666\n",
      "1987 loss: tensor(1.0936) acc: 0.38666666666666666\n",
      "1988 loss: tensor(1.0935) acc: 0.38666666666666666\n",
      "1989 loss: tensor(1.0934) acc: 0.38666666666666666\n",
      "1990 loss: tensor(1.0934) acc: 0.38666666666666666\n",
      "1991 loss: tensor(1.0933) acc: 0.38666666666666666\n",
      "1992 loss: tensor(1.0932) acc: 0.38666666666666666\n",
      "1993 loss: tensor(1.0932) acc: 0.38666666666666666\n",
      "1994 loss: tensor(1.0931) acc: 0.38666666666666666\n",
      "1995 loss: tensor(1.0930) acc: 0.38666666666666666\n",
      "1996 loss: tensor(1.0930) acc: 0.38666666666666666\n",
      "1997 loss: tensor(1.0929) acc: 0.38666666666666666\n",
      "1998 loss: tensor(1.0928) acc: 0.38666666666666666\n",
      "1999 loss: tensor(1.0928) acc: 0.38666666666666666\n",
      "2000 loss: tensor(1.0927) acc: 0.38666666666666666\n",
      "2001 loss: tensor(1.0926) acc: 0.3933333333333333\n",
      "2002 loss: tensor(1.0925) acc: 0.3933333333333333\n",
      "2003 loss: tensor(1.0925) acc: 0.3933333333333333\n",
      "2004 loss: tensor(1.0924) acc: 0.3933333333333333\n",
      "2005 loss: tensor(1.0923) acc: 0.3933333333333333\n",
      "2006 loss: tensor(1.0923) acc: 0.3933333333333333\n",
      "2007 loss: tensor(1.0922) acc: 0.3933333333333333\n",
      "2008 loss: tensor(1.0921) acc: 0.4\n",
      "2009 loss: tensor(1.0921) acc: 0.4\n",
      "2010 loss: tensor(1.0920) acc: 0.4\n",
      "2011 loss: tensor(1.0919) acc: 0.4\n",
      "2012 loss: tensor(1.0919) acc: 0.4\n",
      "2013 loss: tensor(1.0918) acc: 0.4\n",
      "2014 loss: tensor(1.0917) acc: 0.4\n",
      "2015 loss: tensor(1.0917) acc: 0.4\n",
      "2016 loss: tensor(1.0916) acc: 0.4\n",
      "2017 loss: tensor(1.0915) acc: 0.4\n",
      "2018 loss: tensor(1.0914) acc: 0.4\n",
      "2019 loss: tensor(1.0914) acc: 0.4\n",
      "2020 loss: tensor(1.0913) acc: 0.4\n",
      "2021 loss: tensor(1.0912) acc: 0.4\n",
      "2022 loss: tensor(1.0912) acc: 0.4\n",
      "2023 loss: tensor(1.0911) acc: 0.4\n",
      "2024 loss: tensor(1.0910) acc: 0.4\n",
      "2025 loss: tensor(1.0910) acc: 0.4\n",
      "2026 loss: tensor(1.0909) acc: 0.4\n",
      "2027 loss: tensor(1.0908) acc: 0.4\n",
      "2028 loss: tensor(1.0908) acc: 0.4\n",
      "2029 loss: tensor(1.0907) acc: 0.4\n",
      "2030 loss: tensor(1.0906) acc: 0.4\n",
      "2031 loss: tensor(1.0906) acc: 0.4\n",
      "2032 loss: tensor(1.0905) acc: 0.4\n",
      "2033 loss: tensor(1.0904) acc: 0.4\n",
      "2034 loss: tensor(1.0903) acc: 0.4\n",
      "2035 loss: tensor(1.0903) acc: 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2036 loss: tensor(1.0902) acc: 0.4\n",
      "2037 loss: tensor(1.0901) acc: 0.4\n",
      "2038 loss: tensor(1.0901) acc: 0.4\n",
      "2039 loss: tensor(1.0900) acc: 0.4\n",
      "2040 loss: tensor(1.0899) acc: 0.4\n",
      "2041 loss: tensor(1.0899) acc: 0.4\n",
      "2042 loss: tensor(1.0898) acc: 0.4\n",
      "2043 loss: tensor(1.0897) acc: 0.4\n",
      "2044 loss: tensor(1.0897) acc: 0.4\n",
      "2045 loss: tensor(1.0896) acc: 0.4\n",
      "2046 loss: tensor(1.0895) acc: 0.4\n",
      "2047 loss: tensor(1.0895) acc: 0.4\n",
      "2048 loss: tensor(1.0894) acc: 0.4\n",
      "2049 loss: tensor(1.0893) acc: 0.4\n",
      "2050 loss: tensor(1.0893) acc: 0.4\n",
      "2051 loss: tensor(1.0892) acc: 0.4\n",
      "2052 loss: tensor(1.0891) acc: 0.4\n",
      "2053 loss: tensor(1.0890) acc: 0.4\n",
      "2054 loss: tensor(1.0890) acc: 0.4\n",
      "2055 loss: tensor(1.0889) acc: 0.4\n",
      "2056 loss: tensor(1.0888) acc: 0.4\n",
      "2057 loss: tensor(1.0888) acc: 0.4\n",
      "2058 loss: tensor(1.0887) acc: 0.4\n",
      "2059 loss: tensor(1.0886) acc: 0.4\n",
      "2060 loss: tensor(1.0886) acc: 0.4\n",
      "2061 loss: tensor(1.0885) acc: 0.4\n",
      "2062 loss: tensor(1.0884) acc: 0.4\n",
      "2063 loss: tensor(1.0884) acc: 0.4\n",
      "2064 loss: tensor(1.0883) acc: 0.4\n",
      "2065 loss: tensor(1.0882) acc: 0.4\n",
      "2066 loss: tensor(1.0882) acc: 0.4\n",
      "2067 loss: tensor(1.0881) acc: 0.4\n",
      "2068 loss: tensor(1.0880) acc: 0.4\n",
      "2069 loss: tensor(1.0880) acc: 0.4\n",
      "2070 loss: tensor(1.0879) acc: 0.4\n",
      "2071 loss: tensor(1.0878) acc: 0.4\n",
      "2072 loss: tensor(1.0878) acc: 0.4\n",
      "2073 loss: tensor(1.0877) acc: 0.4\n",
      "2074 loss: tensor(1.0876) acc: 0.4\n",
      "2075 loss: tensor(1.0876) acc: 0.4\n",
      "2076 loss: tensor(1.0875) acc: 0.4\n",
      "2077 loss: tensor(1.0874) acc: 0.4\n",
      "2078 loss: tensor(1.0873) acc: 0.4\n",
      "2079 loss: tensor(1.0873) acc: 0.4\n",
      "2080 loss: tensor(1.0872) acc: 0.4\n",
      "2081 loss: tensor(1.0871) acc: 0.4\n",
      "2082 loss: tensor(1.0871) acc: 0.4\n",
      "2083 loss: tensor(1.0870) acc: 0.4\n",
      "2084 loss: tensor(1.0869) acc: 0.4\n",
      "2085 loss: tensor(1.0869) acc: 0.4\n",
      "2086 loss: tensor(1.0868) acc: 0.4\n",
      "2087 loss: tensor(1.0867) acc: 0.4\n",
      "2088 loss: tensor(1.0867) acc: 0.4\n",
      "2089 loss: tensor(1.0866) acc: 0.4\n",
      "2090 loss: tensor(1.0865) acc: 0.4\n",
      "2091 loss: tensor(1.0865) acc: 0.4\n",
      "2092 loss: tensor(1.0864) acc: 0.4\n",
      "2093 loss: tensor(1.0863) acc: 0.4\n",
      "2094 loss: tensor(1.0863) acc: 0.4\n",
      "2095 loss: tensor(1.0862) acc: 0.4\n",
      "2096 loss: tensor(1.0861) acc: 0.4\n",
      "2097 loss: tensor(1.0861) acc: 0.4\n",
      "2098 loss: tensor(1.0860) acc: 0.4\n",
      "2099 loss: tensor(1.0859) acc: 0.4\n",
      "2100 loss: tensor(1.0859) acc: 0.4\n",
      "2101 loss: tensor(1.0858) acc: 0.4\n",
      "2102 loss: tensor(1.0857) acc: 0.4\n",
      "2103 loss: tensor(1.0857) acc: 0.4\n",
      "2104 loss: tensor(1.0856) acc: 0.4\n",
      "2105 loss: tensor(1.0855) acc: 0.4\n",
      "2106 loss: tensor(1.0855) acc: 0.4\n",
      "2107 loss: tensor(1.0854) acc: 0.4\n",
      "2108 loss: tensor(1.0853) acc: 0.4\n",
      "2109 loss: tensor(1.0853) acc: 0.4\n",
      "2110 loss: tensor(1.0852) acc: 0.4\n",
      "2111 loss: tensor(1.0851) acc: 0.4\n",
      "2112 loss: tensor(1.0851) acc: 0.4\n",
      "2113 loss: tensor(1.0850) acc: 0.4\n",
      "2114 loss: tensor(1.0849) acc: 0.4\n",
      "2115 loss: tensor(1.0848) acc: 0.4\n",
      "2116 loss: tensor(1.0848) acc: 0.4\n",
      "2117 loss: tensor(1.0847) acc: 0.4\n",
      "2118 loss: tensor(1.0846) acc: 0.4\n",
      "2119 loss: tensor(1.0846) acc: 0.4\n",
      "2120 loss: tensor(1.0845) acc: 0.4\n",
      "2121 loss: tensor(1.0844) acc: 0.4\n",
      "2122 loss: tensor(1.0844) acc: 0.4\n",
      "2123 loss: tensor(1.0843) acc: 0.4\n",
      "2124 loss: tensor(1.0842) acc: 0.4\n",
      "2125 loss: tensor(1.0842) acc: 0.4\n",
      "2126 loss: tensor(1.0841) acc: 0.4\n",
      "2127 loss: tensor(1.0840) acc: 0.4\n",
      "2128 loss: tensor(1.0840) acc: 0.4\n",
      "2129 loss: tensor(1.0839) acc: 0.4\n",
      "2130 loss: tensor(1.0838) acc: 0.4\n",
      "2131 loss: tensor(1.0838) acc: 0.4\n",
      "2132 loss: tensor(1.0837) acc: 0.4\n",
      "2133 loss: tensor(1.0836) acc: 0.4\n",
      "2134 loss: tensor(1.0836) acc: 0.4\n",
      "2135 loss: tensor(1.0835) acc: 0.4\n",
      "2136 loss: tensor(1.0834) acc: 0.4\n",
      "2137 loss: tensor(1.0834) acc: 0.4\n",
      "2138 loss: tensor(1.0833) acc: 0.4\n",
      "2139 loss: tensor(1.0832) acc: 0.4\n",
      "2140 loss: tensor(1.0832) acc: 0.4\n",
      "2141 loss: tensor(1.0831) acc: 0.4\n",
      "2142 loss: tensor(1.0830) acc: 0.4\n",
      "2143 loss: tensor(1.0830) acc: 0.4\n",
      "2144 loss: tensor(1.0829) acc: 0.4\n",
      "2145 loss: tensor(1.0828) acc: 0.4\n",
      "2146 loss: tensor(1.0828) acc: 0.4\n",
      "2147 loss: tensor(1.0827) acc: 0.4\n",
      "2148 loss: tensor(1.0826) acc: 0.4\n",
      "2149 loss: tensor(1.0826) acc: 0.4\n",
      "2150 loss: tensor(1.0825) acc: 0.4\n",
      "2151 loss: tensor(1.0824) acc: 0.4\n",
      "2152 loss: tensor(1.0824) acc: 0.4\n",
      "2153 loss: tensor(1.0823) acc: 0.4\n",
      "2154 loss: tensor(1.0822) acc: 0.4\n",
      "2155 loss: tensor(1.0822) acc: 0.4\n",
      "2156 loss: tensor(1.0821) acc: 0.4\n",
      "2157 loss: tensor(1.0820) acc: 0.4\n",
      "2158 loss: tensor(1.0820) acc: 0.4\n",
      "2159 loss: tensor(1.0819) acc: 0.4\n",
      "2160 loss: tensor(1.0818) acc: 0.4\n",
      "2161 loss: tensor(1.0818) acc: 0.4\n",
      "2162 loss: tensor(1.0817) acc: 0.4\n",
      "2163 loss: tensor(1.0816) acc: 0.4\n",
      "2164 loss: tensor(1.0816) acc: 0.4\n",
      "2165 loss: tensor(1.0815) acc: 0.4\n",
      "2166 loss: tensor(1.0814) acc: 0.4\n",
      "2167 loss: tensor(1.0814) acc: 0.4\n",
      "2168 loss: tensor(1.0813) acc: 0.4\n",
      "2169 loss: tensor(1.0812) acc: 0.4\n",
      "2170 loss: tensor(1.0812) acc: 0.4\n",
      "2171 loss: tensor(1.0811) acc: 0.4\n",
      "2172 loss: tensor(1.0810) acc: 0.4\n",
      "2173 loss: tensor(1.0810) acc: 0.4\n",
      "2174 loss: tensor(1.0809) acc: 0.4\n",
      "2175 loss: tensor(1.0808) acc: 0.4\n",
      "2176 loss: tensor(1.0808) acc: 0.4\n",
      "2177 loss: tensor(1.0807) acc: 0.4\n",
      "2178 loss: tensor(1.0806) acc: 0.4\n",
      "2179 loss: tensor(1.0806) acc: 0.4\n",
      "2180 loss: tensor(1.0805) acc: 0.4\n",
      "2181 loss: tensor(1.0804) acc: 0.4\n",
      "2182 loss: tensor(1.0804) acc: 0.4\n",
      "2183 loss: tensor(1.0803) acc: 0.4\n",
      "2184 loss: tensor(1.0802) acc: 0.4\n",
      "2185 loss: tensor(1.0802) acc: 0.4\n",
      "2186 loss: tensor(1.0801) acc: 0.4\n",
      "2187 loss: tensor(1.0800) acc: 0.4\n",
      "2188 loss: tensor(1.0800) acc: 0.4\n",
      "2189 loss: tensor(1.0799) acc: 0.4\n",
      "2190 loss: tensor(1.0798) acc: 0.4\n",
      "2191 loss: tensor(1.0798) acc: 0.4\n",
      "2192 loss: tensor(1.0797) acc: 0.4\n",
      "2193 loss: tensor(1.0796) acc: 0.4\n",
      "2194 loss: tensor(1.0796) acc: 0.4\n",
      "2195 loss: tensor(1.0795) acc: 0.4\n",
      "2196 loss: tensor(1.0794) acc: 0.4\n",
      "2197 loss: tensor(1.0794) acc: 0.4\n",
      "2198 loss: tensor(1.0793) acc: 0.4\n",
      "2199 loss: tensor(1.0792) acc: 0.4\n",
      "2200 loss: tensor(1.0791) acc: 0.4\n",
      "2201 loss: tensor(1.0791) acc: 0.4\n",
      "2202 loss: tensor(1.0790) acc: 0.4\n",
      "2203 loss: tensor(1.0789) acc: 0.4\n",
      "2204 loss: tensor(1.0789) acc: 0.4\n",
      "2205 loss: tensor(1.0788) acc: 0.4\n",
      "2206 loss: tensor(1.0787) acc: 0.4\n",
      "2207 loss: tensor(1.0787) acc: 0.4\n",
      "2208 loss: tensor(1.0786) acc: 0.4\n",
      "2209 loss: tensor(1.0785) acc: 0.4\n",
      "2210 loss: tensor(1.0785) acc: 0.4\n",
      "2211 loss: tensor(1.0784) acc: 0.4\n",
      "2212 loss: tensor(1.0783) acc: 0.4\n",
      "2213 loss: tensor(1.0783) acc: 0.4\n",
      "2214 loss: tensor(1.0782) acc: 0.4\n",
      "2215 loss: tensor(1.0781) acc: 0.4\n",
      "2216 loss: tensor(1.0781) acc: 0.4\n",
      "2217 loss: tensor(1.0780) acc: 0.4\n",
      "2218 loss: tensor(1.0779) acc: 0.4\n",
      "2219 loss: tensor(1.0779) acc: 0.4\n",
      "2220 loss: tensor(1.0778) acc: 0.4\n",
      "2221 loss: tensor(1.0777) acc: 0.4\n",
      "2222 loss: tensor(1.0777) acc: 0.4\n",
      "2223 loss: tensor(1.0776) acc: 0.4\n",
      "2224 loss: tensor(1.0775) acc: 0.4\n",
      "2225 loss: tensor(1.0775) acc: 0.4\n",
      "2226 loss: tensor(1.0774) acc: 0.4\n",
      "2227 loss: tensor(1.0773) acc: 0.4\n",
      "2228 loss: tensor(1.0773) acc: 0.4\n",
      "2229 loss: tensor(1.0772) acc: 0.4\n",
      "2230 loss: tensor(1.0771) acc: 0.4\n",
      "2231 loss: tensor(1.0771) acc: 0.4\n",
      "2232 loss: tensor(1.0770) acc: 0.4\n",
      "2233 loss: tensor(1.0769) acc: 0.4\n",
      "2234 loss: tensor(1.0769) acc: 0.4\n",
      "2235 loss: tensor(1.0768) acc: 0.4\n",
      "2236 loss: tensor(1.0767) acc: 0.4\n",
      "2237 loss: tensor(1.0767) acc: 0.4\n",
      "2238 loss: tensor(1.0766) acc: 0.4\n",
      "2239 loss: tensor(1.0765) acc: 0.4\n",
      "2240 loss: tensor(1.0765) acc: 0.4\n",
      "2241 loss: tensor(1.0764) acc: 0.4\n",
      "2242 loss: tensor(1.0763) acc: 0.4\n",
      "2243 loss: tensor(1.0763) acc: 0.4\n",
      "2244 loss: tensor(1.0762) acc: 0.4\n",
      "2245 loss: tensor(1.0761) acc: 0.4\n",
      "2246 loss: tensor(1.0761) acc: 0.4\n",
      "2247 loss: tensor(1.0760) acc: 0.4\n",
      "2248 loss: tensor(1.0759) acc: 0.4\n",
      "2249 loss: tensor(1.0759) acc: 0.4\n",
      "2250 loss: tensor(1.0758) acc: 0.4\n",
      "2251 loss: tensor(1.0757) acc: 0.4\n",
      "2252 loss: tensor(1.0757) acc: 0.4\n",
      "2253 loss: tensor(1.0756) acc: 0.4\n",
      "2254 loss: tensor(1.0755) acc: 0.4\n",
      "2255 loss: tensor(1.0755) acc: 0.4\n",
      "2256 loss: tensor(1.0754) acc: 0.4\n",
      "2257 loss: tensor(1.0753) acc: 0.4\n",
      "2258 loss: tensor(1.0753) acc: 0.4\n",
      "2259 loss: tensor(1.0752) acc: 0.4\n",
      "2260 loss: tensor(1.0751) acc: 0.4\n",
      "2261 loss: tensor(1.0751) acc: 0.4\n",
      "2262 loss: tensor(1.0750) acc: 0.4\n",
      "2263 loss: tensor(1.0749) acc: 0.4\n",
      "2264 loss: tensor(1.0749) acc: 0.4\n",
      "2265 loss: tensor(1.0748) acc: 0.4\n",
      "2266 loss: tensor(1.0747) acc: 0.4\n",
      "2267 loss: tensor(1.0747) acc: 0.4\n",
      "2268 loss: tensor(1.0746) acc: 0.4\n",
      "2269 loss: tensor(1.0745) acc: 0.4\n",
      "2270 loss: tensor(1.0745) acc: 0.4\n",
      "2271 loss: tensor(1.0744) acc: 0.4\n",
      "2272 loss: tensor(1.0743) acc: 0.4\n",
      "2273 loss: tensor(1.0743) acc: 0.4\n",
      "2274 loss: tensor(1.0742) acc: 0.4\n",
      "2275 loss: tensor(1.0741) acc: 0.4\n",
      "2276 loss: tensor(1.0741) acc: 0.4\n",
      "2277 loss: tensor(1.0740) acc: 0.4\n",
      "2278 loss: tensor(1.0739) acc: 0.4\n",
      "2279 loss: tensor(1.0739) acc: 0.4\n",
      "2280 loss: tensor(1.0738) acc: 0.4\n",
      "2281 loss: tensor(1.0737) acc: 0.4\n",
      "2282 loss: tensor(1.0737) acc: 0.4\n",
      "2283 loss: tensor(1.0736) acc: 0.4\n",
      "2284 loss: tensor(1.0735) acc: 0.4\n",
      "2285 loss: tensor(1.0735) acc: 0.4\n",
      "2286 loss: tensor(1.0734) acc: 0.4\n",
      "2287 loss: tensor(1.0733) acc: 0.4\n",
      "2288 loss: tensor(1.0733) acc: 0.4\n",
      "2289 loss: tensor(1.0732) acc: 0.4\n",
      "2290 loss: tensor(1.0731) acc: 0.4\n",
      "2291 loss: tensor(1.0731) acc: 0.4\n",
      "2292 loss: tensor(1.0730) acc: 0.4\n",
      "2293 loss: tensor(1.0729) acc: 0.4\n",
      "2294 loss: tensor(1.0729) acc: 0.4\n",
      "2295 loss: tensor(1.0728) acc: 0.4\n",
      "2296 loss: tensor(1.0727) acc: 0.4\n",
      "2297 loss: tensor(1.0726) acc: 0.4\n",
      "2298 loss: tensor(1.0726) acc: 0.4\n",
      "2299 loss: tensor(1.0725) acc: 0.4\n",
      "2300 loss: tensor(1.0724) acc: 0.4\n",
      "2301 loss: tensor(1.0724) acc: 0.4\n",
      "2302 loss: tensor(1.0723) acc: 0.4\n",
      "2303 loss: tensor(1.0722) acc: 0.4\n",
      "2304 loss: tensor(1.0722) acc: 0.4\n",
      "2305 loss: tensor(1.0721) acc: 0.4\n",
      "2306 loss: tensor(1.0720) acc: 0.4\n",
      "2307 loss: tensor(1.0720) acc: 0.4\n",
      "2308 loss: tensor(1.0719) acc: 0.4\n",
      "2309 loss: tensor(1.0718) acc: 0.4\n",
      "2310 loss: tensor(1.0718) acc: 0.4\n",
      "2311 loss: tensor(1.0717) acc: 0.4\n",
      "2312 loss: tensor(1.0716) acc: 0.4\n",
      "2313 loss: tensor(1.0716) acc: 0.4\n",
      "2314 loss: tensor(1.0715) acc: 0.4\n",
      "2315 loss: tensor(1.0714) acc: 0.4\n",
      "2316 loss: tensor(1.0714) acc: 0.4\n",
      "2317 loss: tensor(1.0713) acc: 0.4\n",
      "2318 loss: tensor(1.0712) acc: 0.4\n",
      "2319 loss: tensor(1.0712) acc: 0.4\n",
      "2320 loss: tensor(1.0711) acc: 0.4\n",
      "2321 loss: tensor(1.0710) acc: 0.4\n",
      "2322 loss: tensor(1.0710) acc: 0.4\n",
      "2323 loss: tensor(1.0709) acc: 0.4\n",
      "2324 loss: tensor(1.0708) acc: 0.4\n",
      "2325 loss: tensor(1.0708) acc: 0.4\n",
      "2326 loss: tensor(1.0707) acc: 0.4\n",
      "2327 loss: tensor(1.0706) acc: 0.4\n",
      "2328 loss: tensor(1.0706) acc: 0.4\n",
      "2329 loss: tensor(1.0705) acc: 0.4\n",
      "2330 loss: tensor(1.0704) acc: 0.4\n",
      "2331 loss: tensor(1.0704) acc: 0.4\n",
      "2332 loss: tensor(1.0703) acc: 0.4\n",
      "2333 loss: tensor(1.0702) acc: 0.4\n",
      "2334 loss: tensor(1.0701) acc: 0.4\n",
      "2335 loss: tensor(1.0701) acc: 0.4\n",
      "2336 loss: tensor(1.0700) acc: 0.4\n",
      "2337 loss: tensor(1.0699) acc: 0.4\n",
      "2338 loss: tensor(1.0699) acc: 0.4\n",
      "2339 loss: tensor(1.0698) acc: 0.4\n",
      "2340 loss: tensor(1.0697) acc: 0.4\n",
      "2341 loss: tensor(1.0697) acc: 0.4\n",
      "2342 loss: tensor(1.0696) acc: 0.4\n",
      "2343 loss: tensor(1.0695) acc: 0.4\n",
      "2344 loss: tensor(1.0695) acc: 0.4\n",
      "2345 loss: tensor(1.0694) acc: 0.4\n",
      "2346 loss: tensor(1.0693) acc: 0.4\n",
      "2347 loss: tensor(1.0693) acc: 0.4\n",
      "2348 loss: tensor(1.0692) acc: 0.4\n",
      "2349 loss: tensor(1.0691) acc: 0.4\n",
      "2350 loss: tensor(1.0691) acc: 0.4\n",
      "2351 loss: tensor(1.0690) acc: 0.4\n",
      "2352 loss: tensor(1.0689) acc: 0.4\n",
      "2353 loss: tensor(1.0689) acc: 0.4\n",
      "2354 loss: tensor(1.0688) acc: 0.4\n",
      "2355 loss: tensor(1.0687) acc: 0.4\n",
      "2356 loss: tensor(1.0687) acc: 0.4\n",
      "2357 loss: tensor(1.0686) acc: 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2358 loss: tensor(1.0685) acc: 0.4\n",
      "2359 loss: tensor(1.0684) acc: 0.4\n",
      "2360 loss: tensor(1.0684) acc: 0.4\n",
      "2361 loss: tensor(1.0683) acc: 0.4\n",
      "2362 loss: tensor(1.0682) acc: 0.4\n",
      "2363 loss: tensor(1.0682) acc: 0.4\n",
      "2364 loss: tensor(1.0681) acc: 0.4\n",
      "2365 loss: tensor(1.0680) acc: 0.4\n",
      "2366 loss: tensor(1.0680) acc: 0.4\n",
      "2367 loss: tensor(1.0679) acc: 0.4\n",
      "2368 loss: tensor(1.0678) acc: 0.4\n",
      "2369 loss: tensor(1.0678) acc: 0.4\n",
      "2370 loss: tensor(1.0677) acc: 0.4\n",
      "2371 loss: tensor(1.0676) acc: 0.4\n",
      "2372 loss: tensor(1.0676) acc: 0.4\n",
      "2373 loss: tensor(1.0675) acc: 0.4\n",
      "2374 loss: tensor(1.0674) acc: 0.4\n",
      "2375 loss: tensor(1.0674) acc: 0.4\n",
      "2376 loss: tensor(1.0673) acc: 0.4\n",
      "2377 loss: tensor(1.0672) acc: 0.4\n",
      "2378 loss: tensor(1.0671) acc: 0.4\n",
      "2379 loss: tensor(1.0671) acc: 0.4\n",
      "2380 loss: tensor(1.0670) acc: 0.4\n",
      "2381 loss: tensor(1.0669) acc: 0.4\n",
      "2382 loss: tensor(1.0669) acc: 0.4\n",
      "2383 loss: tensor(1.0668) acc: 0.4\n",
      "2384 loss: tensor(1.0667) acc: 0.4\n",
      "2385 loss: tensor(1.0667) acc: 0.4\n",
      "2386 loss: tensor(1.0666) acc: 0.4\n",
      "2387 loss: tensor(1.0665) acc: 0.4\n",
      "2388 loss: tensor(1.0665) acc: 0.4\n",
      "2389 loss: tensor(1.0664) acc: 0.4\n",
      "2390 loss: tensor(1.0663) acc: 0.4\n",
      "2391 loss: tensor(1.0663) acc: 0.4\n",
      "2392 loss: tensor(1.0662) acc: 0.4\n",
      "2393 loss: tensor(1.0661) acc: 0.4\n",
      "2394 loss: tensor(1.0661) acc: 0.4\n",
      "2395 loss: tensor(1.0660) acc: 0.4\n",
      "2396 loss: tensor(1.0659) acc: 0.4\n",
      "2397 loss: tensor(1.0658) acc: 0.4\n",
      "2398 loss: tensor(1.0658) acc: 0.4\n",
      "2399 loss: tensor(1.0657) acc: 0.4\n",
      "2400 loss: tensor(1.0656) acc: 0.4\n",
      "2401 loss: tensor(1.0656) acc: 0.4\n",
      "2402 loss: tensor(1.0655) acc: 0.4\n",
      "2403 loss: tensor(1.0654) acc: 0.4\n",
      "2404 loss: tensor(1.0654) acc: 0.4\n",
      "2405 loss: tensor(1.0653) acc: 0.4\n",
      "2406 loss: tensor(1.0652) acc: 0.4\n",
      "2407 loss: tensor(1.0652) acc: 0.4\n",
      "2408 loss: tensor(1.0651) acc: 0.4\n",
      "2409 loss: tensor(1.0650) acc: 0.4\n",
      "2410 loss: tensor(1.0649) acc: 0.4\n",
      "2411 loss: tensor(1.0649) acc: 0.4\n",
      "2412 loss: tensor(1.0648) acc: 0.4\n",
      "2413 loss: tensor(1.0647) acc: 0.4\n",
      "2414 loss: tensor(1.0647) acc: 0.4\n",
      "2415 loss: tensor(1.0646) acc: 0.4\n",
      "2416 loss: tensor(1.0645) acc: 0.4\n",
      "2417 loss: tensor(1.0645) acc: 0.4\n",
      "2418 loss: tensor(1.0644) acc: 0.4\n",
      "2419 loss: tensor(1.0643) acc: 0.4\n",
      "2420 loss: tensor(1.0643) acc: 0.4\n",
      "2421 loss: tensor(1.0642) acc: 0.4\n",
      "2422 loss: tensor(1.0641) acc: 0.4\n",
      "2423 loss: tensor(1.0640) acc: 0.4\n",
      "2424 loss: tensor(1.0640) acc: 0.4\n",
      "2425 loss: tensor(1.0639) acc: 0.4\n",
      "2426 loss: tensor(1.0638) acc: 0.4\n",
      "2427 loss: tensor(1.0638) acc: 0.4\n",
      "2428 loss: tensor(1.0637) acc: 0.4\n",
      "2429 loss: tensor(1.0636) acc: 0.4\n",
      "2430 loss: tensor(1.0636) acc: 0.4\n",
      "2431 loss: tensor(1.0635) acc: 0.4066666666666667\n",
      "2432 loss: tensor(1.0634) acc: 0.4066666666666667\n",
      "2433 loss: tensor(1.0633) acc: 0.4066666666666667\n",
      "2434 loss: tensor(1.0633) acc: 0.4066666666666667\n",
      "2435 loss: tensor(1.0632) acc: 0.4066666666666667\n",
      "2436 loss: tensor(1.0631) acc: 0.4066666666666667\n",
      "2437 loss: tensor(1.0631) acc: 0.4066666666666667\n",
      "2438 loss: tensor(1.0630) acc: 0.4066666666666667\n",
      "2439 loss: tensor(1.0629) acc: 0.4066666666666667\n",
      "2440 loss: tensor(1.0629) acc: 0.4066666666666667\n",
      "2441 loss: tensor(1.0628) acc: 0.4066666666666667\n",
      "2442 loss: tensor(1.0627) acc: 0.4066666666666667\n",
      "2443 loss: tensor(1.0626) acc: 0.4066666666666667\n",
      "2444 loss: tensor(1.0626) acc: 0.4066666666666667\n",
      "2445 loss: tensor(1.0625) acc: 0.4066666666666667\n",
      "2446 loss: tensor(1.0624) acc: 0.4066666666666667\n",
      "2447 loss: tensor(1.0624) acc: 0.4066666666666667\n",
      "2448 loss: tensor(1.0623) acc: 0.4066666666666667\n",
      "2449 loss: tensor(1.0622) acc: 0.4066666666666667\n",
      "2450 loss: tensor(1.0622) acc: 0.4066666666666667\n",
      "2451 loss: tensor(1.0621) acc: 0.4066666666666667\n",
      "2452 loss: tensor(1.0620) acc: 0.4066666666666667\n",
      "2453 loss: tensor(1.0619) acc: 0.4066666666666667\n",
      "2454 loss: tensor(1.0619) acc: 0.4066666666666667\n",
      "2455 loss: tensor(1.0618) acc: 0.4066666666666667\n",
      "2456 loss: tensor(1.0617) acc: 0.4066666666666667\n",
      "2457 loss: tensor(1.0617) acc: 0.4066666666666667\n",
      "2458 loss: tensor(1.0616) acc: 0.4\n",
      "2459 loss: tensor(1.0615) acc: 0.3933333333333333\n",
      "2460 loss: tensor(1.0615) acc: 0.3933333333333333\n",
      "2461 loss: tensor(1.0614) acc: 0.3933333333333333\n",
      "2462 loss: tensor(1.0613) acc: 0.3933333333333333\n",
      "2463 loss: tensor(1.0612) acc: 0.3933333333333333\n",
      "2464 loss: tensor(1.0612) acc: 0.3933333333333333\n",
      "2465 loss: tensor(1.0611) acc: 0.3933333333333333\n",
      "2466 loss: tensor(1.0610) acc: 0.3933333333333333\n",
      "2467 loss: tensor(1.0610) acc: 0.3933333333333333\n",
      "2468 loss: tensor(1.0609) acc: 0.3933333333333333\n",
      "2469 loss: tensor(1.0608) acc: 0.3933333333333333\n",
      "2470 loss: tensor(1.0607) acc: 0.3933333333333333\n",
      "2471 loss: tensor(1.0607) acc: 0.3933333333333333\n",
      "2472 loss: tensor(1.0606) acc: 0.3933333333333333\n",
      "2473 loss: tensor(1.0605) acc: 0.3933333333333333\n",
      "2474 loss: tensor(1.0605) acc: 0.3933333333333333\n",
      "2475 loss: tensor(1.0604) acc: 0.3933333333333333\n",
      "2476 loss: tensor(1.0603) acc: 0.3933333333333333\n",
      "2477 loss: tensor(1.0602) acc: 0.3933333333333333\n",
      "2478 loss: tensor(1.0602) acc: 0.3933333333333333\n",
      "2479 loss: tensor(1.0601) acc: 0.3933333333333333\n",
      "2480 loss: tensor(1.0600) acc: 0.3933333333333333\n",
      "2481 loss: tensor(1.0600) acc: 0.3933333333333333\n",
      "2482 loss: tensor(1.0599) acc: 0.3933333333333333\n",
      "2483 loss: tensor(1.0598) acc: 0.3933333333333333\n",
      "2484 loss: tensor(1.0597) acc: 0.3933333333333333\n",
      "2485 loss: tensor(1.0597) acc: 0.3933333333333333\n",
      "2486 loss: tensor(1.0596) acc: 0.3933333333333333\n",
      "2487 loss: tensor(1.0595) acc: 0.3933333333333333\n",
      "2488 loss: tensor(1.0595) acc: 0.3933333333333333\n",
      "2489 loss: tensor(1.0594) acc: 0.3933333333333333\n",
      "2490 loss: tensor(1.0593) acc: 0.3933333333333333\n",
      "2491 loss: tensor(1.0592) acc: 0.3933333333333333\n",
      "2492 loss: tensor(1.0592) acc: 0.3933333333333333\n",
      "2493 loss: tensor(1.0591) acc: 0.3933333333333333\n",
      "2494 loss: tensor(1.0590) acc: 0.3933333333333333\n",
      "2495 loss: tensor(1.0590) acc: 0.3933333333333333\n",
      "2496 loss: tensor(1.0589) acc: 0.3933333333333333\n",
      "2497 loss: tensor(1.0588) acc: 0.3933333333333333\n",
      "2498 loss: tensor(1.0587) acc: 0.3933333333333333\n",
      "2499 loss: tensor(1.0587) acc: 0.3933333333333333\n",
      "2500 loss: tensor(1.0586) acc: 0.3933333333333333\n",
      "2501 loss: tensor(1.0585) acc: 0.3933333333333333\n",
      "2502 loss: tensor(1.0585) acc: 0.3933333333333333\n",
      "2503 loss: tensor(1.0584) acc: 0.3933333333333333\n",
      "2504 loss: tensor(1.0583) acc: 0.3933333333333333\n",
      "2505 loss: tensor(1.0582) acc: 0.3933333333333333\n",
      "2506 loss: tensor(1.0582) acc: 0.3933333333333333\n",
      "2507 loss: tensor(1.0581) acc: 0.3933333333333333\n",
      "2508 loss: tensor(1.0580) acc: 0.3933333333333333\n",
      "2509 loss: tensor(1.0580) acc: 0.3933333333333333\n",
      "2510 loss: tensor(1.0579) acc: 0.3933333333333333\n",
      "2511 loss: tensor(1.0578) acc: 0.3933333333333333\n",
      "2512 loss: tensor(1.0577) acc: 0.3933333333333333\n",
      "2513 loss: tensor(1.0577) acc: 0.3933333333333333\n",
      "2514 loss: tensor(1.0576) acc: 0.3933333333333333\n",
      "2515 loss: tensor(1.0575) acc: 0.3933333333333333\n",
      "2516 loss: tensor(1.0574) acc: 0.3933333333333333\n",
      "2517 loss: tensor(1.0574) acc: 0.3933333333333333\n",
      "2518 loss: tensor(1.0573) acc: 0.3933333333333333\n",
      "2519 loss: tensor(1.0572) acc: 0.3933333333333333\n",
      "2520 loss: tensor(1.0572) acc: 0.3933333333333333\n",
      "2521 loss: tensor(1.0571) acc: 0.3933333333333333\n",
      "2522 loss: tensor(1.0570) acc: 0.3933333333333333\n",
      "2523 loss: tensor(1.0569) acc: 0.3933333333333333\n",
      "2524 loss: tensor(1.0569) acc: 0.3933333333333333\n",
      "2525 loss: tensor(1.0568) acc: 0.3933333333333333\n",
      "2526 loss: tensor(1.0567) acc: 0.3933333333333333\n",
      "2527 loss: tensor(1.0566) acc: 0.3933333333333333\n",
      "2528 loss: tensor(1.0566) acc: 0.3933333333333333\n",
      "2529 loss: tensor(1.0565) acc: 0.3933333333333333\n",
      "2530 loss: tensor(1.0564) acc: 0.3933333333333333\n",
      "2531 loss: tensor(1.0564) acc: 0.3933333333333333\n",
      "2532 loss: tensor(1.0563) acc: 0.3933333333333333\n",
      "2533 loss: tensor(1.0562) acc: 0.3933333333333333\n",
      "2534 loss: tensor(1.0561) acc: 0.3933333333333333\n",
      "2535 loss: tensor(1.0561) acc: 0.3933333333333333\n",
      "2536 loss: tensor(1.0560) acc: 0.3933333333333333\n",
      "2537 loss: tensor(1.0559) acc: 0.3933333333333333\n",
      "2538 loss: tensor(1.0558) acc: 0.3933333333333333\n",
      "2539 loss: tensor(1.0558) acc: 0.3933333333333333\n",
      "2540 loss: tensor(1.0557) acc: 0.3933333333333333\n",
      "2541 loss: tensor(1.0556) acc: 0.3933333333333333\n",
      "2542 loss: tensor(1.0556) acc: 0.3933333333333333\n",
      "2543 loss: tensor(1.0555) acc: 0.3933333333333333\n",
      "2544 loss: tensor(1.0554) acc: 0.3933333333333333\n",
      "2545 loss: tensor(1.0553) acc: 0.3933333333333333\n",
      "2546 loss: tensor(1.0553) acc: 0.3933333333333333\n",
      "2547 loss: tensor(1.0552) acc: 0.3933333333333333\n",
      "2548 loss: tensor(1.0551) acc: 0.3933333333333333\n",
      "2549 loss: tensor(1.0550) acc: 0.3933333333333333\n",
      "2550 loss: tensor(1.0550) acc: 0.3933333333333333\n",
      "2551 loss: tensor(1.0549) acc: 0.3933333333333333\n",
      "2552 loss: tensor(1.0548) acc: 0.3933333333333333\n",
      "2553 loss: tensor(1.0547) acc: 0.3933333333333333\n",
      "2554 loss: tensor(1.0547) acc: 0.3933333333333333\n",
      "2555 loss: tensor(1.0546) acc: 0.3933333333333333\n",
      "2556 loss: tensor(1.0545) acc: 0.3933333333333333\n",
      "2557 loss: tensor(1.0544) acc: 0.3933333333333333\n",
      "2558 loss: tensor(1.0544) acc: 0.3933333333333333\n",
      "2559 loss: tensor(1.0543) acc: 0.3933333333333333\n",
      "2560 loss: tensor(1.0542) acc: 0.3933333333333333\n",
      "2561 loss: tensor(1.0541) acc: 0.3933333333333333\n",
      "2562 loss: tensor(1.0541) acc: 0.3933333333333333\n",
      "2563 loss: tensor(1.0540) acc: 0.3933333333333333\n",
      "2564 loss: tensor(1.0539) acc: 0.3933333333333333\n",
      "2565 loss: tensor(1.0539) acc: 0.3933333333333333\n",
      "2566 loss: tensor(1.0538) acc: 0.3933333333333333\n",
      "2567 loss: tensor(1.0537) acc: 0.3933333333333333\n",
      "2568 loss: tensor(1.0536) acc: 0.3933333333333333\n",
      "2569 loss: tensor(1.0536) acc: 0.3933333333333333\n",
      "2570 loss: tensor(1.0535) acc: 0.3933333333333333\n",
      "2571 loss: tensor(1.0534) acc: 0.3933333333333333\n",
      "2572 loss: tensor(1.0533) acc: 0.3933333333333333\n",
      "2573 loss: tensor(1.0533) acc: 0.3933333333333333\n",
      "2574 loss: tensor(1.0532) acc: 0.3933333333333333\n",
      "2575 loss: tensor(1.0531) acc: 0.3933333333333333\n",
      "2576 loss: tensor(1.0530) acc: 0.3933333333333333\n",
      "2577 loss: tensor(1.0530) acc: 0.3933333333333333\n",
      "2578 loss: tensor(1.0529) acc: 0.3933333333333333\n",
      "2579 loss: tensor(1.0528) acc: 0.3933333333333333\n",
      "2580 loss: tensor(1.0527) acc: 0.3933333333333333\n",
      "2581 loss: tensor(1.0527) acc: 0.3933333333333333\n",
      "2582 loss: tensor(1.0526) acc: 0.3933333333333333\n",
      "2583 loss: tensor(1.0525) acc: 0.3933333333333333\n",
      "2584 loss: tensor(1.0524) acc: 0.3933333333333333\n",
      "2585 loss: tensor(1.0524) acc: 0.3933333333333333\n",
      "2586 loss: tensor(1.0523) acc: 0.3933333333333333\n",
      "2587 loss: tensor(1.0522) acc: 0.3933333333333333\n",
      "2588 loss: tensor(1.0521) acc: 0.3933333333333333\n",
      "2589 loss: tensor(1.0521) acc: 0.3933333333333333\n",
      "2590 loss: tensor(1.0520) acc: 0.3933333333333333\n",
      "2591 loss: tensor(1.0519) acc: 0.3933333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592 loss: tensor(1.0518) acc: 0.3933333333333333\n",
      "2593 loss: tensor(1.0518) acc: 0.3933333333333333\n",
      "2594 loss: tensor(1.0517) acc: 0.3933333333333333\n",
      "2595 loss: tensor(1.0516) acc: 0.3933333333333333\n",
      "2596 loss: tensor(1.0515) acc: 0.3933333333333333\n",
      "2597 loss: tensor(1.0515) acc: 0.3933333333333333\n",
      "2598 loss: tensor(1.0514) acc: 0.3933333333333333\n",
      "2599 loss: tensor(1.0513) acc: 0.3933333333333333\n",
      "2600 loss: tensor(1.0512) acc: 0.3933333333333333\n",
      "2601 loss: tensor(1.0511) acc: 0.3933333333333333\n",
      "2602 loss: tensor(1.0511) acc: 0.3933333333333333\n",
      "2603 loss: tensor(1.0510) acc: 0.3933333333333333\n",
      "2604 loss: tensor(1.0509) acc: 0.3933333333333333\n",
      "2605 loss: tensor(1.0508) acc: 0.3933333333333333\n",
      "2606 loss: tensor(1.0508) acc: 0.3933333333333333\n",
      "2607 loss: tensor(1.0507) acc: 0.3933333333333333\n",
      "2608 loss: tensor(1.0506) acc: 0.3933333333333333\n",
      "2609 loss: tensor(1.0505) acc: 0.3933333333333333\n",
      "2610 loss: tensor(1.0505) acc: 0.3933333333333333\n",
      "2611 loss: tensor(1.0504) acc: 0.3933333333333333\n",
      "2612 loss: tensor(1.0503) acc: 0.3933333333333333\n",
      "2613 loss: tensor(1.0502) acc: 0.3933333333333333\n",
      "2614 loss: tensor(1.0502) acc: 0.4\n",
      "2615 loss: tensor(1.0501) acc: 0.4\n",
      "2616 loss: tensor(1.0500) acc: 0.4\n",
      "2617 loss: tensor(1.0499) acc: 0.4\n",
      "2618 loss: tensor(1.0498) acc: 0.4\n",
      "2619 loss: tensor(1.0498) acc: 0.4\n",
      "2620 loss: tensor(1.0497) acc: 0.4\n",
      "2621 loss: tensor(1.0496) acc: 0.4\n",
      "2622 loss: tensor(1.0495) acc: 0.4\n",
      "2623 loss: tensor(1.0495) acc: 0.4\n",
      "2624 loss: tensor(1.0494) acc: 0.4\n",
      "2625 loss: tensor(1.0493) acc: 0.4\n",
      "2626 loss: tensor(1.0492) acc: 0.4\n",
      "2627 loss: tensor(1.0492) acc: 0.4\n",
      "2628 loss: tensor(1.0491) acc: 0.4\n",
      "2629 loss: tensor(1.0490) acc: 0.4\n",
      "2630 loss: tensor(1.0489) acc: 0.4\n",
      "2631 loss: tensor(1.0488) acc: 0.4066666666666667\n",
      "2632 loss: tensor(1.0488) acc: 0.4066666666666667\n",
      "2633 loss: tensor(1.0487) acc: 0.4066666666666667\n",
      "2634 loss: tensor(1.0486) acc: 0.4066666666666667\n",
      "2635 loss: tensor(1.0485) acc: 0.4066666666666667\n",
      "2636 loss: tensor(1.0485) acc: 0.4066666666666667\n",
      "2637 loss: tensor(1.0484) acc: 0.4066666666666667\n",
      "2638 loss: tensor(1.0483) acc: 0.4066666666666667\n",
      "2639 loss: tensor(1.0482) acc: 0.4066666666666667\n",
      "2640 loss: tensor(1.0481) acc: 0.4066666666666667\n",
      "2641 loss: tensor(1.0481) acc: 0.4066666666666667\n",
      "2642 loss: tensor(1.0480) acc: 0.4066666666666667\n",
      "2643 loss: tensor(1.0479) acc: 0.4066666666666667\n",
      "2644 loss: tensor(1.0478) acc: 0.4066666666666667\n",
      "2645 loss: tensor(1.0478) acc: 0.4\n",
      "2646 loss: tensor(1.0477) acc: 0.4\n",
      "2647 loss: tensor(1.0476) acc: 0.4\n",
      "2648 loss: tensor(1.0475) acc: 0.4\n",
      "2649 loss: tensor(1.0474) acc: 0.4\n",
      "2650 loss: tensor(1.0474) acc: 0.4\n",
      "2651 loss: tensor(1.0473) acc: 0.4\n",
      "2652 loss: tensor(1.0472) acc: 0.4\n",
      "2653 loss: tensor(1.0471) acc: 0.4\n",
      "2654 loss: tensor(1.0471) acc: 0.4\n",
      "2655 loss: tensor(1.0470) acc: 0.4\n",
      "2656 loss: tensor(1.0469) acc: 0.4\n",
      "2657 loss: tensor(1.0468) acc: 0.4\n",
      "2658 loss: tensor(1.0467) acc: 0.4\n",
      "2659 loss: tensor(1.0467) acc: 0.4\n",
      "2660 loss: tensor(1.0466) acc: 0.4\n",
      "2661 loss: tensor(1.0465) acc: 0.4\n",
      "2662 loss: tensor(1.0464) acc: 0.4\n",
      "2663 loss: tensor(1.0463) acc: 0.4\n",
      "2664 loss: tensor(1.0463) acc: 0.4\n",
      "2665 loss: tensor(1.0462) acc: 0.4\n",
      "2666 loss: tensor(1.0461) acc: 0.4\n",
      "2667 loss: tensor(1.0460) acc: 0.4\n",
      "2668 loss: tensor(1.0459) acc: 0.4\n",
      "2669 loss: tensor(1.0459) acc: 0.4\n",
      "2670 loss: tensor(1.0458) acc: 0.4\n",
      "2671 loss: tensor(1.0457) acc: 0.4\n",
      "2672 loss: tensor(1.0456) acc: 0.4\n",
      "2673 loss: tensor(1.0456) acc: 0.4\n",
      "2674 loss: tensor(1.0455) acc: 0.4\n",
      "2675 loss: tensor(1.0454) acc: 0.4\n",
      "2676 loss: tensor(1.0453) acc: 0.4\n",
      "2677 loss: tensor(1.0452) acc: 0.4\n",
      "2678 loss: tensor(1.0452) acc: 0.4\n",
      "2679 loss: tensor(1.0451) acc: 0.4\n",
      "2680 loss: tensor(1.0450) acc: 0.4\n",
      "2681 loss: tensor(1.0449) acc: 0.4\n",
      "2682 loss: tensor(1.0448) acc: 0.4\n",
      "2683 loss: tensor(1.0448) acc: 0.4\n",
      "2684 loss: tensor(1.0447) acc: 0.4\n",
      "2685 loss: tensor(1.0446) acc: 0.4\n",
      "2686 loss: tensor(1.0445) acc: 0.4\n",
      "2687 loss: tensor(1.0444) acc: 0.4\n",
      "2688 loss: tensor(1.0444) acc: 0.4\n",
      "2689 loss: tensor(1.0443) acc: 0.4\n",
      "2690 loss: tensor(1.0442) acc: 0.4\n",
      "2691 loss: tensor(1.0441) acc: 0.4\n",
      "2692 loss: tensor(1.0440) acc: 0.4\n",
      "2693 loss: tensor(1.0440) acc: 0.4\n",
      "2694 loss: tensor(1.0439) acc: 0.4\n",
      "2695 loss: tensor(1.0438) acc: 0.4\n",
      "2696 loss: tensor(1.0437) acc: 0.4\n",
      "2697 loss: tensor(1.0436) acc: 0.4\n",
      "2698 loss: tensor(1.0435) acc: 0.4\n",
      "2699 loss: tensor(1.0435) acc: 0.4\n",
      "2700 loss: tensor(1.0434) acc: 0.4\n",
      "2701 loss: tensor(1.0433) acc: 0.3933333333333333\n",
      "2702 loss: tensor(1.0432) acc: 0.3933333333333333\n",
      "2703 loss: tensor(1.0431) acc: 0.3933333333333333\n",
      "2704 loss: tensor(1.0431) acc: 0.3933333333333333\n",
      "2705 loss: tensor(1.0430) acc: 0.3933333333333333\n",
      "2706 loss: tensor(1.0429) acc: 0.3933333333333333\n",
      "2707 loss: tensor(1.0428) acc: 0.3933333333333333\n",
      "2708 loss: tensor(1.0427) acc: 0.3933333333333333\n",
      "2709 loss: tensor(1.0427) acc: 0.3933333333333333\n",
      "2710 loss: tensor(1.0426) acc: 0.3933333333333333\n",
      "2711 loss: tensor(1.0425) acc: 0.3933333333333333\n",
      "2712 loss: tensor(1.0424) acc: 0.3933333333333333\n",
      "2713 loss: tensor(1.0423) acc: 0.3933333333333333\n",
      "2714 loss: tensor(1.0422) acc: 0.3933333333333333\n",
      "2715 loss: tensor(1.0422) acc: 0.3933333333333333\n",
      "2716 loss: tensor(1.0421) acc: 0.4\n",
      "2717 loss: tensor(1.0420) acc: 0.4\n",
      "2718 loss: tensor(1.0419) acc: 0.4\n",
      "2719 loss: tensor(1.0418) acc: 0.4\n",
      "2720 loss: tensor(1.0418) acc: 0.4\n",
      "2721 loss: tensor(1.0417) acc: 0.4\n",
      "2722 loss: tensor(1.0416) acc: 0.4\n",
      "2723 loss: tensor(1.0415) acc: 0.4\n",
      "2724 loss: tensor(1.0414) acc: 0.4\n",
      "2725 loss: tensor(1.0413) acc: 0.4\n",
      "2726 loss: tensor(1.0413) acc: 0.4\n",
      "2727 loss: tensor(1.0412) acc: 0.4\n",
      "2728 loss: tensor(1.0411) acc: 0.4\n",
      "2729 loss: tensor(1.0410) acc: 0.4\n",
      "2730 loss: tensor(1.0409) acc: 0.4\n",
      "2731 loss: tensor(1.0408) acc: 0.4\n",
      "2732 loss: tensor(1.0408) acc: 0.4\n",
      "2733 loss: tensor(1.0407) acc: 0.4\n",
      "2734 loss: tensor(1.0406) acc: 0.4\n",
      "2735 loss: tensor(1.0405) acc: 0.4\n",
      "2736 loss: tensor(1.0404) acc: 0.4\n",
      "2737 loss: tensor(1.0404) acc: 0.4\n",
      "2738 loss: tensor(1.0403) acc: 0.4\n",
      "2739 loss: tensor(1.0402) acc: 0.4\n",
      "2740 loss: tensor(1.0401) acc: 0.4066666666666667\n",
      "2741 loss: tensor(1.0400) acc: 0.4066666666666667\n",
      "2742 loss: tensor(1.0399) acc: 0.4066666666666667\n",
      "2743 loss: tensor(1.0399) acc: 0.4066666666666667\n",
      "2744 loss: tensor(1.0398) acc: 0.4066666666666667\n",
      "2745 loss: tensor(1.0397) acc: 0.4066666666666667\n",
      "2746 loss: tensor(1.0396) acc: 0.4066666666666667\n",
      "2747 loss: tensor(1.0395) acc: 0.4066666666666667\n",
      "2748 loss: tensor(1.0394) acc: 0.4066666666666667\n",
      "2749 loss: tensor(1.0394) acc: 0.4066666666666667\n",
      "2750 loss: tensor(1.0393) acc: 0.4066666666666667\n",
      "2751 loss: tensor(1.0392) acc: 0.4066666666666667\n",
      "2752 loss: tensor(1.0391) acc: 0.4066666666666667\n",
      "2753 loss: tensor(1.0390) acc: 0.4\n",
      "2754 loss: tensor(1.0389) acc: 0.4\n",
      "2755 loss: tensor(1.0388) acc: 0.4\n",
      "2756 loss: tensor(1.0388) acc: 0.4\n",
      "2757 loss: tensor(1.0387) acc: 0.4\n",
      "2758 loss: tensor(1.0386) acc: 0.4\n",
      "2759 loss: tensor(1.0385) acc: 0.4\n",
      "2760 loss: tensor(1.0384) acc: 0.4\n",
      "2761 loss: tensor(1.0383) acc: 0.4\n",
      "2762 loss: tensor(1.0383) acc: 0.4\n",
      "2763 loss: tensor(1.0382) acc: 0.4\n",
      "2764 loss: tensor(1.0381) acc: 0.4\n",
      "2765 loss: tensor(1.0380) acc: 0.4\n",
      "2766 loss: tensor(1.0379) acc: 0.4\n",
      "2767 loss: tensor(1.0378) acc: 0.4\n",
      "2768 loss: tensor(1.0378) acc: 0.4\n",
      "2769 loss: tensor(1.0377) acc: 0.4\n",
      "2770 loss: tensor(1.0376) acc: 0.4\n",
      "2771 loss: tensor(1.0375) acc: 0.4\n",
      "2772 loss: tensor(1.0374) acc: 0.4\n",
      "2773 loss: tensor(1.0373) acc: 0.4\n",
      "2774 loss: tensor(1.0372) acc: 0.4\n",
      "2775 loss: tensor(1.0372) acc: 0.4\n",
      "2776 loss: tensor(1.0371) acc: 0.4\n",
      "2777 loss: tensor(1.0370) acc: 0.4\n",
      "2778 loss: tensor(1.0369) acc: 0.4\n",
      "2779 loss: tensor(1.0368) acc: 0.4\n",
      "2780 loss: tensor(1.0367) acc: 0.4\n",
      "2781 loss: tensor(1.0366) acc: 0.4\n",
      "2782 loss: tensor(1.0366) acc: 0.4\n",
      "2783 loss: tensor(1.0365) acc: 0.4\n",
      "2784 loss: tensor(1.0364) acc: 0.4\n",
      "2785 loss: tensor(1.0363) acc: 0.4\n",
      "2786 loss: tensor(1.0362) acc: 0.4\n",
      "2787 loss: tensor(1.0361) acc: 0.4\n",
      "2788 loss: tensor(1.0360) acc: 0.4\n",
      "2789 loss: tensor(1.0360) acc: 0.4\n",
      "2790 loss: tensor(1.0359) acc: 0.3933333333333333\n",
      "2791 loss: tensor(1.0358) acc: 0.3933333333333333\n",
      "2792 loss: tensor(1.0357) acc: 0.3933333333333333\n",
      "2793 loss: tensor(1.0356) acc: 0.3933333333333333\n",
      "2794 loss: tensor(1.0355) acc: 0.3933333333333333\n",
      "2795 loss: tensor(1.0354) acc: 0.3933333333333333\n",
      "2796 loss: tensor(1.0354) acc: 0.3933333333333333\n",
      "2797 loss: tensor(1.0353) acc: 0.3933333333333333\n",
      "2798 loss: tensor(1.0352) acc: 0.3933333333333333\n",
      "2799 loss: tensor(1.0351) acc: 0.3933333333333333\n",
      "2800 loss: tensor(1.0350) acc: 0.3933333333333333\n",
      "2801 loss: tensor(1.0349) acc: 0.3933333333333333\n",
      "2802 loss: tensor(1.0348) acc: 0.3933333333333333\n",
      "2803 loss: tensor(1.0347) acc: 0.3933333333333333\n",
      "2804 loss: tensor(1.0347) acc: 0.3933333333333333\n",
      "2805 loss: tensor(1.0346) acc: 0.3933333333333333\n",
      "2806 loss: tensor(1.0345) acc: 0.3933333333333333\n",
      "2807 loss: tensor(1.0344) acc: 0.3933333333333333\n",
      "2808 loss: tensor(1.0343) acc: 0.3933333333333333\n",
      "2809 loss: tensor(1.0342) acc: 0.3933333333333333\n",
      "2810 loss: tensor(1.0341) acc: 0.3933333333333333\n",
      "2811 loss: tensor(1.0341) acc: 0.3933333333333333\n",
      "2812 loss: tensor(1.0340) acc: 0.3933333333333333\n",
      "2813 loss: tensor(1.0339) acc: 0.3933333333333333\n",
      "2814 loss: tensor(1.0338) acc: 0.3933333333333333\n",
      "2815 loss: tensor(1.0337) acc: 0.3933333333333333\n",
      "2816 loss: tensor(1.0336) acc: 0.3933333333333333\n",
      "2817 loss: tensor(1.0335) acc: 0.3933333333333333\n",
      "2818 loss: tensor(1.0334) acc: 0.3933333333333333\n",
      "2819 loss: tensor(1.0334) acc: 0.3933333333333333\n",
      "2820 loss: tensor(1.0333) acc: 0.3933333333333333\n",
      "2821 loss: tensor(1.0332) acc: 0.3933333333333333\n",
      "2822 loss: tensor(1.0331) acc: 0.3933333333333333\n",
      "2823 loss: tensor(1.0330) acc: 0.3933333333333333\n",
      "2824 loss: tensor(1.0329) acc: 0.3933333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825 loss: tensor(1.0328) acc: 0.3933333333333333\n",
      "2826 loss: tensor(1.0327) acc: 0.3933333333333333\n",
      "2827 loss: tensor(1.0327) acc: 0.3933333333333333\n",
      "2828 loss: tensor(1.0326) acc: 0.3933333333333333\n",
      "2829 loss: tensor(1.0325) acc: 0.3933333333333333\n",
      "2830 loss: tensor(1.0324) acc: 0.3933333333333333\n",
      "2831 loss: tensor(1.0323) acc: 0.3933333333333333\n",
      "2832 loss: tensor(1.0322) acc: 0.3933333333333333\n",
      "2833 loss: tensor(1.0321) acc: 0.3933333333333333\n",
      "2834 loss: tensor(1.0320) acc: 0.3933333333333333\n",
      "2835 loss: tensor(1.0319) acc: 0.3933333333333333\n",
      "2836 loss: tensor(1.0319) acc: 0.3933333333333333\n",
      "2837 loss: tensor(1.0318) acc: 0.3933333333333333\n",
      "2838 loss: tensor(1.0317) acc: 0.3933333333333333\n",
      "2839 loss: tensor(1.0316) acc: 0.3933333333333333\n",
      "2840 loss: tensor(1.0315) acc: 0.3933333333333333\n",
      "2841 loss: tensor(1.0314) acc: 0.3933333333333333\n",
      "2842 loss: tensor(1.0313) acc: 0.3933333333333333\n",
      "2843 loss: tensor(1.0312) acc: 0.3933333333333333\n",
      "2844 loss: tensor(1.0311) acc: 0.3933333333333333\n",
      "2845 loss: tensor(1.0311) acc: 0.3933333333333333\n",
      "2846 loss: tensor(1.0310) acc: 0.3933333333333333\n",
      "2847 loss: tensor(1.0309) acc: 0.3933333333333333\n",
      "2848 loss: tensor(1.0308) acc: 0.3933333333333333\n",
      "2849 loss: tensor(1.0307) acc: 0.3933333333333333\n",
      "2850 loss: tensor(1.0306) acc: 0.3933333333333333\n",
      "2851 loss: tensor(1.0305) acc: 0.3933333333333333\n",
      "2852 loss: tensor(1.0304) acc: 0.3933333333333333\n",
      "2853 loss: tensor(1.0303) acc: 0.3933333333333333\n",
      "2854 loss: tensor(1.0302) acc: 0.3933333333333333\n",
      "2855 loss: tensor(1.0302) acc: 0.3933333333333333\n",
      "2856 loss: tensor(1.0301) acc: 0.3933333333333333\n",
      "2857 loss: tensor(1.0300) acc: 0.38666666666666666\n",
      "2858 loss: tensor(1.0299) acc: 0.38666666666666666\n",
      "2859 loss: tensor(1.0298) acc: 0.38666666666666666\n",
      "2860 loss: tensor(1.0297) acc: 0.38666666666666666\n",
      "2861 loss: tensor(1.0296) acc: 0.38666666666666666\n",
      "2862 loss: tensor(1.0295) acc: 0.38666666666666666\n",
      "2863 loss: tensor(1.0294) acc: 0.38666666666666666\n",
      "2864 loss: tensor(1.0294) acc: 0.38666666666666666\n",
      "2865 loss: tensor(1.0293) acc: 0.38666666666666666\n",
      "2866 loss: tensor(1.0292) acc: 0.38666666666666666\n",
      "2867 loss: tensor(1.0291) acc: 0.38666666666666666\n",
      "2868 loss: tensor(1.0290) acc: 0.38\n",
      "2869 loss: tensor(1.0289) acc: 0.38\n",
      "2870 loss: tensor(1.0288) acc: 0.38\n",
      "2871 loss: tensor(1.0287) acc: 0.38\n",
      "2872 loss: tensor(1.0286) acc: 0.38\n",
      "2873 loss: tensor(1.0285) acc: 0.38\n",
      "2874 loss: tensor(1.0284) acc: 0.38\n",
      "2875 loss: tensor(1.0284) acc: 0.37333333333333335\n",
      "2876 loss: tensor(1.0283) acc: 0.37333333333333335\n",
      "2877 loss: tensor(1.0282) acc: 0.37333333333333335\n",
      "2878 loss: tensor(1.0281) acc: 0.37333333333333335\n",
      "2879 loss: tensor(1.0280) acc: 0.37333333333333335\n",
      "2880 loss: tensor(1.0279) acc: 0.37333333333333335\n",
      "2881 loss: tensor(1.0278) acc: 0.37333333333333335\n",
      "2882 loss: tensor(1.0277) acc: 0.37333333333333335\n",
      "2883 loss: tensor(1.0276) acc: 0.37333333333333335\n",
      "2884 loss: tensor(1.0275) acc: 0.37333333333333335\n",
      "2885 loss: tensor(1.0274) acc: 0.37333333333333335\n",
      "2886 loss: tensor(1.0274) acc: 0.37333333333333335\n",
      "2887 loss: tensor(1.0273) acc: 0.37333333333333335\n",
      "2888 loss: tensor(1.0272) acc: 0.37333333333333335\n",
      "2889 loss: tensor(1.0271) acc: 0.37333333333333335\n",
      "2890 loss: tensor(1.0270) acc: 0.37333333333333335\n",
      "2891 loss: tensor(1.0269) acc: 0.37333333333333335\n",
      "2892 loss: tensor(1.0268) acc: 0.37333333333333335\n",
      "2893 loss: tensor(1.0267) acc: 0.37333333333333335\n",
      "2894 loss: tensor(1.0266) acc: 0.37333333333333335\n",
      "2895 loss: tensor(1.0265) acc: 0.37333333333333335\n",
      "2896 loss: tensor(1.0264) acc: 0.37333333333333335\n",
      "2897 loss: tensor(1.0263) acc: 0.37333333333333335\n",
      "2898 loss: tensor(1.0263) acc: 0.37333333333333335\n",
      "2899 loss: tensor(1.0262) acc: 0.37333333333333335\n",
      "2900 loss: tensor(1.0261) acc: 0.36666666666666664\n",
      "2901 loss: tensor(1.0260) acc: 0.36666666666666664\n",
      "2902 loss: tensor(1.0259) acc: 0.36666666666666664\n",
      "2903 loss: tensor(1.0258) acc: 0.36666666666666664\n",
      "2904 loss: tensor(1.0257) acc: 0.36666666666666664\n",
      "2905 loss: tensor(1.0256) acc: 0.36666666666666664\n",
      "2906 loss: tensor(1.0255) acc: 0.36666666666666664\n",
      "2907 loss: tensor(1.0254) acc: 0.36666666666666664\n",
      "2908 loss: tensor(1.0253) acc: 0.36666666666666664\n",
      "2909 loss: tensor(1.0252) acc: 0.36666666666666664\n",
      "2910 loss: tensor(1.0251) acc: 0.36666666666666664\n",
      "2911 loss: tensor(1.0251) acc: 0.36666666666666664\n",
      "2912 loss: tensor(1.0250) acc: 0.36666666666666664\n",
      "2913 loss: tensor(1.0249) acc: 0.36666666666666664\n",
      "2914 loss: tensor(1.0248) acc: 0.36666666666666664\n",
      "2915 loss: tensor(1.0247) acc: 0.36666666666666664\n",
      "2916 loss: tensor(1.0246) acc: 0.36666666666666664\n",
      "2917 loss: tensor(1.0245) acc: 0.36666666666666664\n",
      "2918 loss: tensor(1.0244) acc: 0.36666666666666664\n",
      "2919 loss: tensor(1.0243) acc: 0.36666666666666664\n",
      "2920 loss: tensor(1.0242) acc: 0.36666666666666664\n",
      "2921 loss: tensor(1.0241) acc: 0.36666666666666664\n",
      "2922 loss: tensor(1.0240) acc: 0.36666666666666664\n",
      "2923 loss: tensor(1.0239) acc: 0.36666666666666664\n",
      "2924 loss: tensor(1.0238) acc: 0.36666666666666664\n",
      "2925 loss: tensor(1.0238) acc: 0.36666666666666664\n",
      "2926 loss: tensor(1.0237) acc: 0.36666666666666664\n",
      "2927 loss: tensor(1.0236) acc: 0.36666666666666664\n",
      "2928 loss: tensor(1.0235) acc: 0.36666666666666664\n",
      "2929 loss: tensor(1.0234) acc: 0.36666666666666664\n",
      "2930 loss: tensor(1.0233) acc: 0.36666666666666664\n",
      "2931 loss: tensor(1.0232) acc: 0.36666666666666664\n",
      "2932 loss: tensor(1.0231) acc: 0.36666666666666664\n",
      "2933 loss: tensor(1.0230) acc: 0.36666666666666664\n",
      "2934 loss: tensor(1.0229) acc: 0.36666666666666664\n",
      "2935 loss: tensor(1.0228) acc: 0.36666666666666664\n",
      "2936 loss: tensor(1.0227) acc: 0.36666666666666664\n",
      "2937 loss: tensor(1.0226) acc: 0.36666666666666664\n",
      "2938 loss: tensor(1.0225) acc: 0.36666666666666664\n",
      "2939 loss: tensor(1.0224) acc: 0.36666666666666664\n",
      "2940 loss: tensor(1.0223) acc: 0.36666666666666664\n",
      "2941 loss: tensor(1.0223) acc: 0.36666666666666664\n",
      "2942 loss: tensor(1.0222) acc: 0.36666666666666664\n",
      "2943 loss: tensor(1.0221) acc: 0.36666666666666664\n",
      "2944 loss: tensor(1.0220) acc: 0.36666666666666664\n",
      "2945 loss: tensor(1.0219) acc: 0.36666666666666664\n",
      "2946 loss: tensor(1.0218) acc: 0.36666666666666664\n",
      "2947 loss: tensor(1.0217) acc: 0.36666666666666664\n",
      "2948 loss: tensor(1.0216) acc: 0.36666666666666664\n",
      "2949 loss: tensor(1.0215) acc: 0.36666666666666664\n",
      "2950 loss: tensor(1.0214) acc: 0.36666666666666664\n",
      "2951 loss: tensor(1.0213) acc: 0.36666666666666664\n",
      "2952 loss: tensor(1.0212) acc: 0.36666666666666664\n",
      "2953 loss: tensor(1.0211) acc: 0.36666666666666664\n",
      "2954 loss: tensor(1.0210) acc: 0.36666666666666664\n",
      "2955 loss: tensor(1.0209) acc: 0.36666666666666664\n",
      "2956 loss: tensor(1.0208) acc: 0.36666666666666664\n",
      "2957 loss: tensor(1.0207) acc: 0.36666666666666664\n",
      "2958 loss: tensor(1.0206) acc: 0.36666666666666664\n",
      "2959 loss: tensor(1.0206) acc: 0.36666666666666664\n",
      "2960 loss: tensor(1.0205) acc: 0.36666666666666664\n",
      "2961 loss: tensor(1.0204) acc: 0.36666666666666664\n",
      "2962 loss: tensor(1.0203) acc: 0.36666666666666664\n",
      "2963 loss: tensor(1.0202) acc: 0.36666666666666664\n",
      "2964 loss: tensor(1.0201) acc: 0.36\n",
      "2965 loss: tensor(1.0200) acc: 0.36\n",
      "2966 loss: tensor(1.0199) acc: 0.36\n",
      "2967 loss: tensor(1.0198) acc: 0.36\n",
      "2968 loss: tensor(1.0197) acc: 0.36\n",
      "2969 loss: tensor(1.0196) acc: 0.36\n",
      "2970 loss: tensor(1.0195) acc: 0.36\n",
      "2971 loss: tensor(1.0194) acc: 0.36\n",
      "2972 loss: tensor(1.0193) acc: 0.36\n",
      "2973 loss: tensor(1.0192) acc: 0.36\n",
      "2974 loss: tensor(1.0191) acc: 0.36\n",
      "2975 loss: tensor(1.0190) acc: 0.36\n",
      "2976 loss: tensor(1.0189) acc: 0.36\n",
      "2977 loss: tensor(1.0188) acc: 0.36\n",
      "2978 loss: tensor(1.0187) acc: 0.36\n",
      "2979 loss: tensor(1.0187) acc: 0.36\n",
      "2980 loss: tensor(1.0186) acc: 0.36\n",
      "2981 loss: tensor(1.0185) acc: 0.36\n",
      "2982 loss: tensor(1.0184) acc: 0.36\n",
      "2983 loss: tensor(1.0183) acc: 0.36\n",
      "2984 loss: tensor(1.0182) acc: 0.36\n",
      "2985 loss: tensor(1.0181) acc: 0.36\n",
      "2986 loss: tensor(1.0180) acc: 0.36\n",
      "2987 loss: tensor(1.0179) acc: 0.36\n",
      "2988 loss: tensor(1.0178) acc: 0.36\n",
      "2989 loss: tensor(1.0177) acc: 0.36\n",
      "2990 loss: tensor(1.0176) acc: 0.36\n",
      "2991 loss: tensor(1.0175) acc: 0.36\n",
      "2992 loss: tensor(1.0174) acc: 0.36\n",
      "2993 loss: tensor(1.0173) acc: 0.36\n",
      "2994 loss: tensor(1.0172) acc: 0.36\n",
      "2995 loss: tensor(1.0171) acc: 0.36\n",
      "2996 loss: tensor(1.0170) acc: 0.36\n",
      "2997 loss: tensor(1.0169) acc: 0.36\n",
      "2998 loss: tensor(1.0168) acc: 0.36\n",
      "2999 loss: tensor(1.0167) acc: 0.36\n",
      "3000 loss: tensor(1.0166) acc: 0.36\n",
      "3001 loss: tensor(1.0165) acc: 0.36\n",
      "3002 loss: tensor(1.0164) acc: 0.36\n",
      "3003 loss: tensor(1.0163) acc: 0.36\n",
      "3004 loss: tensor(1.0163) acc: 0.36\n",
      "3005 loss: tensor(1.0162) acc: 0.36\n",
      "3006 loss: tensor(1.0161) acc: 0.36\n",
      "3007 loss: tensor(1.0160) acc: 0.36\n",
      "3008 loss: tensor(1.0159) acc: 0.36\n",
      "3009 loss: tensor(1.0158) acc: 0.36\n",
      "3010 loss: tensor(1.0157) acc: 0.36\n",
      "3011 loss: tensor(1.0156) acc: 0.36\n",
      "3012 loss: tensor(1.0155) acc: 0.36\n",
      "3013 loss: tensor(1.0154) acc: 0.36\n",
      "3014 loss: tensor(1.0153) acc: 0.36\n",
      "3015 loss: tensor(1.0152) acc: 0.36\n",
      "3016 loss: tensor(1.0151) acc: 0.36\n",
      "3017 loss: tensor(1.0150) acc: 0.36\n",
      "3018 loss: tensor(1.0149) acc: 0.36\n",
      "3019 loss: tensor(1.0148) acc: 0.36\n",
      "3020 loss: tensor(1.0147) acc: 0.36\n",
      "3021 loss: tensor(1.0146) acc: 0.36\n",
      "3022 loss: tensor(1.0145) acc: 0.36\n",
      "3023 loss: tensor(1.0144) acc: 0.36\n",
      "3024 loss: tensor(1.0143) acc: 0.36\n",
      "3025 loss: tensor(1.0142) acc: 0.36\n",
      "3026 loss: tensor(1.0141) acc: 0.36\n",
      "3027 loss: tensor(1.0140) acc: 0.36\n",
      "3028 loss: tensor(1.0139) acc: 0.36\n",
      "3029 loss: tensor(1.0138) acc: 0.36\n",
      "3030 loss: tensor(1.0137) acc: 0.36\n",
      "3031 loss: tensor(1.0136) acc: 0.36\n",
      "3032 loss: tensor(1.0135) acc: 0.36\n",
      "3033 loss: tensor(1.0134) acc: 0.36\n",
      "3034 loss: tensor(1.0134) acc: 0.36\n",
      "3035 loss: tensor(1.0133) acc: 0.36\n",
      "3036 loss: tensor(1.0132) acc: 0.36\n",
      "3037 loss: tensor(1.0131) acc: 0.36\n",
      "3038 loss: tensor(1.0130) acc: 0.36\n",
      "3039 loss: tensor(1.0129) acc: 0.36\n",
      "3040 loss: tensor(1.0128) acc: 0.36\n",
      "3041 loss: tensor(1.0127) acc: 0.36\n",
      "3042 loss: tensor(1.0126) acc: 0.36\n",
      "3043 loss: tensor(1.0125) acc: 0.36\n",
      "3044 loss: tensor(1.0124) acc: 0.36\n",
      "3045 loss: tensor(1.0123) acc: 0.36\n",
      "3046 loss: tensor(1.0122) acc: 0.36\n",
      "3047 loss: tensor(1.0121) acc: 0.36\n",
      "3048 loss: tensor(1.0120) acc: 0.36\n",
      "3049 loss: tensor(1.0119) acc: 0.36\n",
      "3050 loss: tensor(1.0118) acc: 0.36\n",
      "3051 loss: tensor(1.0117) acc: 0.36\n",
      "3052 loss: tensor(1.0116) acc: 0.36\n",
      "3053 loss: tensor(1.0115) acc: 0.36\n",
      "3054 loss: tensor(1.0114) acc: 0.36\n",
      "3055 loss: tensor(1.0113) acc: 0.36\n",
      "3056 loss: tensor(1.0112) acc: 0.36\n",
      "3057 loss: tensor(1.0111) acc: 0.36\n",
      "3058 loss: tensor(1.0110) acc: 0.36\n",
      "3059 loss: tensor(1.0109) acc: 0.36\n",
      "3060 loss: tensor(1.0108) acc: 0.36\n",
      "3061 loss: tensor(1.0107) acc: 0.36\n",
      "3062 loss: tensor(1.0106) acc: 0.36\n",
      "3063 loss: tensor(1.0105) acc: 0.36\n",
      "3064 loss: tensor(1.0104) acc: 0.36\n",
      "3065 loss: tensor(1.0103) acc: 0.36\n",
      "3066 loss: tensor(1.0102) acc: 0.36\n",
      "3067 loss: tensor(1.0101) acc: 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3068 loss: tensor(1.0100) acc: 0.36\n",
      "3069 loss: tensor(1.0099) acc: 0.36\n",
      "3070 loss: tensor(1.0098) acc: 0.36\n",
      "3071 loss: tensor(1.0098) acc: 0.36\n",
      "3072 loss: tensor(1.0097) acc: 0.36\n",
      "3073 loss: tensor(1.0096) acc: 0.36\n",
      "3074 loss: tensor(1.0095) acc: 0.36\n",
      "3075 loss: tensor(1.0094) acc: 0.36\n",
      "3076 loss: tensor(1.0093) acc: 0.36\n",
      "3077 loss: tensor(1.0092) acc: 0.36\n",
      "3078 loss: tensor(1.0091) acc: 0.36\n",
      "3079 loss: tensor(1.0090) acc: 0.36\n",
      "3080 loss: tensor(1.0089) acc: 0.36\n",
      "3081 loss: tensor(1.0088) acc: 0.36\n",
      "3082 loss: tensor(1.0087) acc: 0.36\n",
      "3083 loss: tensor(1.0086) acc: 0.36\n",
      "3084 loss: tensor(1.0085) acc: 0.36\n",
      "3085 loss: tensor(1.0084) acc: 0.36\n",
      "3086 loss: tensor(1.0083) acc: 0.36\n",
      "3087 loss: tensor(1.0082) acc: 0.36\n",
      "3088 loss: tensor(1.0081) acc: 0.36\n",
      "3089 loss: tensor(1.0080) acc: 0.36\n",
      "3090 loss: tensor(1.0079) acc: 0.36\n",
      "3091 loss: tensor(1.0078) acc: 0.36\n",
      "3092 loss: tensor(1.0077) acc: 0.36\n",
      "3093 loss: tensor(1.0076) acc: 0.36\n",
      "3094 loss: tensor(1.0075) acc: 0.36\n",
      "3095 loss: tensor(1.0074) acc: 0.36\n",
      "3096 loss: tensor(1.0073) acc: 0.36\n",
      "3097 loss: tensor(1.0072) acc: 0.36\n",
      "3098 loss: tensor(1.0071) acc: 0.36\n",
      "3099 loss: tensor(1.0070) acc: 0.36\n",
      "3100 loss: tensor(1.0069) acc: 0.36\n",
      "3101 loss: tensor(1.0068) acc: 0.36\n",
      "3102 loss: tensor(1.0067) acc: 0.36\n",
      "3103 loss: tensor(1.0066) acc: 0.36\n",
      "3104 loss: tensor(1.0065) acc: 0.36\n",
      "3105 loss: tensor(1.0064) acc: 0.36\n",
      "3106 loss: tensor(1.0063) acc: 0.36\n",
      "3107 loss: tensor(1.0062) acc: 0.36\n",
      "3108 loss: tensor(1.0061) acc: 0.36\n",
      "3109 loss: tensor(1.0060) acc: 0.36\n",
      "3110 loss: tensor(1.0059) acc: 0.36\n",
      "3111 loss: tensor(1.0058) acc: 0.36\n",
      "3112 loss: tensor(1.0057) acc: 0.35333333333333333\n",
      "3113 loss: tensor(1.0056) acc: 0.35333333333333333\n",
      "3114 loss: tensor(1.0056) acc: 0.35333333333333333\n",
      "3115 loss: tensor(1.0055) acc: 0.35333333333333333\n",
      "3116 loss: tensor(1.0054) acc: 0.35333333333333333\n",
      "3117 loss: tensor(1.0053) acc: 0.35333333333333333\n",
      "3118 loss: tensor(1.0052) acc: 0.35333333333333333\n",
      "3119 loss: tensor(1.0051) acc: 0.35333333333333333\n",
      "3120 loss: tensor(1.0050) acc: 0.35333333333333333\n",
      "3121 loss: tensor(1.0049) acc: 0.35333333333333333\n",
      "3122 loss: tensor(1.0048) acc: 0.35333333333333333\n",
      "3123 loss: tensor(1.0047) acc: 0.35333333333333333\n",
      "3124 loss: tensor(1.0046) acc: 0.35333333333333333\n",
      "3125 loss: tensor(1.0045) acc: 0.35333333333333333\n",
      "3126 loss: tensor(1.0044) acc: 0.35333333333333333\n",
      "3127 loss: tensor(1.0043) acc: 0.35333333333333333\n",
      "3128 loss: tensor(1.0042) acc: 0.35333333333333333\n",
      "3129 loss: tensor(1.0041) acc: 0.35333333333333333\n",
      "3130 loss: tensor(1.0040) acc: 0.35333333333333333\n",
      "3131 loss: tensor(1.0039) acc: 0.35333333333333333\n",
      "3132 loss: tensor(1.0038) acc: 0.35333333333333333\n",
      "3133 loss: tensor(1.0037) acc: 0.35333333333333333\n",
      "3134 loss: tensor(1.0036) acc: 0.35333333333333333\n",
      "3135 loss: tensor(1.0035) acc: 0.35333333333333333\n",
      "3136 loss: tensor(1.0034) acc: 0.35333333333333333\n",
      "3137 loss: tensor(1.0033) acc: 0.35333333333333333\n",
      "3138 loss: tensor(1.0032) acc: 0.35333333333333333\n",
      "3139 loss: tensor(1.0031) acc: 0.35333333333333333\n",
      "3140 loss: tensor(1.0030) acc: 0.35333333333333333\n",
      "3141 loss: tensor(1.0029) acc: 0.35333333333333333\n",
      "3142 loss: tensor(1.0028) acc: 0.35333333333333333\n",
      "3143 loss: tensor(1.0027) acc: 0.35333333333333333\n",
      "3144 loss: tensor(1.0026) acc: 0.35333333333333333\n",
      "3145 loss: tensor(1.0025) acc: 0.35333333333333333\n",
      "3146 loss: tensor(1.0024) acc: 0.35333333333333333\n",
      "3147 loss: tensor(1.0023) acc: 0.35333333333333333\n",
      "3148 loss: tensor(1.0022) acc: 0.35333333333333333\n",
      "3149 loss: tensor(1.0021) acc: 0.35333333333333333\n",
      "3150 loss: tensor(1.0020) acc: 0.35333333333333333\n",
      "3151 loss: tensor(1.0020) acc: 0.35333333333333333\n",
      "3152 loss: tensor(1.0019) acc: 0.35333333333333333\n",
      "3153 loss: tensor(1.0018) acc: 0.35333333333333333\n",
      "3154 loss: tensor(1.0017) acc: 0.35333333333333333\n",
      "3155 loss: tensor(1.0016) acc: 0.35333333333333333\n",
      "3156 loss: tensor(1.0015) acc: 0.35333333333333333\n",
      "3157 loss: tensor(1.0014) acc: 0.35333333333333333\n",
      "3158 loss: tensor(1.0013) acc: 0.35333333333333333\n",
      "3159 loss: tensor(1.0012) acc: 0.35333333333333333\n",
      "3160 loss: tensor(1.0011) acc: 0.35333333333333333\n",
      "3161 loss: tensor(1.0010) acc: 0.35333333333333333\n",
      "3162 loss: tensor(1.0009) acc: 0.35333333333333333\n",
      "3163 loss: tensor(1.0008) acc: 0.35333333333333333\n",
      "3164 loss: tensor(1.0007) acc: 0.35333333333333333\n",
      "3165 loss: tensor(1.0006) acc: 0.35333333333333333\n",
      "3166 loss: tensor(1.0005) acc: 0.35333333333333333\n",
      "3167 loss: tensor(1.0004) acc: 0.35333333333333333\n",
      "3168 loss: tensor(1.0003) acc: 0.35333333333333333\n",
      "3169 loss: tensor(1.0002) acc: 0.35333333333333333\n",
      "3170 loss: tensor(1.0001) acc: 0.35333333333333333\n",
      "3171 loss: tensor(1.0000) acc: 0.35333333333333333\n",
      "3172 loss: tensor(0.9999) acc: 0.35333333333333333\n",
      "3173 loss: tensor(0.9998) acc: 0.35333333333333333\n",
      "3174 loss: tensor(0.9997) acc: 0.35333333333333333\n",
      "3175 loss: tensor(0.9996) acc: 0.35333333333333333\n",
      "3176 loss: tensor(0.9995) acc: 0.35333333333333333\n",
      "3177 loss: tensor(0.9994) acc: 0.35333333333333333\n",
      "3178 loss: tensor(0.9993) acc: 0.35333333333333333\n",
      "3179 loss: tensor(0.9992) acc: 0.35333333333333333\n",
      "3180 loss: tensor(0.9991) acc: 0.35333333333333333\n",
      "3181 loss: tensor(0.9991) acc: 0.35333333333333333\n",
      "3182 loss: tensor(0.9990) acc: 0.35333333333333333\n",
      "3183 loss: tensor(0.9989) acc: 0.35333333333333333\n",
      "3184 loss: tensor(0.9988) acc: 0.35333333333333333\n",
      "3185 loss: tensor(0.9987) acc: 0.35333333333333333\n",
      "3186 loss: tensor(0.9986) acc: 0.35333333333333333\n",
      "3187 loss: tensor(0.9985) acc: 0.35333333333333333\n",
      "3188 loss: tensor(0.9984) acc: 0.35333333333333333\n",
      "3189 loss: tensor(0.9983) acc: 0.35333333333333333\n",
      "3190 loss: tensor(0.9982) acc: 0.35333333333333333\n",
      "3191 loss: tensor(0.9981) acc: 0.35333333333333333\n",
      "3192 loss: tensor(0.9980) acc: 0.35333333333333333\n",
      "3193 loss: tensor(0.9979) acc: 0.35333333333333333\n",
      "3194 loss: tensor(0.9978) acc: 0.35333333333333333\n",
      "3195 loss: tensor(0.9977) acc: 0.35333333333333333\n",
      "3196 loss: tensor(0.9976) acc: 0.35333333333333333\n",
      "3197 loss: tensor(0.9975) acc: 0.35333333333333333\n",
      "3198 loss: tensor(0.9974) acc: 0.35333333333333333\n",
      "3199 loss: tensor(0.9973) acc: 0.35333333333333333\n",
      "3200 loss: tensor(0.9972) acc: 0.35333333333333333\n",
      "3201 loss: tensor(0.9971) acc: 0.35333333333333333\n",
      "3202 loss: tensor(0.9970) acc: 0.35333333333333333\n",
      "3203 loss: tensor(0.9969) acc: 0.35333333333333333\n",
      "3204 loss: tensor(0.9969) acc: 0.35333333333333333\n",
      "3205 loss: tensor(0.9968) acc: 0.35333333333333333\n",
      "3206 loss: tensor(0.9967) acc: 0.35333333333333333\n",
      "3207 loss: tensor(0.9966) acc: 0.35333333333333333\n",
      "3208 loss: tensor(0.9965) acc: 0.35333333333333333\n",
      "3209 loss: tensor(0.9964) acc: 0.35333333333333333\n",
      "3210 loss: tensor(0.9963) acc: 0.35333333333333333\n",
      "3211 loss: tensor(0.9962) acc: 0.35333333333333333\n",
      "3212 loss: tensor(0.9961) acc: 0.35333333333333333\n",
      "3213 loss: tensor(0.9960) acc: 0.35333333333333333\n",
      "3214 loss: tensor(0.9959) acc: 0.35333333333333333\n",
      "3215 loss: tensor(0.9958) acc: 0.35333333333333333\n",
      "3216 loss: tensor(0.9957) acc: 0.35333333333333333\n",
      "3217 loss: tensor(0.9956) acc: 0.35333333333333333\n",
      "3218 loss: tensor(0.9955) acc: 0.35333333333333333\n",
      "3219 loss: tensor(0.9954) acc: 0.35333333333333333\n",
      "3220 loss: tensor(0.9953) acc: 0.35333333333333333\n",
      "3221 loss: tensor(0.9952) acc: 0.35333333333333333\n",
      "3222 loss: tensor(0.9951) acc: 0.35333333333333333\n",
      "3223 loss: tensor(0.9950) acc: 0.35333333333333333\n",
      "3224 loss: tensor(0.9950) acc: 0.35333333333333333\n",
      "3225 loss: tensor(0.9949) acc: 0.35333333333333333\n",
      "3226 loss: tensor(0.9948) acc: 0.35333333333333333\n",
      "3227 loss: tensor(0.9947) acc: 0.35333333333333333\n",
      "3228 loss: tensor(0.9946) acc: 0.35333333333333333\n",
      "3229 loss: tensor(0.9945) acc: 0.35333333333333333\n",
      "3230 loss: tensor(0.9944) acc: 0.35333333333333333\n",
      "3231 loss: tensor(0.9943) acc: 0.35333333333333333\n",
      "3232 loss: tensor(0.9942) acc: 0.35333333333333333\n",
      "3233 loss: tensor(0.9941) acc: 0.35333333333333333\n",
      "3234 loss: tensor(0.9940) acc: 0.35333333333333333\n",
      "3235 loss: tensor(0.9939) acc: 0.35333333333333333\n",
      "3236 loss: tensor(0.9938) acc: 0.35333333333333333\n",
      "3237 loss: tensor(0.9937) acc: 0.35333333333333333\n",
      "3238 loss: tensor(0.9936) acc: 0.35333333333333333\n",
      "3239 loss: tensor(0.9935) acc: 0.35333333333333333\n",
      "3240 loss: tensor(0.9934) acc: 0.35333333333333333\n",
      "3241 loss: tensor(0.9934) acc: 0.35333333333333333\n",
      "3242 loss: tensor(0.9933) acc: 0.35333333333333333\n",
      "3243 loss: tensor(0.9932) acc: 0.35333333333333333\n",
      "3244 loss: tensor(0.9931) acc: 0.35333333333333333\n",
      "3245 loss: tensor(0.9930) acc: 0.35333333333333333\n",
      "3246 loss: tensor(0.9929) acc: 0.35333333333333333\n",
      "3247 loss: tensor(0.9928) acc: 0.35333333333333333\n",
      "3248 loss: tensor(0.9927) acc: 0.35333333333333333\n",
      "3249 loss: tensor(0.9926) acc: 0.35333333333333333\n",
      "3250 loss: tensor(0.9925) acc: 0.35333333333333333\n",
      "3251 loss: tensor(0.9924) acc: 0.35333333333333333\n",
      "3252 loss: tensor(0.9923) acc: 0.35333333333333333\n",
      "3253 loss: tensor(0.9922) acc: 0.35333333333333333\n",
      "3254 loss: tensor(0.9921) acc: 0.35333333333333333\n",
      "3255 loss: tensor(0.9921) acc: 0.35333333333333333\n",
      "3256 loss: tensor(0.9920) acc: 0.35333333333333333\n",
      "3257 loss: tensor(0.9919) acc: 0.35333333333333333\n",
      "3258 loss: tensor(0.9918) acc: 0.35333333333333333\n",
      "3259 loss: tensor(0.9917) acc: 0.35333333333333333\n",
      "3260 loss: tensor(0.9916) acc: 0.35333333333333333\n",
      "3261 loss: tensor(0.9915) acc: 0.35333333333333333\n",
      "3262 loss: tensor(0.9914) acc: 0.35333333333333333\n",
      "3263 loss: tensor(0.9913) acc: 0.35333333333333333\n",
      "3264 loss: tensor(0.9912) acc: 0.35333333333333333\n",
      "3265 loss: tensor(0.9911) acc: 0.35333333333333333\n",
      "3266 loss: tensor(0.9910) acc: 0.35333333333333333\n",
      "3267 loss: tensor(0.9909) acc: 0.35333333333333333\n",
      "3268 loss: tensor(0.9909) acc: 0.35333333333333333\n",
      "3269 loss: tensor(0.9908) acc: 0.35333333333333333\n",
      "3270 loss: tensor(0.9907) acc: 0.35333333333333333\n",
      "3271 loss: tensor(0.9906) acc: 0.35333333333333333\n",
      "3272 loss: tensor(0.9905) acc: 0.35333333333333333\n",
      "3273 loss: tensor(0.9904) acc: 0.35333333333333333\n",
      "3274 loss: tensor(0.9903) acc: 0.35333333333333333\n",
      "3275 loss: tensor(0.9902) acc: 0.35333333333333333\n",
      "3276 loss: tensor(0.9901) acc: 0.35333333333333333\n",
      "3277 loss: tensor(0.9900) acc: 0.35333333333333333\n",
      "3278 loss: tensor(0.9899) acc: 0.35333333333333333\n",
      "3279 loss: tensor(0.9898) acc: 0.35333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3280 loss: tensor(0.9898) acc: 0.35333333333333333\n",
      "3281 loss: tensor(0.9897) acc: 0.35333333333333333\n",
      "3282 loss: tensor(0.9896) acc: 0.35333333333333333\n",
      "3283 loss: tensor(0.9895) acc: 0.35333333333333333\n",
      "3284 loss: tensor(0.9894) acc: 0.35333333333333333\n",
      "3285 loss: tensor(0.9893) acc: 0.35333333333333333\n",
      "3286 loss: tensor(0.9892) acc: 0.35333333333333333\n",
      "3287 loss: tensor(0.9891) acc: 0.35333333333333333\n",
      "3288 loss: tensor(0.9890) acc: 0.35333333333333333\n",
      "3289 loss: tensor(0.9889) acc: 0.35333333333333333\n",
      "3290 loss: tensor(0.9888) acc: 0.35333333333333333\n",
      "3291 loss: tensor(0.9888) acc: 0.35333333333333333\n",
      "3292 loss: tensor(0.9887) acc: 0.3466666666666667\n",
      "3293 loss: tensor(0.9886) acc: 0.3466666666666667\n",
      "3294 loss: tensor(0.9885) acc: 0.3466666666666667\n",
      "3295 loss: tensor(0.9884) acc: 0.3466666666666667\n",
      "3296 loss: tensor(0.9883) acc: 0.3466666666666667\n",
      "3297 loss: tensor(0.9882) acc: 0.3466666666666667\n",
      "3298 loss: tensor(0.9881) acc: 0.3466666666666667\n",
      "3299 loss: tensor(0.9880) acc: 0.3466666666666667\n",
      "3300 loss: tensor(0.9879) acc: 0.3466666666666667\n",
      "3301 loss: tensor(0.9879) acc: 0.3466666666666667\n",
      "3302 loss: tensor(0.9878) acc: 0.3466666666666667\n",
      "3303 loss: tensor(0.9877) acc: 0.35333333333333333\n",
      "3304 loss: tensor(0.9876) acc: 0.35333333333333333\n",
      "3305 loss: tensor(0.9875) acc: 0.35333333333333333\n",
      "3306 loss: tensor(0.9874) acc: 0.35333333333333333\n",
      "3307 loss: tensor(0.9873) acc: 0.35333333333333333\n",
      "3308 loss: tensor(0.9872) acc: 0.35333333333333333\n",
      "3309 loss: tensor(0.9871) acc: 0.35333333333333333\n",
      "3310 loss: tensor(0.9871) acc: 0.35333333333333333\n",
      "3311 loss: tensor(0.9870) acc: 0.35333333333333333\n",
      "3312 loss: tensor(0.9869) acc: 0.35333333333333333\n",
      "3313 loss: tensor(0.9868) acc: 0.35333333333333333\n",
      "3314 loss: tensor(0.9867) acc: 0.35333333333333333\n",
      "3315 loss: tensor(0.9866) acc: 0.35333333333333333\n",
      "3316 loss: tensor(0.9865) acc: 0.35333333333333333\n",
      "3317 loss: tensor(0.9864) acc: 0.35333333333333333\n",
      "3318 loss: tensor(0.9863) acc: 0.35333333333333333\n",
      "3319 loss: tensor(0.9863) acc: 0.35333333333333333\n",
      "3320 loss: tensor(0.9862) acc: 0.35333333333333333\n",
      "3321 loss: tensor(0.9861) acc: 0.35333333333333333\n",
      "3322 loss: tensor(0.9860) acc: 0.35333333333333333\n",
      "3323 loss: tensor(0.9859) acc: 0.35333333333333333\n",
      "3324 loss: tensor(0.9858) acc: 0.35333333333333333\n",
      "3325 loss: tensor(0.9857) acc: 0.35333333333333333\n",
      "3326 loss: tensor(0.9856) acc: 0.35333333333333333\n",
      "3327 loss: tensor(0.9856) acc: 0.35333333333333333\n",
      "3328 loss: tensor(0.9855) acc: 0.35333333333333333\n",
      "3329 loss: tensor(0.9854) acc: 0.35333333333333333\n",
      "3330 loss: tensor(0.9853) acc: 0.35333333333333333\n",
      "3331 loss: tensor(0.9852) acc: 0.35333333333333333\n",
      "3332 loss: tensor(0.9851) acc: 0.35333333333333333\n",
      "3333 loss: tensor(0.9850) acc: 0.35333333333333333\n",
      "3334 loss: tensor(0.9849) acc: 0.35333333333333333\n",
      "3335 loss: tensor(0.9849) acc: 0.35333333333333333\n",
      "3336 loss: tensor(0.9848) acc: 0.35333333333333333\n",
      "3337 loss: tensor(0.9847) acc: 0.35333333333333333\n",
      "3338 loss: tensor(0.9846) acc: 0.35333333333333333\n",
      "3339 loss: tensor(0.9845) acc: 0.35333333333333333\n",
      "3340 loss: tensor(0.9844) acc: 0.35333333333333333\n",
      "3341 loss: tensor(0.9843) acc: 0.35333333333333333\n",
      "3342 loss: tensor(0.9842) acc: 0.35333333333333333\n",
      "3343 loss: tensor(0.9842) acc: 0.35333333333333333\n",
      "3344 loss: tensor(0.9841) acc: 0.35333333333333333\n",
      "3345 loss: tensor(0.9840) acc: 0.35333333333333333\n",
      "3346 loss: tensor(0.9839) acc: 0.35333333333333333\n",
      "3347 loss: tensor(0.9838) acc: 0.35333333333333333\n",
      "3348 loss: tensor(0.9837) acc: 0.35333333333333333\n",
      "3349 loss: tensor(0.9836) acc: 0.35333333333333333\n",
      "3350 loss: tensor(0.9836) acc: 0.35333333333333333\n",
      "3351 loss: tensor(0.9835) acc: 0.35333333333333333\n",
      "3352 loss: tensor(0.9834) acc: 0.35333333333333333\n",
      "3353 loss: tensor(0.9833) acc: 0.35333333333333333\n",
      "3354 loss: tensor(0.9832) acc: 0.35333333333333333\n",
      "3355 loss: tensor(0.9831) acc: 0.35333333333333333\n",
      "3356 loss: tensor(0.9830) acc: 0.35333333333333333\n",
      "3357 loss: tensor(0.9830) acc: 0.35333333333333333\n",
      "3358 loss: tensor(0.9829) acc: 0.35333333333333333\n",
      "3359 loss: tensor(0.9828) acc: 0.35333333333333333\n",
      "3360 loss: tensor(0.9827) acc: 0.35333333333333333\n",
      "3361 loss: tensor(0.9826) acc: 0.35333333333333333\n",
      "3362 loss: tensor(0.9825) acc: 0.35333333333333333\n",
      "3363 loss: tensor(0.9824) acc: 0.35333333333333333\n",
      "3364 loss: tensor(0.9824) acc: 0.35333333333333333\n",
      "3365 loss: tensor(0.9823) acc: 0.35333333333333333\n",
      "3366 loss: tensor(0.9822) acc: 0.35333333333333333\n",
      "3367 loss: tensor(0.9821) acc: 0.35333333333333333\n",
      "3368 loss: tensor(0.9820) acc: 0.35333333333333333\n",
      "3369 loss: tensor(0.9819) acc: 0.35333333333333333\n",
      "3370 loss: tensor(0.9819) acc: 0.35333333333333333\n",
      "3371 loss: tensor(0.9818) acc: 0.35333333333333333\n",
      "3372 loss: tensor(0.9817) acc: 0.35333333333333333\n",
      "3373 loss: tensor(0.9816) acc: 0.35333333333333333\n",
      "3374 loss: tensor(0.9815) acc: 0.35333333333333333\n",
      "3375 loss: tensor(0.9814) acc: 0.35333333333333333\n",
      "3376 loss: tensor(0.9813) acc: 0.35333333333333333\n",
      "3377 loss: tensor(0.9813) acc: 0.35333333333333333\n",
      "3378 loss: tensor(0.9812) acc: 0.35333333333333333\n",
      "3379 loss: tensor(0.9811) acc: 0.35333333333333333\n",
      "3380 loss: tensor(0.9810) acc: 0.35333333333333333\n",
      "3381 loss: tensor(0.9809) acc: 0.35333333333333333\n",
      "3382 loss: tensor(0.9808) acc: 0.35333333333333333\n",
      "3383 loss: tensor(0.9808) acc: 0.35333333333333333\n",
      "3384 loss: tensor(0.9807) acc: 0.35333333333333333\n",
      "3385 loss: tensor(0.9806) acc: 0.35333333333333333\n",
      "3386 loss: tensor(0.9805) acc: 0.35333333333333333\n",
      "3387 loss: tensor(0.9804) acc: 0.35333333333333333\n",
      "3388 loss: tensor(0.9803) acc: 0.35333333333333333\n",
      "3389 loss: tensor(0.9803) acc: 0.35333333333333333\n",
      "3390 loss: tensor(0.9802) acc: 0.35333333333333333\n",
      "3391 loss: tensor(0.9801) acc: 0.35333333333333333\n",
      "3392 loss: tensor(0.9800) acc: 0.35333333333333333\n",
      "3393 loss: tensor(0.9799) acc: 0.35333333333333333\n",
      "3394 loss: tensor(0.9799) acc: 0.35333333333333333\n",
      "3395 loss: tensor(0.9798) acc: 0.35333333333333333\n",
      "3396 loss: tensor(0.9797) acc: 0.35333333333333333\n",
      "3397 loss: tensor(0.9796) acc: 0.35333333333333333\n",
      "3398 loss: tensor(0.9795) acc: 0.35333333333333333\n",
      "3399 loss: tensor(0.9794) acc: 0.35333333333333333\n",
      "3400 loss: tensor(0.9794) acc: 0.35333333333333333\n",
      "3401 loss: tensor(0.9793) acc: 0.35333333333333333\n",
      "3402 loss: tensor(0.9792) acc: 0.35333333333333333\n",
      "3403 loss: tensor(0.9791) acc: 0.35333333333333333\n",
      "3404 loss: tensor(0.9790) acc: 0.35333333333333333\n",
      "3405 loss: tensor(0.9789) acc: 0.35333333333333333\n",
      "3406 loss: tensor(0.9789) acc: 0.36\n",
      "3407 loss: tensor(0.9788) acc: 0.36\n",
      "3408 loss: tensor(0.9787) acc: 0.36\n",
      "3409 loss: tensor(0.9786) acc: 0.36\n",
      "3410 loss: tensor(0.9785) acc: 0.36\n",
      "3411 loss: tensor(0.9785) acc: 0.36\n",
      "3412 loss: tensor(0.9784) acc: 0.36\n",
      "3413 loss: tensor(0.9783) acc: 0.36\n",
      "3414 loss: tensor(0.9782) acc: 0.36\n",
      "3415 loss: tensor(0.9781) acc: 0.36\n",
      "3416 loss: tensor(0.9781) acc: 0.36\n",
      "3417 loss: tensor(0.9780) acc: 0.36\n",
      "3418 loss: tensor(0.9779) acc: 0.36\n",
      "3419 loss: tensor(0.9778) acc: 0.36\n",
      "3420 loss: tensor(0.9777) acc: 0.36\n",
      "3421 loss: tensor(0.9777) acc: 0.36\n",
      "3422 loss: tensor(0.9776) acc: 0.36\n",
      "3423 loss: tensor(0.9775) acc: 0.36\n",
      "3424 loss: tensor(0.9774) acc: 0.36\n",
      "3425 loss: tensor(0.9773) acc: 0.36\n",
      "3426 loss: tensor(0.9773) acc: 0.36\n",
      "3427 loss: tensor(0.9772) acc: 0.36\n",
      "3428 loss: tensor(0.9771) acc: 0.36\n",
      "3429 loss: tensor(0.9770) acc: 0.36\n",
      "3430 loss: tensor(0.9769) acc: 0.36\n",
      "3431 loss: tensor(0.9769) acc: 0.36\n",
      "3432 loss: tensor(0.9768) acc: 0.36\n",
      "3433 loss: tensor(0.9767) acc: 0.36\n",
      "3434 loss: tensor(0.9766) acc: 0.36\n",
      "3435 loss: tensor(0.9765) acc: 0.36\n",
      "3436 loss: tensor(0.9765) acc: 0.36666666666666664\n",
      "3437 loss: tensor(0.9764) acc: 0.36666666666666664\n",
      "3438 loss: tensor(0.9763) acc: 0.36666666666666664\n",
      "3439 loss: tensor(0.9762) acc: 0.36666666666666664\n",
      "3440 loss: tensor(0.9762) acc: 0.36666666666666664\n",
      "3441 loss: tensor(0.9761) acc: 0.36666666666666664\n",
      "3442 loss: tensor(0.9760) acc: 0.36666666666666664\n",
      "3443 loss: tensor(0.9759) acc: 0.36666666666666664\n",
      "3444 loss: tensor(0.9758) acc: 0.36666666666666664\n",
      "3445 loss: tensor(0.9758) acc: 0.36666666666666664\n",
      "3446 loss: tensor(0.9757) acc: 0.36666666666666664\n",
      "3447 loss: tensor(0.9756) acc: 0.36666666666666664\n",
      "3448 loss: tensor(0.9755) acc: 0.36666666666666664\n",
      "3449 loss: tensor(0.9754) acc: 0.36666666666666664\n",
      "3450 loss: tensor(0.9754) acc: 0.36666666666666664\n",
      "3451 loss: tensor(0.9753) acc: 0.36666666666666664\n",
      "3452 loss: tensor(0.9752) acc: 0.36666666666666664\n",
      "3453 loss: tensor(0.9751) acc: 0.36666666666666664\n",
      "3454 loss: tensor(0.9751) acc: 0.36666666666666664\n",
      "3455 loss: tensor(0.9750) acc: 0.36666666666666664\n",
      "3456 loss: tensor(0.9749) acc: 0.36666666666666664\n",
      "3457 loss: tensor(0.9748) acc: 0.36666666666666664\n",
      "3458 loss: tensor(0.9748) acc: 0.36666666666666664\n",
      "3459 loss: tensor(0.9747) acc: 0.36666666666666664\n",
      "3460 loss: tensor(0.9746) acc: 0.36666666666666664\n",
      "3461 loss: tensor(0.9745) acc: 0.36666666666666664\n",
      "3462 loss: tensor(0.9744) acc: 0.36666666666666664\n",
      "3463 loss: tensor(0.9744) acc: 0.37333333333333335\n",
      "3464 loss: tensor(0.9743) acc: 0.37333333333333335\n",
      "3465 loss: tensor(0.9742) acc: 0.37333333333333335\n",
      "3466 loss: tensor(0.9741) acc: 0.37333333333333335\n",
      "3467 loss: tensor(0.9741) acc: 0.37333333333333335\n",
      "3468 loss: tensor(0.9740) acc: 0.37333333333333335\n",
      "3469 loss: tensor(0.9739) acc: 0.37333333333333335\n",
      "3470 loss: tensor(0.9738) acc: 0.37333333333333335\n",
      "3471 loss: tensor(0.9738) acc: 0.37333333333333335\n",
      "3472 loss: tensor(0.9737) acc: 0.37333333333333335\n",
      "3473 loss: tensor(0.9736) acc: 0.37333333333333335\n",
      "3474 loss: tensor(0.9735) acc: 0.37333333333333335\n",
      "3475 loss: tensor(0.9735) acc: 0.37333333333333335\n",
      "3476 loss: tensor(0.9734) acc: 0.37333333333333335\n",
      "3477 loss: tensor(0.9733) acc: 0.37333333333333335\n",
      "3478 loss: tensor(0.9732) acc: 0.37333333333333335\n",
      "3479 loss: tensor(0.9731) acc: 0.37333333333333335\n",
      "3480 loss: tensor(0.9731) acc: 0.37333333333333335\n",
      "3481 loss: tensor(0.9730) acc: 0.37333333333333335\n",
      "3482 loss: tensor(0.9729) acc: 0.37333333333333335\n",
      "3483 loss: tensor(0.9728) acc: 0.38\n",
      "3484 loss: tensor(0.9728) acc: 0.38\n",
      "3485 loss: tensor(0.9727) acc: 0.38\n",
      "3486 loss: tensor(0.9726) acc: 0.38\n",
      "3487 loss: tensor(0.9725) acc: 0.38\n",
      "3488 loss: tensor(0.9725) acc: 0.38\n",
      "3489 loss: tensor(0.9724) acc: 0.38\n",
      "3490 loss: tensor(0.9723) acc: 0.38\n",
      "3491 loss: tensor(0.9723) acc: 0.38\n",
      "3492 loss: tensor(0.9722) acc: 0.38\n",
      "3493 loss: tensor(0.9721) acc: 0.38\n",
      "3494 loss: tensor(0.9720) acc: 0.38\n",
      "3495 loss: tensor(0.9720) acc: 0.38\n",
      "3496 loss: tensor(0.9719) acc: 0.38\n",
      "3497 loss: tensor(0.9718) acc: 0.38\n",
      "3498 loss: tensor(0.9717) acc: 0.38\n",
      "3499 loss: tensor(0.9717) acc: 0.38\n",
      "3500 loss: tensor(0.9716) acc: 0.38\n",
      "3501 loss: tensor(0.9715) acc: 0.38\n",
      "3502 loss: tensor(0.9714) acc: 0.38\n",
      "3503 loss: tensor(0.9714) acc: 0.38\n",
      "3504 loss: tensor(0.9713) acc: 0.38\n",
      "3505 loss: tensor(0.9712) acc: 0.38\n",
      "3506 loss: tensor(0.9711) acc: 0.38\n",
      "3507 loss: tensor(0.9711) acc: 0.38\n",
      "3508 loss: tensor(0.9710) acc: 0.38\n",
      "3509 loss: tensor(0.9709) acc: 0.38\n",
      "3510 loss: tensor(0.9708) acc: 0.38\n",
      "3511 loss: tensor(0.9708) acc: 0.38\n",
      "3512 loss: tensor(0.9707) acc: 0.38\n",
      "3513 loss: tensor(0.9706) acc: 0.38\n",
      "3514 loss: tensor(0.9706) acc: 0.38\n",
      "3515 loss: tensor(0.9705) acc: 0.38\n",
      "3516 loss: tensor(0.9704) acc: 0.38\n",
      "3517 loss: tensor(0.9703) acc: 0.38\n",
      "3518 loss: tensor(0.9703) acc: 0.38\n",
      "3519 loss: tensor(0.9702) acc: 0.38\n",
      "3520 loss: tensor(0.9701) acc: 0.38\n",
      "3521 loss: tensor(0.9700) acc: 0.38\n",
      "3522 loss: tensor(0.9700) acc: 0.38\n",
      "3523 loss: tensor(0.9699) acc: 0.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3524 loss: tensor(0.9698) acc: 0.38\n",
      "3525 loss: tensor(0.9698) acc: 0.38\n",
      "3526 loss: tensor(0.9697) acc: 0.38\n",
      "3527 loss: tensor(0.9696) acc: 0.38\n",
      "3528 loss: tensor(0.9695) acc: 0.38\n",
      "3529 loss: tensor(0.9695) acc: 0.38\n",
      "3530 loss: tensor(0.9694) acc: 0.38\n",
      "3531 loss: tensor(0.9693) acc: 0.37333333333333335\n",
      "3532 loss: tensor(0.9693) acc: 0.38\n",
      "3533 loss: tensor(0.9692) acc: 0.38\n",
      "3534 loss: tensor(0.9691) acc: 0.38\n",
      "3535 loss: tensor(0.9690) acc: 0.38\n",
      "3536 loss: tensor(0.9690) acc: 0.38\n",
      "3537 loss: tensor(0.9689) acc: 0.38\n",
      "3538 loss: tensor(0.9688) acc: 0.38\n",
      "3539 loss: tensor(0.9688) acc: 0.38\n",
      "3540 loss: tensor(0.9687) acc: 0.38\n",
      "3541 loss: tensor(0.9686) acc: 0.38\n",
      "3542 loss: tensor(0.9685) acc: 0.38\n",
      "3543 loss: tensor(0.9685) acc: 0.38\n",
      "3544 loss: tensor(0.9684) acc: 0.38\n",
      "3545 loss: tensor(0.9683) acc: 0.38\n",
      "3546 loss: tensor(0.9683) acc: 0.38\n",
      "3547 loss: tensor(0.9682) acc: 0.38\n",
      "3548 loss: tensor(0.9681) acc: 0.38\n",
      "3549 loss: tensor(0.9681) acc: 0.38\n",
      "3550 loss: tensor(0.9680) acc: 0.38\n",
      "3551 loss: tensor(0.9679) acc: 0.38\n",
      "3552 loss: tensor(0.9678) acc: 0.38\n",
      "3553 loss: tensor(0.9678) acc: 0.38\n",
      "3554 loss: tensor(0.9677) acc: 0.38\n",
      "3555 loss: tensor(0.9676) acc: 0.38\n",
      "3556 loss: tensor(0.9676) acc: 0.38\n",
      "3557 loss: tensor(0.9675) acc: 0.38\n",
      "3558 loss: tensor(0.9674) acc: 0.38\n",
      "3559 loss: tensor(0.9674) acc: 0.38\n",
      "3560 loss: tensor(0.9673) acc: 0.38\n",
      "3561 loss: tensor(0.9672) acc: 0.38\n",
      "3562 loss: tensor(0.9671) acc: 0.38\n",
      "3563 loss: tensor(0.9671) acc: 0.38\n",
      "3564 loss: tensor(0.9670) acc: 0.38\n",
      "3565 loss: tensor(0.9669) acc: 0.38\n",
      "3566 loss: tensor(0.9669) acc: 0.38\n",
      "3567 loss: tensor(0.9668) acc: 0.38\n",
      "3568 loss: tensor(0.9667) acc: 0.38\n",
      "3569 loss: tensor(0.9667) acc: 0.38\n",
      "3570 loss: tensor(0.9666) acc: 0.38\n",
      "3571 loss: tensor(0.9665) acc: 0.38\n",
      "3572 loss: tensor(0.9665) acc: 0.38\n",
      "3573 loss: tensor(0.9664) acc: 0.38\n",
      "3574 loss: tensor(0.9663) acc: 0.38\n",
      "3575 loss: tensor(0.9662) acc: 0.38\n",
      "3576 loss: tensor(0.9662) acc: 0.38\n",
      "3577 loss: tensor(0.9661) acc: 0.38\n",
      "3578 loss: tensor(0.9660) acc: 0.38666666666666666\n",
      "3579 loss: tensor(0.9660) acc: 0.38666666666666666\n",
      "3580 loss: tensor(0.9659) acc: 0.38666666666666666\n",
      "3581 loss: tensor(0.9658) acc: 0.38666666666666666\n",
      "3582 loss: tensor(0.9658) acc: 0.38666666666666666\n",
      "3583 loss: tensor(0.9657) acc: 0.38666666666666666\n",
      "3584 loss: tensor(0.9656) acc: 0.3933333333333333\n",
      "3585 loss: tensor(0.9656) acc: 0.3933333333333333\n",
      "3586 loss: tensor(0.9655) acc: 0.3933333333333333\n",
      "3587 loss: tensor(0.9654) acc: 0.3933333333333333\n",
      "3588 loss: tensor(0.9654) acc: 0.3933333333333333\n",
      "3589 loss: tensor(0.9653) acc: 0.3933333333333333\n",
      "3590 loss: tensor(0.9652) acc: 0.3933333333333333\n",
      "3591 loss: tensor(0.9652) acc: 0.3933333333333333\n",
      "3592 loss: tensor(0.9651) acc: 0.3933333333333333\n",
      "3593 loss: tensor(0.9650) acc: 0.3933333333333333\n",
      "3594 loss: tensor(0.9650) acc: 0.3933333333333333\n",
      "3595 loss: tensor(0.9649) acc: 0.3933333333333333\n",
      "3596 loss: tensor(0.9648) acc: 0.3933333333333333\n",
      "3597 loss: tensor(0.9648) acc: 0.3933333333333333\n",
      "3598 loss: tensor(0.9647) acc: 0.3933333333333333\n",
      "3599 loss: tensor(0.9646) acc: 0.3933333333333333\n",
      "3600 loss: tensor(0.9645) acc: 0.3933333333333333\n",
      "3601 loss: tensor(0.9645) acc: 0.3933333333333333\n",
      "3602 loss: tensor(0.9644) acc: 0.3933333333333333\n",
      "3603 loss: tensor(0.9643) acc: 0.3933333333333333\n",
      "3604 loss: tensor(0.9643) acc: 0.3933333333333333\n",
      "3605 loss: tensor(0.9642) acc: 0.3933333333333333\n",
      "3606 loss: tensor(0.9641) acc: 0.3933333333333333\n",
      "3607 loss: tensor(0.9641) acc: 0.3933333333333333\n",
      "3608 loss: tensor(0.9640) acc: 0.3933333333333333\n",
      "3609 loss: tensor(0.9639) acc: 0.3933333333333333\n",
      "3610 loss: tensor(0.9639) acc: 0.3933333333333333\n",
      "3611 loss: tensor(0.9638) acc: 0.3933333333333333\n",
      "3612 loss: tensor(0.9637) acc: 0.3933333333333333\n",
      "3613 loss: tensor(0.9637) acc: 0.3933333333333333\n",
      "3614 loss: tensor(0.9636) acc: 0.3933333333333333\n",
      "3615 loss: tensor(0.9635) acc: 0.3933333333333333\n",
      "3616 loss: tensor(0.9635) acc: 0.3933333333333333\n",
      "3617 loss: tensor(0.9634) acc: 0.4\n",
      "3618 loss: tensor(0.9633) acc: 0.4\n",
      "3619 loss: tensor(0.9633) acc: 0.4066666666666667\n",
      "3620 loss: tensor(0.9632) acc: 0.4066666666666667\n",
      "3621 loss: tensor(0.9631) acc: 0.4066666666666667\n",
      "3622 loss: tensor(0.9631) acc: 0.4066666666666667\n",
      "3623 loss: tensor(0.9630) acc: 0.4066666666666667\n",
      "3624 loss: tensor(0.9630) acc: 0.4066666666666667\n",
      "3625 loss: tensor(0.9629) acc: 0.4066666666666667\n",
      "3626 loss: tensor(0.9628) acc: 0.4066666666666667\n",
      "3627 loss: tensor(0.9628) acc: 0.4066666666666667\n",
      "3628 loss: tensor(0.9627) acc: 0.4066666666666667\n",
      "3629 loss: tensor(0.9626) acc: 0.4066666666666667\n",
      "3630 loss: tensor(0.9626) acc: 0.4066666666666667\n",
      "3631 loss: tensor(0.9625) acc: 0.4066666666666667\n",
      "3632 loss: tensor(0.9624) acc: 0.4066666666666667\n",
      "3633 loss: tensor(0.9624) acc: 0.4066666666666667\n",
      "3634 loss: tensor(0.9623) acc: 0.4066666666666667\n",
      "3635 loss: tensor(0.9622) acc: 0.4066666666666667\n",
      "3636 loss: tensor(0.9622) acc: 0.4066666666666667\n",
      "3637 loss: tensor(0.9621) acc: 0.4066666666666667\n",
      "3638 loss: tensor(0.9620) acc: 0.4066666666666667\n",
      "3639 loss: tensor(0.9620) acc: 0.4066666666666667\n",
      "3640 loss: tensor(0.9619) acc: 0.4066666666666667\n",
      "3641 loss: tensor(0.9618) acc: 0.4066666666666667\n",
      "3642 loss: tensor(0.9618) acc: 0.41333333333333333\n",
      "3643 loss: tensor(0.9617) acc: 0.41333333333333333\n",
      "3644 loss: tensor(0.9616) acc: 0.41333333333333333\n",
      "3645 loss: tensor(0.9616) acc: 0.41333333333333333\n",
      "3646 loss: tensor(0.9615) acc: 0.41333333333333333\n",
      "3647 loss: tensor(0.9614) acc: 0.41333333333333333\n",
      "3648 loss: tensor(0.9614) acc: 0.41333333333333333\n",
      "3649 loss: tensor(0.9613) acc: 0.41333333333333333\n",
      "3650 loss: tensor(0.9613) acc: 0.41333333333333333\n",
      "3651 loss: tensor(0.9612) acc: 0.41333333333333333\n",
      "3652 loss: tensor(0.9611) acc: 0.41333333333333333\n",
      "3653 loss: tensor(0.9611) acc: 0.42\n",
      "3654 loss: tensor(0.9610) acc: 0.42\n",
      "3655 loss: tensor(0.9609) acc: 0.42\n",
      "3656 loss: tensor(0.9609) acc: 0.42\n",
      "3657 loss: tensor(0.9608) acc: 0.42\n",
      "3658 loss: tensor(0.9607) acc: 0.42\n",
      "3659 loss: tensor(0.9607) acc: 0.42\n",
      "3660 loss: tensor(0.9606) acc: 0.42\n",
      "3661 loss: tensor(0.9605) acc: 0.42\n",
      "3662 loss: tensor(0.9605) acc: 0.42\n",
      "3663 loss: tensor(0.9604) acc: 0.42\n",
      "3664 loss: tensor(0.9604) acc: 0.42\n",
      "3665 loss: tensor(0.9603) acc: 0.42\n",
      "3666 loss: tensor(0.9602) acc: 0.42\n",
      "3667 loss: tensor(0.9602) acc: 0.42\n",
      "3668 loss: tensor(0.9601) acc: 0.42\n",
      "3669 loss: tensor(0.9600) acc: 0.42\n",
      "3670 loss: tensor(0.9600) acc: 0.42\n",
      "3671 loss: tensor(0.9599) acc: 0.42\n",
      "3672 loss: tensor(0.9598) acc: 0.42\n",
      "3673 loss: tensor(0.9598) acc: 0.42\n",
      "3674 loss: tensor(0.9597) acc: 0.42\n",
      "3675 loss: tensor(0.9596) acc: 0.42\n",
      "3676 loss: tensor(0.9596) acc: 0.42\n",
      "3677 loss: tensor(0.9595) acc: 0.42\n",
      "3678 loss: tensor(0.9595) acc: 0.42\n",
      "3679 loss: tensor(0.9594) acc: 0.42\n",
      "3680 loss: tensor(0.9593) acc: 0.42\n",
      "3681 loss: tensor(0.9593) acc: 0.42\n",
      "3682 loss: tensor(0.9592) acc: 0.42\n",
      "3683 loss: tensor(0.9591) acc: 0.42\n",
      "3684 loss: tensor(0.9591) acc: 0.42\n",
      "3685 loss: tensor(0.9590) acc: 0.42\n",
      "3686 loss: tensor(0.9590) acc: 0.42\n",
      "3687 loss: tensor(0.9589) acc: 0.42\n",
      "3688 loss: tensor(0.9588) acc: 0.42\n",
      "3689 loss: tensor(0.9588) acc: 0.42\n",
      "3690 loss: tensor(0.9587) acc: 0.42\n",
      "3691 loss: tensor(0.9586) acc: 0.42\n",
      "3692 loss: tensor(0.9586) acc: 0.42\n",
      "3693 loss: tensor(0.9585) acc: 0.42\n",
      "3694 loss: tensor(0.9584) acc: 0.42\n",
      "3695 loss: tensor(0.9584) acc: 0.42\n",
      "3696 loss: tensor(0.9583) acc: 0.42\n",
      "3697 loss: tensor(0.9583) acc: 0.42\n",
      "3698 loss: tensor(0.9582) acc: 0.42\n",
      "3699 loss: tensor(0.9581) acc: 0.42\n",
      "3700 loss: tensor(0.9581) acc: 0.42\n",
      "3701 loss: tensor(0.9580) acc: 0.42\n",
      "3702 loss: tensor(0.9579) acc: 0.42\n",
      "3703 loss: tensor(0.9579) acc: 0.42\n",
      "3704 loss: tensor(0.9578) acc: 0.42\n",
      "3705 loss: tensor(0.9578) acc: 0.42\n",
      "3706 loss: tensor(0.9577) acc: 0.42\n",
      "3707 loss: tensor(0.9576) acc: 0.42\n",
      "3708 loss: tensor(0.9576) acc: 0.42\n",
      "3709 loss: tensor(0.9575) acc: 0.42\n",
      "3710 loss: tensor(0.9574) acc: 0.42\n",
      "3711 loss: tensor(0.9574) acc: 0.42\n",
      "3712 loss: tensor(0.9573) acc: 0.42\n",
      "3713 loss: tensor(0.9573) acc: 0.42\n",
      "3714 loss: tensor(0.9572) acc: 0.42\n",
      "3715 loss: tensor(0.9571) acc: 0.42\n",
      "3716 loss: tensor(0.9571) acc: 0.42\n",
      "3717 loss: tensor(0.9570) acc: 0.42\n",
      "3718 loss: tensor(0.9569) acc: 0.42\n",
      "3719 loss: tensor(0.9569) acc: 0.42\n",
      "3720 loss: tensor(0.9568) acc: 0.42\n",
      "3721 loss: tensor(0.9568) acc: 0.42\n",
      "3722 loss: tensor(0.9567) acc: 0.42\n",
      "3723 loss: tensor(0.9566) acc: 0.42\n",
      "3724 loss: tensor(0.9566) acc: 0.42\n",
      "3725 loss: tensor(0.9565) acc: 0.42\n",
      "3726 loss: tensor(0.9565) acc: 0.42\n",
      "3727 loss: tensor(0.9564) acc: 0.42\n",
      "3728 loss: tensor(0.9563) acc: 0.42\n",
      "3729 loss: tensor(0.9563) acc: 0.42\n",
      "3730 loss: tensor(0.9562) acc: 0.42\n",
      "3731 loss: tensor(0.9561) acc: 0.42\n",
      "3732 loss: tensor(0.9561) acc: 0.4266666666666667\n",
      "3733 loss: tensor(0.9560) acc: 0.4266666666666667\n",
      "3734 loss: tensor(0.9560) acc: 0.4266666666666667\n",
      "3735 loss: tensor(0.9559) acc: 0.43333333333333335\n",
      "3736 loss: tensor(0.9558) acc: 0.43333333333333335\n",
      "3737 loss: tensor(0.9558) acc: 0.43333333333333335\n",
      "3738 loss: tensor(0.9557) acc: 0.43333333333333335\n",
      "3739 loss: tensor(0.9557) acc: 0.43333333333333335\n",
      "3740 loss: tensor(0.9556) acc: 0.44\n",
      "3741 loss: tensor(0.9555) acc: 0.44\n",
      "3742 loss: tensor(0.9555) acc: 0.44666666666666666\n",
      "3743 loss: tensor(0.9554) acc: 0.44666666666666666\n",
      "3744 loss: tensor(0.9553) acc: 0.44666666666666666\n",
      "3745 loss: tensor(0.9553) acc: 0.44666666666666666\n",
      "3746 loss: tensor(0.9552) acc: 0.44666666666666666\n",
      "3747 loss: tensor(0.9552) acc: 0.44666666666666666\n",
      "3748 loss: tensor(0.9551) acc: 0.44666666666666666\n",
      "3749 loss: tensor(0.9550) acc: 0.44666666666666666\n",
      "3750 loss: tensor(0.9550) acc: 0.44666666666666666\n",
      "3751 loss: tensor(0.9549) acc: 0.44666666666666666\n",
      "3752 loss: tensor(0.9549) acc: 0.4533333333333333\n",
      "3753 loss: tensor(0.9548) acc: 0.4533333333333333\n",
      "3754 loss: tensor(0.9547) acc: 0.4533333333333333\n",
      "3755 loss: tensor(0.9547) acc: 0.4533333333333333\n",
      "3756 loss: tensor(0.9546) acc: 0.4533333333333333\n",
      "3757 loss: tensor(0.9546) acc: 0.4533333333333333\n",
      "3758 loss: tensor(0.9545) acc: 0.4533333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3759 loss: tensor(0.9544) acc: 0.4533333333333333\n",
      "3760 loss: tensor(0.9544) acc: 0.4533333333333333\n",
      "3761 loss: tensor(0.9543) acc: 0.46\n",
      "3762 loss: tensor(0.9542) acc: 0.46\n",
      "3763 loss: tensor(0.9542) acc: 0.46\n",
      "3764 loss: tensor(0.9541) acc: 0.46\n",
      "3765 loss: tensor(0.9541) acc: 0.46\n",
      "3766 loss: tensor(0.9540) acc: 0.46\n",
      "3767 loss: tensor(0.9539) acc: 0.46\n",
      "3768 loss: tensor(0.9539) acc: 0.46\n",
      "3769 loss: tensor(0.9538) acc: 0.46\n",
      "3770 loss: tensor(0.9538) acc: 0.46\n",
      "3771 loss: tensor(0.9537) acc: 0.46\n",
      "3772 loss: tensor(0.9536) acc: 0.46\n",
      "3773 loss: tensor(0.9536) acc: 0.46\n",
      "3774 loss: tensor(0.9535) acc: 0.46\n",
      "3775 loss: tensor(0.9535) acc: 0.46\n",
      "3776 loss: tensor(0.9534) acc: 0.46\n",
      "3777 loss: tensor(0.9533) acc: 0.46\n",
      "3778 loss: tensor(0.9533) acc: 0.46\n",
      "3779 loss: tensor(0.9532) acc: 0.46\n",
      "3780 loss: tensor(0.9532) acc: 0.46\n",
      "3781 loss: tensor(0.9531) acc: 0.46\n",
      "3782 loss: tensor(0.9530) acc: 0.4666666666666667\n",
      "3783 loss: tensor(0.9530) acc: 0.4666666666666667\n",
      "3784 loss: tensor(0.9529) acc: 0.4666666666666667\n",
      "3785 loss: tensor(0.9529) acc: 0.4666666666666667\n",
      "3786 loss: tensor(0.9528) acc: 0.4666666666666667\n",
      "3787 loss: tensor(0.9527) acc: 0.4666666666666667\n",
      "3788 loss: tensor(0.9527) acc: 0.4666666666666667\n",
      "3789 loss: tensor(0.9526) acc: 0.4666666666666667\n",
      "3790 loss: tensor(0.9526) acc: 0.47333333333333333\n",
      "3791 loss: tensor(0.9525) acc: 0.47333333333333333\n",
      "3792 loss: tensor(0.9524) acc: 0.47333333333333333\n",
      "3793 loss: tensor(0.9524) acc: 0.47333333333333333\n",
      "3794 loss: tensor(0.9523) acc: 0.47333333333333333\n",
      "3795 loss: tensor(0.9523) acc: 0.47333333333333333\n",
      "3796 loss: tensor(0.9522) acc: 0.47333333333333333\n",
      "3797 loss: tensor(0.9521) acc: 0.47333333333333333\n",
      "3798 loss: tensor(0.9521) acc: 0.47333333333333333\n",
      "3799 loss: tensor(0.9520) acc: 0.47333333333333333\n",
      "3800 loss: tensor(0.9520) acc: 0.47333333333333333\n",
      "3801 loss: tensor(0.9519) acc: 0.47333333333333333\n",
      "3802 loss: tensor(0.9518) acc: 0.48\n",
      "3803 loss: tensor(0.9518) acc: 0.48\n",
      "3804 loss: tensor(0.9517) acc: 0.48\n",
      "3805 loss: tensor(0.9517) acc: 0.48\n",
      "3806 loss: tensor(0.9516) acc: 0.48\n",
      "3807 loss: tensor(0.9515) acc: 0.48\n",
      "3808 loss: tensor(0.9515) acc: 0.48\n",
      "3809 loss: tensor(0.9514) acc: 0.48\n",
      "3810 loss: tensor(0.9514) acc: 0.48\n",
      "3811 loss: tensor(0.9513) acc: 0.48\n",
      "3812 loss: tensor(0.9512) acc: 0.48\n",
      "3813 loss: tensor(0.9512) acc: 0.48\n",
      "3814 loss: tensor(0.9511) acc: 0.48\n",
      "3815 loss: tensor(0.9511) acc: 0.48\n",
      "3816 loss: tensor(0.9510) acc: 0.48\n",
      "3817 loss: tensor(0.9509) acc: 0.48\n",
      "3818 loss: tensor(0.9509) acc: 0.48\n",
      "3819 loss: tensor(0.9508) acc: 0.48\n",
      "3820 loss: tensor(0.9508) acc: 0.48\n",
      "3821 loss: tensor(0.9507) acc: 0.48\n",
      "3822 loss: tensor(0.9506) acc: 0.48\n",
      "3823 loss: tensor(0.9506) acc: 0.48\n",
      "3824 loss: tensor(0.9505) acc: 0.48\n",
      "3825 loss: tensor(0.9505) acc: 0.48\n",
      "3826 loss: tensor(0.9504) acc: 0.48\n",
      "3827 loss: tensor(0.9503) acc: 0.48\n",
      "3828 loss: tensor(0.9503) acc: 0.48\n",
      "3829 loss: tensor(0.9502) acc: 0.48\n",
      "3830 loss: tensor(0.9502) acc: 0.48\n",
      "3831 loss: tensor(0.9501) acc: 0.48\n",
      "3832 loss: tensor(0.9501) acc: 0.48\n",
      "3833 loss: tensor(0.9500) acc: 0.48\n",
      "3834 loss: tensor(0.9499) acc: 0.48\n",
      "3835 loss: tensor(0.9499) acc: 0.48\n",
      "3836 loss: tensor(0.9498) acc: 0.48\n",
      "3837 loss: tensor(0.9498) acc: 0.48\n",
      "3838 loss: tensor(0.9497) acc: 0.48\n",
      "3839 loss: tensor(0.9496) acc: 0.48\n",
      "3840 loss: tensor(0.9496) acc: 0.48\n",
      "3841 loss: tensor(0.9495) acc: 0.48\n",
      "3842 loss: tensor(0.9495) acc: 0.48\n",
      "3843 loss: tensor(0.9494) acc: 0.48\n",
      "3844 loss: tensor(0.9493) acc: 0.48\n",
      "3845 loss: tensor(0.9493) acc: 0.48\n",
      "3846 loss: tensor(0.9492) acc: 0.4866666666666667\n",
      "3847 loss: tensor(0.9492) acc: 0.4866666666666667\n",
      "3848 loss: tensor(0.9491) acc: 0.4866666666666667\n",
      "3849 loss: tensor(0.9490) acc: 0.4866666666666667\n",
      "3850 loss: tensor(0.9490) acc: 0.4866666666666667\n",
      "3851 loss: tensor(0.9489) acc: 0.4866666666666667\n",
      "3852 loss: tensor(0.9489) acc: 0.4866666666666667\n",
      "3853 loss: tensor(0.9488) acc: 0.4866666666666667\n",
      "3854 loss: tensor(0.9488) acc: 0.4866666666666667\n",
      "3855 loss: tensor(0.9487) acc: 0.4866666666666667\n",
      "3856 loss: tensor(0.9486) acc: 0.4866666666666667\n",
      "3857 loss: tensor(0.9486) acc: 0.4866666666666667\n",
      "3858 loss: tensor(0.9485) acc: 0.4866666666666667\n",
      "3859 loss: tensor(0.9485) acc: 0.4866666666666667\n",
      "3860 loss: tensor(0.9484) acc: 0.4866666666666667\n",
      "3861 loss: tensor(0.9483) acc: 0.4866666666666667\n",
      "3862 loss: tensor(0.9483) acc: 0.4866666666666667\n",
      "3863 loss: tensor(0.9482) acc: 0.4866666666666667\n",
      "3864 loss: tensor(0.9482) acc: 0.4866666666666667\n",
      "3865 loss: tensor(0.9481) acc: 0.4866666666666667\n",
      "3866 loss: tensor(0.9480) acc: 0.4866666666666667\n",
      "3867 loss: tensor(0.9480) acc: 0.4866666666666667\n",
      "3868 loss: tensor(0.9479) acc: 0.4866666666666667\n",
      "3869 loss: tensor(0.9479) acc: 0.4866666666666667\n",
      "3870 loss: tensor(0.9478) acc: 0.4866666666666667\n",
      "3871 loss: tensor(0.9478) acc: 0.4866666666666667\n",
      "3872 loss: tensor(0.9477) acc: 0.4866666666666667\n",
      "3873 loss: tensor(0.9476) acc: 0.4866666666666667\n",
      "3874 loss: tensor(0.9476) acc: 0.4866666666666667\n",
      "3875 loss: tensor(0.9475) acc: 0.4866666666666667\n",
      "3876 loss: tensor(0.9475) acc: 0.4866666666666667\n",
      "3877 loss: tensor(0.9474) acc: 0.4866666666666667\n",
      "3878 loss: tensor(0.9473) acc: 0.4866666666666667\n",
      "3879 loss: tensor(0.9473) acc: 0.49333333333333335\n",
      "3880 loss: tensor(0.9472) acc: 0.49333333333333335\n",
      "3881 loss: tensor(0.9472) acc: 0.49333333333333335\n",
      "3882 loss: tensor(0.9471) acc: 0.49333333333333335\n",
      "3883 loss: tensor(0.9471) acc: 0.49333333333333335\n",
      "3884 loss: tensor(0.9470) acc: 0.49333333333333335\n",
      "3885 loss: tensor(0.9469) acc: 0.49333333333333335\n",
      "3886 loss: tensor(0.9469) acc: 0.49333333333333335\n",
      "3887 loss: tensor(0.9468) acc: 0.49333333333333335\n",
      "3888 loss: tensor(0.9468) acc: 0.49333333333333335\n",
      "3889 loss: tensor(0.9467) acc: 0.5\n",
      "3890 loss: tensor(0.9466) acc: 0.5\n",
      "3891 loss: tensor(0.9466) acc: 0.5\n",
      "3892 loss: tensor(0.9465) acc: 0.5\n",
      "3893 loss: tensor(0.9465) acc: 0.5\n",
      "3894 loss: tensor(0.9464) acc: 0.5\n",
      "3895 loss: tensor(0.9464) acc: 0.5\n",
      "3896 loss: tensor(0.9463) acc: 0.5\n",
      "3897 loss: tensor(0.9462) acc: 0.5\n",
      "3898 loss: tensor(0.9462) acc: 0.5\n",
      "3899 loss: tensor(0.9461) acc: 0.5\n",
      "3900 loss: tensor(0.9461) acc: 0.5066666666666667\n",
      "3901 loss: tensor(0.9460) acc: 0.5066666666666667\n",
      "3902 loss: tensor(0.9459) acc: 0.5066666666666667\n",
      "3903 loss: tensor(0.9459) acc: 0.5066666666666667\n",
      "3904 loss: tensor(0.9458) acc: 0.5066666666666667\n",
      "3905 loss: tensor(0.9458) acc: 0.5066666666666667\n",
      "3906 loss: tensor(0.9457) acc: 0.5066666666666667\n",
      "3907 loss: tensor(0.9457) acc: 0.5066666666666667\n",
      "3908 loss: tensor(0.9456) acc: 0.5066666666666667\n",
      "3909 loss: tensor(0.9455) acc: 0.5066666666666667\n",
      "3910 loss: tensor(0.9455) acc: 0.5066666666666667\n",
      "3911 loss: tensor(0.9454) acc: 0.5066666666666667\n",
      "3912 loss: tensor(0.9454) acc: 0.5133333333333333\n",
      "3913 loss: tensor(0.9453) acc: 0.5133333333333333\n",
      "3914 loss: tensor(0.9453) acc: 0.5133333333333333\n",
      "3915 loss: tensor(0.9452) acc: 0.52\n",
      "3916 loss: tensor(0.9451) acc: 0.52\n",
      "3917 loss: tensor(0.9451) acc: 0.52\n",
      "3918 loss: tensor(0.9450) acc: 0.52\n",
      "3919 loss: tensor(0.9450) acc: 0.52\n",
      "3920 loss: tensor(0.9449) acc: 0.52\n",
      "3921 loss: tensor(0.9448) acc: 0.52\n",
      "3922 loss: tensor(0.9448) acc: 0.52\n",
      "3923 loss: tensor(0.9447) acc: 0.52\n",
      "3924 loss: tensor(0.9447) acc: 0.52\n",
      "3925 loss: tensor(0.9446) acc: 0.5266666666666666\n",
      "3926 loss: tensor(0.9446) acc: 0.5266666666666666\n",
      "3927 loss: tensor(0.9445) acc: 0.5266666666666666\n",
      "3928 loss: tensor(0.9444) acc: 0.5266666666666666\n",
      "3929 loss: tensor(0.9444) acc: 0.5266666666666666\n",
      "3930 loss: tensor(0.9443) acc: 0.5266666666666666\n",
      "3931 loss: tensor(0.9443) acc: 0.5266666666666666\n",
      "3932 loss: tensor(0.9442) acc: 0.5266666666666666\n",
      "3933 loss: tensor(0.9442) acc: 0.5266666666666666\n",
      "3934 loss: tensor(0.9441) acc: 0.5266666666666666\n",
      "3935 loss: tensor(0.9440) acc: 0.5333333333333333\n",
      "3936 loss: tensor(0.9440) acc: 0.5333333333333333\n",
      "3937 loss: tensor(0.9439) acc: 0.5333333333333333\n",
      "3938 loss: tensor(0.9439) acc: 0.5333333333333333\n",
      "3939 loss: tensor(0.9438) acc: 0.5333333333333333\n",
      "3940 loss: tensor(0.9438) acc: 0.5333333333333333\n",
      "3941 loss: tensor(0.9437) acc: 0.5333333333333333\n",
      "3942 loss: tensor(0.9436) acc: 0.5333333333333333\n",
      "3943 loss: tensor(0.9436) acc: 0.5333333333333333\n",
      "3944 loss: tensor(0.9435) acc: 0.5333333333333333\n",
      "3945 loss: tensor(0.9435) acc: 0.5333333333333333\n",
      "3946 loss: tensor(0.9434) acc: 0.5333333333333333\n",
      "3947 loss: tensor(0.9433) acc: 0.5333333333333333\n",
      "3948 loss: tensor(0.9433) acc: 0.5333333333333333\n",
      "3949 loss: tensor(0.9432) acc: 0.5333333333333333\n",
      "3950 loss: tensor(0.9432) acc: 0.5333333333333333\n",
      "3951 loss: tensor(0.9431) acc: 0.5333333333333333\n",
      "3952 loss: tensor(0.9431) acc: 0.5333333333333333\n",
      "3953 loss: tensor(0.9430) acc: 0.5333333333333333\n",
      "3954 loss: tensor(0.9429) acc: 0.5333333333333333\n",
      "3955 loss: tensor(0.9429) acc: 0.5333333333333333\n",
      "3956 loss: tensor(0.9428) acc: 0.5333333333333333\n",
      "3957 loss: tensor(0.9428) acc: 0.5333333333333333\n",
      "3958 loss: tensor(0.9427) acc: 0.5333333333333333\n",
      "3959 loss: tensor(0.9427) acc: 0.5333333333333333\n",
      "3960 loss: tensor(0.9426) acc: 0.54\n",
      "3961 loss: tensor(0.9425) acc: 0.54\n",
      "3962 loss: tensor(0.9425) acc: 0.54\n",
      "3963 loss: tensor(0.9424) acc: 0.54\n",
      "3964 loss: tensor(0.9424) acc: 0.54\n",
      "3965 loss: tensor(0.9423) acc: 0.54\n",
      "3966 loss: tensor(0.9423) acc: 0.54\n",
      "3967 loss: tensor(0.9422) acc: 0.54\n",
      "3968 loss: tensor(0.9421) acc: 0.54\n",
      "3969 loss: tensor(0.9421) acc: 0.54\n",
      "3970 loss: tensor(0.9420) acc: 0.54\n",
      "3971 loss: tensor(0.9420) acc: 0.54\n",
      "3972 loss: tensor(0.9419) acc: 0.54\n",
      "3973 loss: tensor(0.9419) acc: 0.54\n",
      "3974 loss: tensor(0.9418) acc: 0.54\n",
      "3975 loss: tensor(0.9417) acc: 0.54\n",
      "3976 loss: tensor(0.9417) acc: 0.54\n",
      "3977 loss: tensor(0.9416) acc: 0.54\n",
      "3978 loss: tensor(0.9416) acc: 0.54\n",
      "3979 loss: tensor(0.9415) acc: 0.54\n",
      "3980 loss: tensor(0.9415) acc: 0.54\n",
      "3981 loss: tensor(0.9414) acc: 0.54\n",
      "3982 loss: tensor(0.9413) acc: 0.54\n",
      "3983 loss: tensor(0.9413) acc: 0.54\n",
      "3984 loss: tensor(0.9412) acc: 0.54\n",
      "3985 loss: tensor(0.9412) acc: 0.54\n",
      "3986 loss: tensor(0.9411) acc: 0.54\n",
      "3987 loss: tensor(0.9411) acc: 0.54\n",
      "3988 loss: tensor(0.9410) acc: 0.54\n",
      "3989 loss: tensor(0.9409) acc: 0.54\n",
      "3990 loss: tensor(0.9409) acc: 0.54\n",
      "3991 loss: tensor(0.9408) acc: 0.54\n",
      "3992 loss: tensor(0.9408) acc: 0.54\n",
      "3993 loss: tensor(0.9407) acc: 0.54\n",
      "3994 loss: tensor(0.9407) acc: 0.54\n",
      "3995 loss: tensor(0.9406) acc: 0.54\n",
      "3996 loss: tensor(0.9405) acc: 0.54\n",
      "3997 loss: tensor(0.9405) acc: 0.54\n",
      "3998 loss: tensor(0.9404) acc: 0.54\n",
      "3999 loss: tensor(0.9404) acc: 0.54\n",
      "4000 loss: tensor(0.9403) acc: 0.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4001 loss: tensor(0.9403) acc: 0.54\n",
      "4002 loss: tensor(0.9402) acc: 0.54\n",
      "4003 loss: tensor(0.9401) acc: 0.54\n",
      "4004 loss: tensor(0.9401) acc: 0.54\n",
      "4005 loss: tensor(0.9400) acc: 0.54\n",
      "4006 loss: tensor(0.9400) acc: 0.54\n",
      "4007 loss: tensor(0.9399) acc: 0.54\n",
      "4008 loss: tensor(0.9399) acc: 0.54\n",
      "4009 loss: tensor(0.9398) acc: 0.54\n",
      "4010 loss: tensor(0.9398) acc: 0.54\n",
      "4011 loss: tensor(0.9397) acc: 0.54\n",
      "4012 loss: tensor(0.9396) acc: 0.54\n",
      "4013 loss: tensor(0.9396) acc: 0.54\n",
      "4014 loss: tensor(0.9395) acc: 0.54\n",
      "4015 loss: tensor(0.9395) acc: 0.54\n",
      "4016 loss: tensor(0.9394) acc: 0.54\n",
      "4017 loss: tensor(0.9394) acc: 0.54\n",
      "4018 loss: tensor(0.9393) acc: 0.54\n",
      "4019 loss: tensor(0.9392) acc: 0.5466666666666666\n",
      "4020 loss: tensor(0.9392) acc: 0.5466666666666666\n",
      "4021 loss: tensor(0.9391) acc: 0.5466666666666666\n",
      "4022 loss: tensor(0.9391) acc: 0.5466666666666666\n",
      "4023 loss: tensor(0.9390) acc: 0.5466666666666666\n",
      "4024 loss: tensor(0.9390) acc: 0.5466666666666666\n",
      "4025 loss: tensor(0.9389) acc: 0.5466666666666666\n",
      "4026 loss: tensor(0.9388) acc: 0.5466666666666666\n",
      "4027 loss: tensor(0.9388) acc: 0.5466666666666666\n",
      "4028 loss: tensor(0.9387) acc: 0.5466666666666666\n",
      "4029 loss: tensor(0.9387) acc: 0.5533333333333333\n",
      "4030 loss: tensor(0.9386) acc: 0.5533333333333333\n",
      "4031 loss: tensor(0.9386) acc: 0.5533333333333333\n",
      "4032 loss: tensor(0.9385) acc: 0.5533333333333333\n",
      "4033 loss: tensor(0.9385) acc: 0.5533333333333333\n",
      "4034 loss: tensor(0.9384) acc: 0.5533333333333333\n",
      "4035 loss: tensor(0.9383) acc: 0.5533333333333333\n",
      "4036 loss: tensor(0.9383) acc: 0.5533333333333333\n",
      "4037 loss: tensor(0.9382) acc: 0.5533333333333333\n",
      "4038 loss: tensor(0.9382) acc: 0.56\n",
      "4039 loss: tensor(0.9381) acc: 0.56\n",
      "4040 loss: tensor(0.9381) acc: 0.56\n",
      "4041 loss: tensor(0.9380) acc: 0.56\n",
      "4042 loss: tensor(0.9379) acc: 0.56\n",
      "4043 loss: tensor(0.9379) acc: 0.56\n",
      "4044 loss: tensor(0.9378) acc: 0.56\n",
      "4045 loss: tensor(0.9378) acc: 0.56\n",
      "4046 loss: tensor(0.9377) acc: 0.56\n",
      "4047 loss: tensor(0.9377) acc: 0.56\n",
      "4048 loss: tensor(0.9376) acc: 0.56\n",
      "4049 loss: tensor(0.9376) acc: 0.56\n",
      "4050 loss: tensor(0.9375) acc: 0.56\n",
      "4051 loss: tensor(0.9374) acc: 0.56\n",
      "4052 loss: tensor(0.9374) acc: 0.56\n",
      "4053 loss: tensor(0.9373) acc: 0.56\n",
      "4054 loss: tensor(0.9373) acc: 0.56\n",
      "4055 loss: tensor(0.9372) acc: 0.56\n",
      "4056 loss: tensor(0.9372) acc: 0.56\n",
      "4057 loss: tensor(0.9371) acc: 0.56\n",
      "4058 loss: tensor(0.9370) acc: 0.56\n",
      "4059 loss: tensor(0.9370) acc: 0.56\n",
      "4060 loss: tensor(0.9369) acc: 0.56\n",
      "4061 loss: tensor(0.9369) acc: 0.56\n",
      "4062 loss: tensor(0.9368) acc: 0.56\n",
      "4063 loss: tensor(0.9368) acc: 0.56\n",
      "4064 loss: tensor(0.9367) acc: 0.56\n",
      "4065 loss: tensor(0.9367) acc: 0.56\n",
      "4066 loss: tensor(0.9366) acc: 0.56\n",
      "4067 loss: tensor(0.9365) acc: 0.56\n",
      "4068 loss: tensor(0.9365) acc: 0.56\n",
      "4069 loss: tensor(0.9364) acc: 0.56\n",
      "4070 loss: tensor(0.9364) acc: 0.56\n",
      "4071 loss: tensor(0.9363) acc: 0.56\n",
      "4072 loss: tensor(0.9363) acc: 0.56\n",
      "4073 loss: tensor(0.9362) acc: 0.56\n",
      "4074 loss: tensor(0.9362) acc: 0.56\n",
      "4075 loss: tensor(0.9361) acc: 0.56\n",
      "4076 loss: tensor(0.9360) acc: 0.56\n",
      "4077 loss: tensor(0.9360) acc: 0.5666666666666667\n",
      "4078 loss: tensor(0.9359) acc: 0.5733333333333334\n",
      "4079 loss: tensor(0.9359) acc: 0.5733333333333334\n",
      "4080 loss: tensor(0.9358) acc: 0.5733333333333334\n",
      "4081 loss: tensor(0.9358) acc: 0.5733333333333334\n",
      "4082 loss: tensor(0.9357) acc: 0.5733333333333334\n",
      "4083 loss: tensor(0.9356) acc: 0.5733333333333334\n",
      "4084 loss: tensor(0.9356) acc: 0.5733333333333334\n",
      "4085 loss: tensor(0.9355) acc: 0.5733333333333334\n",
      "4086 loss: tensor(0.9355) acc: 0.5733333333333334\n",
      "4087 loss: tensor(0.9354) acc: 0.5733333333333334\n",
      "4088 loss: tensor(0.9354) acc: 0.5733333333333334\n",
      "4089 loss: tensor(0.9353) acc: 0.5733333333333334\n",
      "4090 loss: tensor(0.9353) acc: 0.5733333333333334\n",
      "4091 loss: tensor(0.9352) acc: 0.5733333333333334\n",
      "4092 loss: tensor(0.9351) acc: 0.5733333333333334\n",
      "4093 loss: tensor(0.9351) acc: 0.5733333333333334\n",
      "4094 loss: tensor(0.9350) acc: 0.5733333333333334\n",
      "4095 loss: tensor(0.9350) acc: 0.5733333333333334\n",
      "4096 loss: tensor(0.9349) acc: 0.5733333333333334\n",
      "4097 loss: tensor(0.9349) acc: 0.5733333333333334\n",
      "4098 loss: tensor(0.9348) acc: 0.5733333333333334\n",
      "4099 loss: tensor(0.9348) acc: 0.5733333333333334\n",
      "4100 loss: tensor(0.9347) acc: 0.5733333333333334\n",
      "4101 loss: tensor(0.9346) acc: 0.5733333333333334\n",
      "4102 loss: tensor(0.9346) acc: 0.5733333333333334\n",
      "4103 loss: tensor(0.9345) acc: 0.58\n",
      "4104 loss: tensor(0.9345) acc: 0.58\n",
      "4105 loss: tensor(0.9344) acc: 0.58\n",
      "4106 loss: tensor(0.9344) acc: 0.58\n",
      "4107 loss: tensor(0.9343) acc: 0.58\n",
      "4108 loss: tensor(0.9343) acc: 0.58\n",
      "4109 loss: tensor(0.9342) acc: 0.5866666666666667\n",
      "4110 loss: tensor(0.9341) acc: 0.5866666666666667\n",
      "4111 loss: tensor(0.9341) acc: 0.5866666666666667\n",
      "4112 loss: tensor(0.9340) acc: 0.5866666666666667\n",
      "4113 loss: tensor(0.9340) acc: 0.5866666666666667\n",
      "4114 loss: tensor(0.9339) acc: 0.5866666666666667\n",
      "4115 loss: tensor(0.9339) acc: 0.5866666666666667\n",
      "4116 loss: tensor(0.9338) acc: 0.5866666666666667\n",
      "4117 loss: tensor(0.9338) acc: 0.5866666666666667\n",
      "4118 loss: tensor(0.9337) acc: 0.5866666666666667\n",
      "4119 loss: tensor(0.9337) acc: 0.5866666666666667\n",
      "4120 loss: tensor(0.9336) acc: 0.5866666666666667\n",
      "4121 loss: tensor(0.9335) acc: 0.5866666666666667\n",
      "4122 loss: tensor(0.9335) acc: 0.5866666666666667\n",
      "4123 loss: tensor(0.9334) acc: 0.5866666666666667\n",
      "4124 loss: tensor(0.9334) acc: 0.5866666666666667\n",
      "4125 loss: tensor(0.9333) acc: 0.5866666666666667\n",
      "4126 loss: tensor(0.9333) acc: 0.5866666666666667\n",
      "4127 loss: tensor(0.9332) acc: 0.5866666666666667\n",
      "4128 loss: tensor(0.9332) acc: 0.5866666666666667\n",
      "4129 loss: tensor(0.9331) acc: 0.5866666666666667\n",
      "4130 loss: tensor(0.9330) acc: 0.5866666666666667\n",
      "4131 loss: tensor(0.9330) acc: 0.5866666666666667\n",
      "4132 loss: tensor(0.9329) acc: 0.5866666666666667\n",
      "4133 loss: tensor(0.9329) acc: 0.5866666666666667\n",
      "4134 loss: tensor(0.9328) acc: 0.5866666666666667\n",
      "4135 loss: tensor(0.9328) acc: 0.5866666666666667\n",
      "4136 loss: tensor(0.9327) acc: 0.5866666666666667\n",
      "4137 loss: tensor(0.9327) acc: 0.5866666666666667\n",
      "4138 loss: tensor(0.9326) acc: 0.5866666666666667\n",
      "4139 loss: tensor(0.9326) acc: 0.5866666666666667\n",
      "4140 loss: tensor(0.9325) acc: 0.5866666666666667\n",
      "4141 loss: tensor(0.9324) acc: 0.5866666666666667\n",
      "4142 loss: tensor(0.9324) acc: 0.5866666666666667\n",
      "4143 loss: tensor(0.9323) acc: 0.5866666666666667\n",
      "4144 loss: tensor(0.9323) acc: 0.5866666666666667\n",
      "4145 loss: tensor(0.9322) acc: 0.5866666666666667\n",
      "4146 loss: tensor(0.9322) acc: 0.5866666666666667\n",
      "4147 loss: tensor(0.9321) acc: 0.5866666666666667\n",
      "4148 loss: tensor(0.9321) acc: 0.5866666666666667\n",
      "4149 loss: tensor(0.9320) acc: 0.5866666666666667\n",
      "4150 loss: tensor(0.9319) acc: 0.5866666666666667\n",
      "4151 loss: tensor(0.9319) acc: 0.5866666666666667\n",
      "4152 loss: tensor(0.9318) acc: 0.5866666666666667\n",
      "4153 loss: tensor(0.9318) acc: 0.5866666666666667\n",
      "4154 loss: tensor(0.9317) acc: 0.5866666666666667\n",
      "4155 loss: tensor(0.9317) acc: 0.5866666666666667\n",
      "4156 loss: tensor(0.9316) acc: 0.5866666666666667\n",
      "4157 loss: tensor(0.9316) acc: 0.5866666666666667\n",
      "4158 loss: tensor(0.9315) acc: 0.5866666666666667\n",
      "4159 loss: tensor(0.9315) acc: 0.5866666666666667\n",
      "4160 loss: tensor(0.9314) acc: 0.5866666666666667\n",
      "4161 loss: tensor(0.9313) acc: 0.5866666666666667\n",
      "4162 loss: tensor(0.9313) acc: 0.5866666666666667\n",
      "4163 loss: tensor(0.9312) acc: 0.5866666666666667\n",
      "4164 loss: tensor(0.9312) acc: 0.5866666666666667\n",
      "4165 loss: tensor(0.9311) acc: 0.5866666666666667\n",
      "4166 loss: tensor(0.9311) acc: 0.5866666666666667\n",
      "4167 loss: tensor(0.9310) acc: 0.5866666666666667\n",
      "4168 loss: tensor(0.9310) acc: 0.5866666666666667\n",
      "4169 loss: tensor(0.9309) acc: 0.5866666666666667\n",
      "4170 loss: tensor(0.9309) acc: 0.5866666666666667\n",
      "4171 loss: tensor(0.9308) acc: 0.5866666666666667\n",
      "4172 loss: tensor(0.9307) acc: 0.5866666666666667\n",
      "4173 loss: tensor(0.9307) acc: 0.5866666666666667\n",
      "4174 loss: tensor(0.9306) acc: 0.5933333333333334\n",
      "4175 loss: tensor(0.9306) acc: 0.5933333333333334\n",
      "4176 loss: tensor(0.9305) acc: 0.5933333333333334\n",
      "4177 loss: tensor(0.9305) acc: 0.5933333333333334\n",
      "4178 loss: tensor(0.9304) acc: 0.5933333333333334\n",
      "4179 loss: tensor(0.9304) acc: 0.5933333333333334\n",
      "4180 loss: tensor(0.9303) acc: 0.5933333333333334\n",
      "4181 loss: tensor(0.9303) acc: 0.5933333333333334\n",
      "4182 loss: tensor(0.9302) acc: 0.5933333333333334\n",
      "4183 loss: tensor(0.9301) acc: 0.5933333333333334\n",
      "4184 loss: tensor(0.9301) acc: 0.5933333333333334\n",
      "4185 loss: tensor(0.9300) acc: 0.5933333333333334\n",
      "4186 loss: tensor(0.9300) acc: 0.5933333333333334\n",
      "4187 loss: tensor(0.9299) acc: 0.5933333333333334\n",
      "4188 loss: tensor(0.9299) acc: 0.5933333333333334\n",
      "4189 loss: tensor(0.9298) acc: 0.5933333333333334\n",
      "4190 loss: tensor(0.9298) acc: 0.5933333333333334\n",
      "4191 loss: tensor(0.9297) acc: 0.5933333333333334\n",
      "4192 loss: tensor(0.9297) acc: 0.5933333333333334\n",
      "4193 loss: tensor(0.9296) acc: 0.5933333333333334\n",
      "4194 loss: tensor(0.9296) acc: 0.5933333333333334\n",
      "4195 loss: tensor(0.9295) acc: 0.5933333333333334\n",
      "4196 loss: tensor(0.9294) acc: 0.5933333333333334\n",
      "4197 loss: tensor(0.9294) acc: 0.5933333333333334\n",
      "4198 loss: tensor(0.9293) acc: 0.5933333333333334\n",
      "4199 loss: tensor(0.9293) acc: 0.5933333333333334\n",
      "4200 loss: tensor(0.9292) acc: 0.5933333333333334\n",
      "4201 loss: tensor(0.9292) acc: 0.5933333333333334\n",
      "4202 loss: tensor(0.9291) acc: 0.5933333333333334\n",
      "4203 loss: tensor(0.9291) acc: 0.5933333333333334\n",
      "4204 loss: tensor(0.9290) acc: 0.5933333333333334\n",
      "4205 loss: tensor(0.9290) acc: 0.5933333333333334\n",
      "4206 loss: tensor(0.9289) acc: 0.6\n",
      "4207 loss: tensor(0.9288) acc: 0.6\n",
      "4208 loss: tensor(0.9288) acc: 0.6\n",
      "4209 loss: tensor(0.9287) acc: 0.6\n",
      "4210 loss: tensor(0.9287) acc: 0.6\n",
      "4211 loss: tensor(0.9286) acc: 0.6\n",
      "4212 loss: tensor(0.9286) acc: 0.6\n",
      "4213 loss: tensor(0.9285) acc: 0.6\n",
      "4214 loss: tensor(0.9285) acc: 0.6\n",
      "4215 loss: tensor(0.9284) acc: 0.6\n",
      "4216 loss: tensor(0.9284) acc: 0.6\n",
      "4217 loss: tensor(0.9283) acc: 0.6\n",
      "4218 loss: tensor(0.9283) acc: 0.6\n",
      "4219 loss: tensor(0.9282) acc: 0.6\n",
      "4220 loss: tensor(0.9281) acc: 0.6\n",
      "4221 loss: tensor(0.9281) acc: 0.6\n",
      "4222 loss: tensor(0.9280) acc: 0.6\n",
      "4223 loss: tensor(0.9280) acc: 0.6\n",
      "4224 loss: tensor(0.9279) acc: 0.6\n",
      "4225 loss: tensor(0.9279) acc: 0.6\n",
      "4226 loss: tensor(0.9278) acc: 0.6\n",
      "4227 loss: tensor(0.9278) acc: 0.6\n",
      "4228 loss: tensor(0.9277) acc: 0.6\n",
      "4229 loss: tensor(0.9277) acc: 0.6\n",
      "4230 loss: tensor(0.9276) acc: 0.6\n",
      "4231 loss: tensor(0.9276) acc: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4232 loss: tensor(0.9275) acc: 0.6\n",
      "4233 loss: tensor(0.9275) acc: 0.6\n",
      "4234 loss: tensor(0.9274) acc: 0.6\n",
      "4235 loss: tensor(0.9273) acc: 0.6\n",
      "4236 loss: tensor(0.9273) acc: 0.6\n",
      "4237 loss: tensor(0.9272) acc: 0.6\n",
      "4238 loss: tensor(0.9272) acc: 0.6\n",
      "4239 loss: tensor(0.9271) acc: 0.6\n",
      "4240 loss: tensor(0.9271) acc: 0.6\n",
      "4241 loss: tensor(0.9270) acc: 0.6\n",
      "4242 loss: tensor(0.9270) acc: 0.6\n",
      "4243 loss: tensor(0.9269) acc: 0.6\n",
      "4244 loss: tensor(0.9269) acc: 0.6\n",
      "4245 loss: tensor(0.9268) acc: 0.6\n",
      "4246 loss: tensor(0.9268) acc: 0.6\n",
      "4247 loss: tensor(0.9267) acc: 0.6\n",
      "4248 loss: tensor(0.9267) acc: 0.6\n",
      "4249 loss: tensor(0.9266) acc: 0.6\n",
      "4250 loss: tensor(0.9265) acc: 0.6\n",
      "4251 loss: tensor(0.9265) acc: 0.6\n",
      "4252 loss: tensor(0.9264) acc: 0.6\n",
      "4253 loss: tensor(0.9264) acc: 0.6\n",
      "4254 loss: tensor(0.9263) acc: 0.6\n",
      "4255 loss: tensor(0.9263) acc: 0.6\n",
      "4256 loss: tensor(0.9262) acc: 0.6\n",
      "4257 loss: tensor(0.9262) acc: 0.6\n",
      "4258 loss: tensor(0.9261) acc: 0.6\n",
      "4259 loss: tensor(0.9261) acc: 0.6\n",
      "4260 loss: tensor(0.9260) acc: 0.6\n",
      "4261 loss: tensor(0.9260) acc: 0.6\n",
      "4262 loss: tensor(0.9259) acc: 0.6\n",
      "4263 loss: tensor(0.9259) acc: 0.6\n",
      "4264 loss: tensor(0.9258) acc: 0.6\n",
      "4265 loss: tensor(0.9257) acc: 0.6\n",
      "4266 loss: tensor(0.9257) acc: 0.6\n",
      "4267 loss: tensor(0.9256) acc: 0.6\n",
      "4268 loss: tensor(0.9256) acc: 0.6\n",
      "4269 loss: tensor(0.9255) acc: 0.6\n",
      "4270 loss: tensor(0.9255) acc: 0.6\n",
      "4271 loss: tensor(0.9254) acc: 0.6\n",
      "4272 loss: tensor(0.9254) acc: 0.6\n",
      "4273 loss: tensor(0.9253) acc: 0.6\n",
      "4274 loss: tensor(0.9253) acc: 0.6\n",
      "4275 loss: tensor(0.9252) acc: 0.6\n",
      "4276 loss: tensor(0.9252) acc: 0.6\n",
      "4277 loss: tensor(0.9251) acc: 0.6\n",
      "4278 loss: tensor(0.9251) acc: 0.6\n",
      "4279 loss: tensor(0.9250) acc: 0.6\n",
      "4280 loss: tensor(0.9250) acc: 0.6\n",
      "4281 loss: tensor(0.9249) acc: 0.6066666666666667\n",
      "4282 loss: tensor(0.9249) acc: 0.6066666666666667\n",
      "4283 loss: tensor(0.9248) acc: 0.6066666666666667\n",
      "4284 loss: tensor(0.9247) acc: 0.6066666666666667\n",
      "4285 loss: tensor(0.9247) acc: 0.6066666666666667\n",
      "4286 loss: tensor(0.9246) acc: 0.6066666666666667\n",
      "4287 loss: tensor(0.9246) acc: 0.6066666666666667\n",
      "4288 loss: tensor(0.9245) acc: 0.6066666666666667\n",
      "4289 loss: tensor(0.9245) acc: 0.6066666666666667\n",
      "4290 loss: tensor(0.9244) acc: 0.6066666666666667\n",
      "4291 loss: tensor(0.9244) acc: 0.6066666666666667\n",
      "4292 loss: tensor(0.9243) acc: 0.6066666666666667\n",
      "4293 loss: tensor(0.9243) acc: 0.6066666666666667\n",
      "4294 loss: tensor(0.9242) acc: 0.6066666666666667\n",
      "4295 loss: tensor(0.9242) acc: 0.6066666666666667\n",
      "4296 loss: tensor(0.9241) acc: 0.6066666666666667\n",
      "4297 loss: tensor(0.9241) acc: 0.6066666666666667\n",
      "4298 loss: tensor(0.9240) acc: 0.6066666666666667\n",
      "4299 loss: tensor(0.9240) acc: 0.6066666666666667\n",
      "4300 loss: tensor(0.9239) acc: 0.6066666666666667\n",
      "4301 loss: tensor(0.9239) acc: 0.6066666666666667\n",
      "4302 loss: tensor(0.9238) acc: 0.6066666666666667\n",
      "4303 loss: tensor(0.9237) acc: 0.6066666666666667\n",
      "4304 loss: tensor(0.9237) acc: 0.6066666666666667\n",
      "4305 loss: tensor(0.9236) acc: 0.6066666666666667\n",
      "4306 loss: tensor(0.9236) acc: 0.6066666666666667\n",
      "4307 loss: tensor(0.9235) acc: 0.6066666666666667\n",
      "4308 loss: tensor(0.9235) acc: 0.6066666666666667\n",
      "4309 loss: tensor(0.9234) acc: 0.6066666666666667\n",
      "4310 loss: tensor(0.9234) acc: 0.6066666666666667\n",
      "4311 loss: tensor(0.9233) acc: 0.6066666666666667\n",
      "4312 loss: tensor(0.9233) acc: 0.6066666666666667\n",
      "4313 loss: tensor(0.9232) acc: 0.6066666666666667\n",
      "4314 loss: tensor(0.9232) acc: 0.6066666666666667\n",
      "4315 loss: tensor(0.9231) acc: 0.6066666666666667\n",
      "4316 loss: tensor(0.9231) acc: 0.6066666666666667\n",
      "4317 loss: tensor(0.9230) acc: 0.6066666666666667\n",
      "4318 loss: tensor(0.9230) acc: 0.6066666666666667\n",
      "4319 loss: tensor(0.9229) acc: 0.6066666666666667\n",
      "4320 loss: tensor(0.9229) acc: 0.6066666666666667\n",
      "4321 loss: tensor(0.9228) acc: 0.6066666666666667\n",
      "4322 loss: tensor(0.9228) acc: 0.6066666666666667\n",
      "4323 loss: tensor(0.9227) acc: 0.6066666666666667\n",
      "4324 loss: tensor(0.9227) acc: 0.6066666666666667\n",
      "4325 loss: tensor(0.9226) acc: 0.6066666666666667\n",
      "4326 loss: tensor(0.9226) acc: 0.6066666666666667\n",
      "4327 loss: tensor(0.9225) acc: 0.6066666666666667\n",
      "4328 loss: tensor(0.9224) acc: 0.6066666666666667\n",
      "4329 loss: tensor(0.9224) acc: 0.6066666666666667\n",
      "4330 loss: tensor(0.9223) acc: 0.6066666666666667\n",
      "4331 loss: tensor(0.9223) acc: 0.6\n",
      "4332 loss: tensor(0.9222) acc: 0.6\n",
      "4333 loss: tensor(0.9222) acc: 0.6\n",
      "4334 loss: tensor(0.9221) acc: 0.6\n",
      "4335 loss: tensor(0.9221) acc: 0.6\n",
      "4336 loss: tensor(0.9220) acc: 0.6\n",
      "4337 loss: tensor(0.9220) acc: 0.6\n",
      "4338 loss: tensor(0.9219) acc: 0.6\n",
      "4339 loss: tensor(0.9219) acc: 0.6\n",
      "4340 loss: tensor(0.9218) acc: 0.6\n",
      "4341 loss: tensor(0.9218) acc: 0.6\n",
      "4342 loss: tensor(0.9217) acc: 0.6\n",
      "4343 loss: tensor(0.9217) acc: 0.6\n",
      "4344 loss: tensor(0.9216) acc: 0.6\n",
      "4345 loss: tensor(0.9216) acc: 0.6\n",
      "4346 loss: tensor(0.9215) acc: 0.6\n",
      "4347 loss: tensor(0.9215) acc: 0.6\n",
      "4348 loss: tensor(0.9214) acc: 0.6\n",
      "4349 loss: tensor(0.9214) acc: 0.6\n",
      "4350 loss: tensor(0.9213) acc: 0.6\n",
      "4351 loss: tensor(0.9213) acc: 0.6\n",
      "4352 loss: tensor(0.9212) acc: 0.6\n",
      "4353 loss: tensor(0.9212) acc: 0.6\n",
      "4354 loss: tensor(0.9211) acc: 0.6\n",
      "4355 loss: tensor(0.9211) acc: 0.6\n",
      "4356 loss: tensor(0.9210) acc: 0.6\n",
      "4357 loss: tensor(0.9210) acc: 0.6\n",
      "4358 loss: tensor(0.9209) acc: 0.6\n",
      "4359 loss: tensor(0.9209) acc: 0.6\n",
      "4360 loss: tensor(0.9208) acc: 0.6\n",
      "4361 loss: tensor(0.9208) acc: 0.6\n",
      "4362 loss: tensor(0.9207) acc: 0.6\n",
      "4363 loss: tensor(0.9206) acc: 0.6\n",
      "4364 loss: tensor(0.9206) acc: 0.6\n",
      "4365 loss: tensor(0.9205) acc: 0.6\n",
      "4366 loss: tensor(0.9205) acc: 0.6\n",
      "4367 loss: tensor(0.9204) acc: 0.6\n",
      "4368 loss: tensor(0.9204) acc: 0.6\n",
      "4369 loss: tensor(0.9203) acc: 0.6\n",
      "4370 loss: tensor(0.9203) acc: 0.6\n",
      "4371 loss: tensor(0.9202) acc: 0.6\n",
      "4372 loss: tensor(0.9202) acc: 0.6\n",
      "4373 loss: tensor(0.9201) acc: 0.6066666666666667\n",
      "4374 loss: tensor(0.9201) acc: 0.6066666666666667\n",
      "4375 loss: tensor(0.9200) acc: 0.6066666666666667\n",
      "4376 loss: tensor(0.9200) acc: 0.6066666666666667\n",
      "4377 loss: tensor(0.9199) acc: 0.6066666666666667\n",
      "4378 loss: tensor(0.9199) acc: 0.6066666666666667\n",
      "4379 loss: tensor(0.9198) acc: 0.6066666666666667\n",
      "4380 loss: tensor(0.9198) acc: 0.6066666666666667\n",
      "4381 loss: tensor(0.9197) acc: 0.6066666666666667\n",
      "4382 loss: tensor(0.9197) acc: 0.6066666666666667\n",
      "4383 loss: tensor(0.9196) acc: 0.6066666666666667\n",
      "4384 loss: tensor(0.9196) acc: 0.6066666666666667\n",
      "4385 loss: tensor(0.9195) acc: 0.6066666666666667\n",
      "4386 loss: tensor(0.9195) acc: 0.6066666666666667\n",
      "4387 loss: tensor(0.9194) acc: 0.6066666666666667\n",
      "4388 loss: tensor(0.9194) acc: 0.6066666666666667\n",
      "4389 loss: tensor(0.9193) acc: 0.6066666666666667\n",
      "4390 loss: tensor(0.9193) acc: 0.6066666666666667\n",
      "4391 loss: tensor(0.9192) acc: 0.6066666666666667\n",
      "4392 loss: tensor(0.9192) acc: 0.6066666666666667\n",
      "4393 loss: tensor(0.9191) acc: 0.6066666666666667\n",
      "4394 loss: tensor(0.9191) acc: 0.6066666666666667\n",
      "4395 loss: tensor(0.9190) acc: 0.6066666666666667\n",
      "4396 loss: tensor(0.9190) acc: 0.6066666666666667\n",
      "4397 loss: tensor(0.9189) acc: 0.6066666666666667\n",
      "4398 loss: tensor(0.9189) acc: 0.6066666666666667\n",
      "4399 loss: tensor(0.9188) acc: 0.6066666666666667\n",
      "4400 loss: tensor(0.9188) acc: 0.6066666666666667\n",
      "4401 loss: tensor(0.9187) acc: 0.6066666666666667\n",
      "4402 loss: tensor(0.9187) acc: 0.6066666666666667\n",
      "4403 loss: tensor(0.9186) acc: 0.6066666666666667\n",
      "4404 loss: tensor(0.9186) acc: 0.6066666666666667\n",
      "4405 loss: tensor(0.9185) acc: 0.6133333333333333\n",
      "4406 loss: tensor(0.9185) acc: 0.6133333333333333\n",
      "4407 loss: tensor(0.9184) acc: 0.6133333333333333\n",
      "4408 loss: tensor(0.9184) acc: 0.6133333333333333\n",
      "4409 loss: tensor(0.9183) acc: 0.6133333333333333\n",
      "4410 loss: tensor(0.9183) acc: 0.6133333333333333\n",
      "4411 loss: tensor(0.9182) acc: 0.6133333333333333\n",
      "4412 loss: tensor(0.9182) acc: 0.6133333333333333\n",
      "4413 loss: tensor(0.9181) acc: 0.6133333333333333\n",
      "4414 loss: tensor(0.9181) acc: 0.6133333333333333\n",
      "4415 loss: tensor(0.9180) acc: 0.6133333333333333\n",
      "4416 loss: tensor(0.9180) acc: 0.6133333333333333\n",
      "4417 loss: tensor(0.9179) acc: 0.6133333333333333\n",
      "4418 loss: tensor(0.9179) acc: 0.6133333333333333\n",
      "4419 loss: tensor(0.9178) acc: 0.6133333333333333\n",
      "4420 loss: tensor(0.9178) acc: 0.6133333333333333\n",
      "4421 loss: tensor(0.9177) acc: 0.6133333333333333\n",
      "4422 loss: tensor(0.9177) acc: 0.6133333333333333\n",
      "4423 loss: tensor(0.9176) acc: 0.6133333333333333\n",
      "4424 loss: tensor(0.9176) acc: 0.6133333333333333\n",
      "4425 loss: tensor(0.9175) acc: 0.6133333333333333\n",
      "4426 loss: tensor(0.9175) acc: 0.6133333333333333\n",
      "4427 loss: tensor(0.9174) acc: 0.6133333333333333\n",
      "4428 loss: tensor(0.9174) acc: 0.6133333333333333\n",
      "4429 loss: tensor(0.9173) acc: 0.6133333333333333\n",
      "4430 loss: tensor(0.9173) acc: 0.6133333333333333\n",
      "4431 loss: tensor(0.9172) acc: 0.6133333333333333\n",
      "4432 loss: tensor(0.9172) acc: 0.6133333333333333\n",
      "4433 loss: tensor(0.9171) acc: 0.6133333333333333\n",
      "4434 loss: tensor(0.9171) acc: 0.6133333333333333\n",
      "4435 loss: tensor(0.9170) acc: 0.6133333333333333\n",
      "4436 loss: tensor(0.9170) acc: 0.6133333333333333\n",
      "4437 loss: tensor(0.9169) acc: 0.6133333333333333\n",
      "4438 loss: tensor(0.9169) acc: 0.6133333333333333\n",
      "4439 loss: tensor(0.9168) acc: 0.6133333333333333\n",
      "4440 loss: tensor(0.9168) acc: 0.6133333333333333\n",
      "4441 loss: tensor(0.9167) acc: 0.6133333333333333\n",
      "4442 loss: tensor(0.9167) acc: 0.6133333333333333\n",
      "4443 loss: tensor(0.9166) acc: 0.6133333333333333\n",
      "4444 loss: tensor(0.9166) acc: 0.6133333333333333\n",
      "4445 loss: tensor(0.9165) acc: 0.6133333333333333\n",
      "4446 loss: tensor(0.9165) acc: 0.6133333333333333\n",
      "4447 loss: tensor(0.9164) acc: 0.6133333333333333\n",
      "4448 loss: tensor(0.9164) acc: 0.62\n",
      "4449 loss: tensor(0.9163) acc: 0.62\n",
      "4450 loss: tensor(0.9163) acc: 0.6266666666666667\n",
      "4451 loss: tensor(0.9162) acc: 0.6266666666666667\n",
      "4452 loss: tensor(0.9162) acc: 0.6266666666666667\n",
      "4453 loss: tensor(0.9161) acc: 0.6266666666666667\n",
      "4454 loss: tensor(0.9161) acc: 0.6266666666666667\n",
      "4455 loss: tensor(0.9160) acc: 0.6266666666666667\n",
      "4456 loss: tensor(0.9160) acc: 0.6266666666666667\n",
      "4457 loss: tensor(0.9159) acc: 0.6266666666666667\n",
      "4458 loss: tensor(0.9159) acc: 0.6266666666666667\n",
      "4459 loss: tensor(0.9158) acc: 0.6266666666666667\n",
      "4460 loss: tensor(0.9158) acc: 0.6266666666666667\n",
      "4461 loss: tensor(0.9157) acc: 0.6266666666666667\n",
      "4462 loss: tensor(0.9157) acc: 0.6266666666666667\n",
      "4463 loss: tensor(0.9156) acc: 0.6266666666666667\n",
      "4464 loss: tensor(0.9156) acc: 0.6266666666666667\n",
      "4465 loss: tensor(0.9155) acc: 0.6266666666666667\n",
      "4466 loss: tensor(0.9155) acc: 0.6266666666666667\n",
      "4467 loss: tensor(0.9154) acc: 0.6266666666666667\n",
      "4468 loss: tensor(0.9154) acc: 0.6266666666666667\n",
      "4469 loss: tensor(0.9153) acc: 0.6266666666666667\n",
      "4470 loss: tensor(0.9153) acc: 0.6266666666666667\n",
      "4471 loss: tensor(0.9152) acc: 0.6266666666666667\n",
      "4472 loss: tensor(0.9152) acc: 0.6266666666666667\n",
      "4473 loss: tensor(0.9152) acc: 0.6266666666666667\n",
      "4474 loss: tensor(0.9151) acc: 0.6266666666666667\n",
      "4475 loss: tensor(0.9151) acc: 0.6266666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4476 loss: tensor(0.9150) acc: 0.6266666666666667\n",
      "4477 loss: tensor(0.9150) acc: 0.6266666666666667\n",
      "4478 loss: tensor(0.9149) acc: 0.6266666666666667\n",
      "4479 loss: tensor(0.9149) acc: 0.6266666666666667\n",
      "4480 loss: tensor(0.9148) acc: 0.6266666666666667\n",
      "4481 loss: tensor(0.9148) acc: 0.6266666666666667\n",
      "4482 loss: tensor(0.9147) acc: 0.6266666666666667\n",
      "4483 loss: tensor(0.9147) acc: 0.6266666666666667\n",
      "4484 loss: tensor(0.9146) acc: 0.6266666666666667\n",
      "4485 loss: tensor(0.9146) acc: 0.6266666666666667\n",
      "4486 loss: tensor(0.9145) acc: 0.6266666666666667\n",
      "4487 loss: tensor(0.9145) acc: 0.6266666666666667\n",
      "4488 loss: tensor(0.9144) acc: 0.6266666666666667\n",
      "4489 loss: tensor(0.9144) acc: 0.6266666666666667\n",
      "4490 loss: tensor(0.9143) acc: 0.6266666666666667\n",
      "4491 loss: tensor(0.9143) acc: 0.6266666666666667\n",
      "4492 loss: tensor(0.9142) acc: 0.6266666666666667\n",
      "4493 loss: tensor(0.9142) acc: 0.6266666666666667\n",
      "4494 loss: tensor(0.9141) acc: 0.6266666666666667\n",
      "4495 loss: tensor(0.9141) acc: 0.6266666666666667\n",
      "4496 loss: tensor(0.9140) acc: 0.6266666666666667\n",
      "4497 loss: tensor(0.9140) acc: 0.6266666666666667\n",
      "4498 loss: tensor(0.9139) acc: 0.6266666666666667\n",
      "4499 loss: tensor(0.9139) acc: 0.6266666666666667\n",
      "4500 loss: tensor(0.9138) acc: 0.6266666666666667\n",
      "4501 loss: tensor(0.9138) acc: 0.6266666666666667\n",
      "4502 loss: tensor(0.9137) acc: 0.6266666666666667\n",
      "4503 loss: tensor(0.9137) acc: 0.6266666666666667\n",
      "4504 loss: tensor(0.9136) acc: 0.6266666666666667\n",
      "4505 loss: tensor(0.9136) acc: 0.6266666666666667\n",
      "4506 loss: tensor(0.9136) acc: 0.6266666666666667\n",
      "4507 loss: tensor(0.9135) acc: 0.6266666666666667\n",
      "4508 loss: tensor(0.9135) acc: 0.6266666666666667\n",
      "4509 loss: tensor(0.9134) acc: 0.6266666666666667\n",
      "4510 loss: tensor(0.9134) acc: 0.6266666666666667\n",
      "4511 loss: tensor(0.9133) acc: 0.6266666666666667\n",
      "4512 loss: tensor(0.9133) acc: 0.6266666666666667\n",
      "4513 loss: tensor(0.9132) acc: 0.6266666666666667\n",
      "4514 loss: tensor(0.9132) acc: 0.6266666666666667\n",
      "4515 loss: tensor(0.9131) acc: 0.6266666666666667\n",
      "4516 loss: tensor(0.9131) acc: 0.6266666666666667\n",
      "4517 loss: tensor(0.9130) acc: 0.6266666666666667\n",
      "4518 loss: tensor(0.9130) acc: 0.6266666666666667\n",
      "4519 loss: tensor(0.9129) acc: 0.6266666666666667\n",
      "4520 loss: tensor(0.9129) acc: 0.6266666666666667\n",
      "4521 loss: tensor(0.9128) acc: 0.6266666666666667\n",
      "4522 loss: tensor(0.9128) acc: 0.6266666666666667\n",
      "4523 loss: tensor(0.9127) acc: 0.6266666666666667\n",
      "4524 loss: tensor(0.9127) acc: 0.6266666666666667\n",
      "4525 loss: tensor(0.9126) acc: 0.6266666666666667\n",
      "4526 loss: tensor(0.9126) acc: 0.6266666666666667\n",
      "4527 loss: tensor(0.9125) acc: 0.6266666666666667\n",
      "4528 loss: tensor(0.9125) acc: 0.6266666666666667\n",
      "4529 loss: tensor(0.9125) acc: 0.6266666666666667\n",
      "4530 loss: tensor(0.9124) acc: 0.6266666666666667\n",
      "4531 loss: tensor(0.9124) acc: 0.6266666666666667\n",
      "4532 loss: tensor(0.9123) acc: 0.6266666666666667\n",
      "4533 loss: tensor(0.9123) acc: 0.6266666666666667\n",
      "4534 loss: tensor(0.9122) acc: 0.6266666666666667\n",
      "4535 loss: tensor(0.9122) acc: 0.6266666666666667\n",
      "4536 loss: tensor(0.9121) acc: 0.6266666666666667\n",
      "4537 loss: tensor(0.9121) acc: 0.6266666666666667\n",
      "4538 loss: tensor(0.9120) acc: 0.6266666666666667\n",
      "4539 loss: tensor(0.9120) acc: 0.6266666666666667\n",
      "4540 loss: tensor(0.9119) acc: 0.6266666666666667\n",
      "4541 loss: tensor(0.9119) acc: 0.6266666666666667\n",
      "4542 loss: tensor(0.9118) acc: 0.6266666666666667\n",
      "4543 loss: tensor(0.9118) acc: 0.6266666666666667\n",
      "4544 loss: tensor(0.9117) acc: 0.6333333333333333\n",
      "4545 loss: tensor(0.9117) acc: 0.6333333333333333\n",
      "4546 loss: tensor(0.9116) acc: 0.6333333333333333\n",
      "4547 loss: tensor(0.9116) acc: 0.6333333333333333\n",
      "4548 loss: tensor(0.9116) acc: 0.6333333333333333\n",
      "4549 loss: tensor(0.9115) acc: 0.6333333333333333\n",
      "4550 loss: tensor(0.9115) acc: 0.6333333333333333\n",
      "4551 loss: tensor(0.9114) acc: 0.6333333333333333\n",
      "4552 loss: tensor(0.9114) acc: 0.6333333333333333\n",
      "4553 loss: tensor(0.9113) acc: 0.6333333333333333\n",
      "4554 loss: tensor(0.9113) acc: 0.6333333333333333\n",
      "4555 loss: tensor(0.9112) acc: 0.6333333333333333\n",
      "4556 loss: tensor(0.9112) acc: 0.6333333333333333\n",
      "4557 loss: tensor(0.9111) acc: 0.6333333333333333\n",
      "4558 loss: tensor(0.9111) acc: 0.6333333333333333\n",
      "4559 loss: tensor(0.9110) acc: 0.6333333333333333\n",
      "4560 loss: tensor(0.9110) acc: 0.6333333333333333\n",
      "4561 loss: tensor(0.9109) acc: 0.6333333333333333\n",
      "4562 loss: tensor(0.9109) acc: 0.6333333333333333\n",
      "4563 loss: tensor(0.9109) acc: 0.6333333333333333\n",
      "4564 loss: tensor(0.9108) acc: 0.6333333333333333\n",
      "4565 loss: tensor(0.9108) acc: 0.6333333333333333\n",
      "4566 loss: tensor(0.9107) acc: 0.6333333333333333\n",
      "4567 loss: tensor(0.9107) acc: 0.6333333333333333\n",
      "4568 loss: tensor(0.9106) acc: 0.6333333333333333\n",
      "4569 loss: tensor(0.9106) acc: 0.6333333333333333\n",
      "4570 loss: tensor(0.9105) acc: 0.6333333333333333\n",
      "4571 loss: tensor(0.9105) acc: 0.6333333333333333\n",
      "4572 loss: tensor(0.9104) acc: 0.6333333333333333\n",
      "4573 loss: tensor(0.9104) acc: 0.6333333333333333\n",
      "4574 loss: tensor(0.9103) acc: 0.6333333333333333\n",
      "4575 loss: tensor(0.9103) acc: 0.6333333333333333\n",
      "4576 loss: tensor(0.9102) acc: 0.6333333333333333\n",
      "4577 loss: tensor(0.9102) acc: 0.6333333333333333\n",
      "4578 loss: tensor(0.9102) acc: 0.6333333333333333\n",
      "4579 loss: tensor(0.9101) acc: 0.6333333333333333\n",
      "4580 loss: tensor(0.9101) acc: 0.64\n",
      "4581 loss: tensor(0.9100) acc: 0.64\n",
      "4582 loss: tensor(0.9100) acc: 0.64\n",
      "4583 loss: tensor(0.9099) acc: 0.64\n",
      "4584 loss: tensor(0.9099) acc: 0.64\n",
      "4585 loss: tensor(0.9098) acc: 0.64\n",
      "4586 loss: tensor(0.9098) acc: 0.64\n",
      "4587 loss: tensor(0.9097) acc: 0.64\n",
      "4588 loss: tensor(0.9097) acc: 0.64\n",
      "4589 loss: tensor(0.9096) acc: 0.64\n",
      "4590 loss: tensor(0.9096) acc: 0.64\n",
      "4591 loss: tensor(0.9095) acc: 0.64\n",
      "4592 loss: tensor(0.9095) acc: 0.64\n",
      "4593 loss: tensor(0.9095) acc: 0.64\n",
      "4594 loss: tensor(0.9094) acc: 0.64\n",
      "4595 loss: tensor(0.9094) acc: 0.64\n",
      "4596 loss: tensor(0.9093) acc: 0.64\n",
      "4597 loss: tensor(0.9093) acc: 0.64\n",
      "4598 loss: tensor(0.9092) acc: 0.64\n",
      "4599 loss: tensor(0.9092) acc: 0.64\n",
      "4600 loss: tensor(0.9091) acc: 0.64\n",
      "4601 loss: tensor(0.9091) acc: 0.64\n",
      "4602 loss: tensor(0.9090) acc: 0.64\n",
      "4603 loss: tensor(0.9090) acc: 0.64\n",
      "4604 loss: tensor(0.9090) acc: 0.64\n",
      "4605 loss: tensor(0.9089) acc: 0.64\n",
      "4606 loss: tensor(0.9089) acc: 0.64\n",
      "4607 loss: tensor(0.9088) acc: 0.64\n",
      "4608 loss: tensor(0.9088) acc: 0.64\n",
      "4609 loss: tensor(0.9087) acc: 0.64\n",
      "4610 loss: tensor(0.9087) acc: 0.64\n",
      "4611 loss: tensor(0.9086) acc: 0.64\n",
      "4612 loss: tensor(0.9086) acc: 0.64\n",
      "4613 loss: tensor(0.9085) acc: 0.64\n",
      "4614 loss: tensor(0.9085) acc: 0.64\n",
      "4615 loss: tensor(0.9084) acc: 0.64\n",
      "4616 loss: tensor(0.9084) acc: 0.64\n",
      "4617 loss: tensor(0.9084) acc: 0.64\n",
      "4618 loss: tensor(0.9083) acc: 0.64\n",
      "4619 loss: tensor(0.9083) acc: 0.64\n",
      "4620 loss: tensor(0.9082) acc: 0.64\n",
      "4621 loss: tensor(0.9082) acc: 0.64\n",
      "4622 loss: tensor(0.9081) acc: 0.64\n",
      "4623 loss: tensor(0.9081) acc: 0.64\n",
      "4624 loss: tensor(0.9080) acc: 0.64\n",
      "4625 loss: tensor(0.9080) acc: 0.64\n",
      "4626 loss: tensor(0.9079) acc: 0.64\n",
      "4627 loss: tensor(0.9079) acc: 0.64\n",
      "4628 loss: tensor(0.9079) acc: 0.64\n",
      "4629 loss: tensor(0.9078) acc: 0.64\n",
      "4630 loss: tensor(0.9078) acc: 0.6466666666666666\n",
      "4631 loss: tensor(0.9077) acc: 0.6466666666666666\n",
      "4632 loss: tensor(0.9077) acc: 0.6466666666666666\n",
      "4633 loss: tensor(0.9076) acc: 0.6466666666666666\n",
      "4634 loss: tensor(0.9076) acc: 0.6466666666666666\n",
      "4635 loss: tensor(0.9075) acc: 0.6466666666666666\n",
      "4636 loss: tensor(0.9075) acc: 0.6466666666666666\n",
      "4637 loss: tensor(0.9075) acc: 0.6466666666666666\n",
      "4638 loss: tensor(0.9074) acc: 0.6466666666666666\n",
      "4639 loss: tensor(0.9074) acc: 0.6466666666666666\n",
      "4640 loss: tensor(0.9073) acc: 0.6466666666666666\n",
      "4641 loss: tensor(0.9073) acc: 0.6466666666666666\n",
      "4642 loss: tensor(0.9072) acc: 0.6533333333333333\n",
      "4643 loss: tensor(0.9072) acc: 0.6533333333333333\n",
      "4644 loss: tensor(0.9071) acc: 0.6533333333333333\n",
      "4645 loss: tensor(0.9071) acc: 0.6533333333333333\n",
      "4646 loss: tensor(0.9070) acc: 0.6533333333333333\n",
      "4647 loss: tensor(0.9070) acc: 0.6533333333333333\n",
      "4648 loss: tensor(0.9070) acc: 0.6533333333333333\n",
      "4649 loss: tensor(0.9069) acc: 0.6533333333333333\n",
      "4650 loss: tensor(0.9069) acc: 0.6533333333333333\n",
      "4651 loss: tensor(0.9068) acc: 0.6533333333333333\n",
      "4652 loss: tensor(0.9068) acc: 0.6533333333333333\n",
      "4653 loss: tensor(0.9067) acc: 0.6533333333333333\n",
      "4654 loss: tensor(0.9067) acc: 0.6533333333333333\n",
      "4655 loss: tensor(0.9066) acc: 0.6533333333333333\n",
      "4656 loss: tensor(0.9066) acc: 0.6533333333333333\n",
      "4657 loss: tensor(0.9066) acc: 0.6533333333333333\n",
      "4658 loss: tensor(0.9065) acc: 0.6533333333333333\n",
      "4659 loss: tensor(0.9065) acc: 0.6533333333333333\n",
      "4660 loss: tensor(0.9064) acc: 0.6533333333333333\n",
      "4661 loss: tensor(0.9064) acc: 0.6533333333333333\n",
      "4662 loss: tensor(0.9063) acc: 0.6533333333333333\n",
      "4663 loss: tensor(0.9063) acc: 0.6533333333333333\n",
      "4664 loss: tensor(0.9062) acc: 0.6533333333333333\n",
      "4665 loss: tensor(0.9062) acc: 0.6533333333333333\n",
      "4666 loss: tensor(0.9062) acc: 0.6533333333333333\n",
      "4667 loss: tensor(0.9061) acc: 0.6533333333333333\n",
      "4668 loss: tensor(0.9061) acc: 0.6533333333333333\n",
      "4669 loss: tensor(0.9060) acc: 0.6533333333333333\n",
      "4670 loss: tensor(0.9060) acc: 0.6533333333333333\n",
      "4671 loss: tensor(0.9059) acc: 0.6533333333333333\n",
      "4672 loss: tensor(0.9059) acc: 0.6533333333333333\n",
      "4673 loss: tensor(0.9058) acc: 0.6533333333333333\n",
      "4674 loss: tensor(0.9058) acc: 0.6533333333333333\n",
      "4675 loss: tensor(0.9058) acc: 0.6533333333333333\n",
      "4676 loss: tensor(0.9057) acc: 0.6533333333333333\n",
      "4677 loss: tensor(0.9057) acc: 0.6533333333333333\n",
      "4678 loss: tensor(0.9056) acc: 0.6533333333333333\n",
      "4679 loss: tensor(0.9056) acc: 0.6533333333333333\n",
      "4680 loss: tensor(0.9055) acc: 0.6533333333333333\n",
      "4681 loss: tensor(0.9055) acc: 0.6533333333333333\n",
      "4682 loss: tensor(0.9055) acc: 0.6533333333333333\n",
      "4683 loss: tensor(0.9054) acc: 0.6533333333333333\n",
      "4684 loss: tensor(0.9054) acc: 0.6533333333333333\n",
      "4685 loss: tensor(0.9053) acc: 0.6533333333333333\n",
      "4686 loss: tensor(0.9053) acc: 0.6533333333333333\n",
      "4687 loss: tensor(0.9052) acc: 0.6533333333333333\n",
      "4688 loss: tensor(0.9052) acc: 0.6533333333333333\n",
      "4689 loss: tensor(0.9051) acc: 0.6533333333333333\n",
      "4690 loss: tensor(0.9051) acc: 0.6533333333333333\n",
      "4691 loss: tensor(0.9051) acc: 0.6533333333333333\n",
      "4692 loss: tensor(0.9050) acc: 0.6533333333333333\n",
      "4693 loss: tensor(0.9050) acc: 0.6533333333333333\n",
      "4694 loss: tensor(0.9049) acc: 0.6533333333333333\n",
      "4695 loss: tensor(0.9049) acc: 0.6533333333333333\n",
      "4696 loss: tensor(0.9048) acc: 0.6533333333333333\n",
      "4697 loss: tensor(0.9048) acc: 0.6533333333333333\n",
      "4698 loss: tensor(0.9048) acc: 0.6533333333333333\n",
      "4699 loss: tensor(0.9047) acc: 0.6533333333333333\n",
      "4700 loss: tensor(0.9047) acc: 0.6533333333333333\n",
      "4701 loss: tensor(0.9046) acc: 0.6533333333333333\n",
      "4702 loss: tensor(0.9046) acc: 0.6533333333333333\n",
      "4703 loss: tensor(0.9045) acc: 0.6533333333333333\n",
      "4704 loss: tensor(0.9045) acc: 0.6533333333333333\n",
      "4705 loss: tensor(0.9044) acc: 0.6533333333333333\n",
      "4706 loss: tensor(0.9044) acc: 0.6533333333333333\n",
      "4707 loss: tensor(0.9044) acc: 0.6533333333333333\n",
      "4708 loss: tensor(0.9043) acc: 0.66\n",
      "4709 loss: tensor(0.9043) acc: 0.66\n",
      "4710 loss: tensor(0.9042) acc: 0.66\n",
      "4711 loss: tensor(0.9042) acc: 0.66\n",
      "4712 loss: tensor(0.9041) acc: 0.66\n",
      "4713 loss: tensor(0.9041) acc: 0.66\n",
      "4714 loss: tensor(0.9041) acc: 0.66\n",
      "4715 loss: tensor(0.9040) acc: 0.66\n",
      "4716 loss: tensor(0.9040) acc: 0.66\n",
      "4717 loss: tensor(0.9039) acc: 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4718 loss: tensor(0.9039) acc: 0.66\n",
      "4719 loss: tensor(0.9038) acc: 0.66\n",
      "4720 loss: tensor(0.9038) acc: 0.66\n",
      "4721 loss: tensor(0.9038) acc: 0.66\n",
      "4722 loss: tensor(0.9037) acc: 0.66\n",
      "4723 loss: tensor(0.9037) acc: 0.66\n",
      "4724 loss: tensor(0.9036) acc: 0.66\n",
      "4725 loss: tensor(0.9036) acc: 0.66\n",
      "4726 loss: tensor(0.9035) acc: 0.66\n",
      "4727 loss: tensor(0.9035) acc: 0.66\n",
      "4728 loss: tensor(0.9035) acc: 0.66\n",
      "4729 loss: tensor(0.9034) acc: 0.66\n",
      "4730 loss: tensor(0.9034) acc: 0.66\n",
      "4731 loss: tensor(0.9033) acc: 0.66\n",
      "4732 loss: tensor(0.9033) acc: 0.66\n",
      "4733 loss: tensor(0.9032) acc: 0.66\n",
      "4734 loss: tensor(0.9032) acc: 0.66\n",
      "4735 loss: tensor(0.9032) acc: 0.66\n",
      "4736 loss: tensor(0.9031) acc: 0.66\n",
      "4737 loss: tensor(0.9031) acc: 0.66\n",
      "4738 loss: tensor(0.9030) acc: 0.66\n",
      "4739 loss: tensor(0.9030) acc: 0.66\n",
      "4740 loss: tensor(0.9029) acc: 0.66\n",
      "4741 loss: tensor(0.9029) acc: 0.66\n",
      "4742 loss: tensor(0.9029) acc: 0.66\n",
      "4743 loss: tensor(0.9028) acc: 0.66\n",
      "4744 loss: tensor(0.9028) acc: 0.66\n",
      "4745 loss: tensor(0.9027) acc: 0.66\n",
      "4746 loss: tensor(0.9027) acc: 0.66\n",
      "4747 loss: tensor(0.9026) acc: 0.66\n",
      "4748 loss: tensor(0.9026) acc: 0.66\n",
      "4749 loss: tensor(0.9026) acc: 0.66\n",
      "4750 loss: tensor(0.9025) acc: 0.66\n",
      "4751 loss: tensor(0.9025) acc: 0.66\n",
      "4752 loss: tensor(0.9024) acc: 0.66\n",
      "4753 loss: tensor(0.9024) acc: 0.66\n",
      "4754 loss: tensor(0.9023) acc: 0.66\n",
      "4755 loss: tensor(0.9023) acc: 0.66\n",
      "4756 loss: tensor(0.9023) acc: 0.66\n",
      "4757 loss: tensor(0.9022) acc: 0.66\n",
      "4758 loss: tensor(0.9022) acc: 0.66\n",
      "4759 loss: tensor(0.9021) acc: 0.66\n",
      "4760 loss: tensor(0.9021) acc: 0.66\n",
      "4761 loss: tensor(0.9021) acc: 0.66\n",
      "4762 loss: tensor(0.9020) acc: 0.66\n",
      "4763 loss: tensor(0.9020) acc: 0.66\n",
      "4764 loss: tensor(0.9019) acc: 0.66\n",
      "4765 loss: tensor(0.9019) acc: 0.66\n",
      "4766 loss: tensor(0.9018) acc: 0.66\n",
      "4767 loss: tensor(0.9018) acc: 0.66\n",
      "4768 loss: tensor(0.9018) acc: 0.66\n",
      "4769 loss: tensor(0.9017) acc: 0.66\n",
      "4770 loss: tensor(0.9017) acc: 0.66\n",
      "4771 loss: tensor(0.9016) acc: 0.66\n",
      "4772 loss: tensor(0.9016) acc: 0.66\n",
      "4773 loss: tensor(0.9016) acc: 0.66\n",
      "4774 loss: tensor(0.9015) acc: 0.66\n",
      "4775 loss: tensor(0.9015) acc: 0.66\n",
      "4776 loss: tensor(0.9014) acc: 0.66\n",
      "4777 loss: tensor(0.9014) acc: 0.66\n",
      "4778 loss: tensor(0.9013) acc: 0.66\n",
      "4779 loss: tensor(0.9013) acc: 0.66\n",
      "4780 loss: tensor(0.9013) acc: 0.66\n",
      "4781 loss: tensor(0.9012) acc: 0.66\n",
      "4782 loss: tensor(0.9012) acc: 0.66\n",
      "4783 loss: tensor(0.9011) acc: 0.66\n",
      "4784 loss: tensor(0.9011) acc: 0.66\n",
      "4785 loss: tensor(0.9011) acc: 0.66\n",
      "4786 loss: tensor(0.9010) acc: 0.66\n",
      "4787 loss: tensor(0.9010) acc: 0.66\n",
      "4788 loss: tensor(0.9009) acc: 0.66\n",
      "4789 loss: tensor(0.9009) acc: 0.66\n",
      "4790 loss: tensor(0.9008) acc: 0.66\n",
      "4791 loss: tensor(0.9008) acc: 0.66\n",
      "4792 loss: tensor(0.9008) acc: 0.66\n",
      "4793 loss: tensor(0.9007) acc: 0.66\n",
      "4794 loss: tensor(0.9007) acc: 0.66\n",
      "4795 loss: tensor(0.9006) acc: 0.66\n",
      "4796 loss: tensor(0.9006) acc: 0.66\n",
      "4797 loss: tensor(0.9006) acc: 0.66\n",
      "4798 loss: tensor(0.9005) acc: 0.66\n",
      "4799 loss: tensor(0.9005) acc: 0.66\n",
      "4800 loss: tensor(0.9004) acc: 0.66\n",
      "4801 loss: tensor(0.9004) acc: 0.66\n",
      "4802 loss: tensor(0.9004) acc: 0.66\n",
      "4803 loss: tensor(0.9003) acc: 0.66\n",
      "4804 loss: tensor(0.9003) acc: 0.66\n",
      "4805 loss: tensor(0.9002) acc: 0.66\n",
      "4806 loss: tensor(0.9002) acc: 0.66\n",
      "4807 loss: tensor(0.9001) acc: 0.66\n",
      "4808 loss: tensor(0.9001) acc: 0.66\n",
      "4809 loss: tensor(0.9001) acc: 0.66\n",
      "4810 loss: tensor(0.9000) acc: 0.66\n",
      "4811 loss: tensor(0.9000) acc: 0.66\n",
      "4812 loss: tensor(0.8999) acc: 0.66\n",
      "4813 loss: tensor(0.8999) acc: 0.66\n",
      "4814 loss: tensor(0.8999) acc: 0.66\n",
      "4815 loss: tensor(0.8998) acc: 0.66\n",
      "4816 loss: tensor(0.8998) acc: 0.66\n",
      "4817 loss: tensor(0.8997) acc: 0.66\n",
      "4818 loss: tensor(0.8997) acc: 0.66\n",
      "4819 loss: tensor(0.8997) acc: 0.66\n",
      "4820 loss: tensor(0.8996) acc: 0.66\n",
      "4821 loss: tensor(0.8996) acc: 0.66\n",
      "4822 loss: tensor(0.8995) acc: 0.66\n",
      "4823 loss: tensor(0.8995) acc: 0.66\n",
      "4824 loss: tensor(0.8995) acc: 0.66\n",
      "4825 loss: tensor(0.8994) acc: 0.66\n",
      "4826 loss: tensor(0.8994) acc: 0.66\n",
      "4827 loss: tensor(0.8993) acc: 0.66\n",
      "4828 loss: tensor(0.8993) acc: 0.66\n",
      "4829 loss: tensor(0.8993) acc: 0.66\n",
      "4830 loss: tensor(0.8992) acc: 0.66\n",
      "4831 loss: tensor(0.8992) acc: 0.66\n",
      "4832 loss: tensor(0.8991) acc: 0.66\n",
      "4833 loss: tensor(0.8991) acc: 0.66\n",
      "4834 loss: tensor(0.8991) acc: 0.66\n",
      "4835 loss: tensor(0.8990) acc: 0.66\n",
      "4836 loss: tensor(0.8990) acc: 0.66\n",
      "4837 loss: tensor(0.8989) acc: 0.66\n",
      "4838 loss: tensor(0.8989) acc: 0.66\n",
      "4839 loss: tensor(0.8989) acc: 0.66\n",
      "4840 loss: tensor(0.8988) acc: 0.66\n",
      "4841 loss: tensor(0.8988) acc: 0.66\n",
      "4842 loss: tensor(0.8987) acc: 0.66\n",
      "4843 loss: tensor(0.8987) acc: 0.66\n",
      "4844 loss: tensor(0.8987) acc: 0.66\n",
      "4845 loss: tensor(0.8986) acc: 0.66\n",
      "4846 loss: tensor(0.8986) acc: 0.66\n",
      "4847 loss: tensor(0.8985) acc: 0.66\n",
      "4848 loss: tensor(0.8985) acc: 0.66\n",
      "4849 loss: tensor(0.8985) acc: 0.66\n",
      "4850 loss: tensor(0.8984) acc: 0.66\n",
      "4851 loss: tensor(0.8984) acc: 0.66\n",
      "4852 loss: tensor(0.8983) acc: 0.66\n",
      "4853 loss: tensor(0.8983) acc: 0.66\n",
      "4854 loss: tensor(0.8983) acc: 0.66\n",
      "4855 loss: tensor(0.8982) acc: 0.66\n",
      "4856 loss: tensor(0.8982) acc: 0.66\n",
      "4857 loss: tensor(0.8981) acc: 0.66\n",
      "4858 loss: tensor(0.8981) acc: 0.66\n",
      "4859 loss: tensor(0.8981) acc: 0.66\n",
      "4860 loss: tensor(0.8980) acc: 0.66\n",
      "4861 loss: tensor(0.8980) acc: 0.66\n",
      "4862 loss: tensor(0.8979) acc: 0.66\n",
      "4863 loss: tensor(0.8979) acc: 0.66\n",
      "4864 loss: tensor(0.8979) acc: 0.66\n",
      "4865 loss: tensor(0.8978) acc: 0.66\n",
      "4866 loss: tensor(0.8978) acc: 0.66\n",
      "4867 loss: tensor(0.8977) acc: 0.66\n",
      "4868 loss: tensor(0.8977) acc: 0.66\n",
      "4869 loss: tensor(0.8977) acc: 0.66\n",
      "4870 loss: tensor(0.8976) acc: 0.66\n",
      "4871 loss: tensor(0.8976) acc: 0.66\n",
      "4872 loss: tensor(0.8975) acc: 0.66\n",
      "4873 loss: tensor(0.8975) acc: 0.66\n",
      "4874 loss: tensor(0.8975) acc: 0.66\n",
      "4875 loss: tensor(0.8974) acc: 0.66\n",
      "4876 loss: tensor(0.8974) acc: 0.66\n",
      "4877 loss: tensor(0.8973) acc: 0.66\n",
      "4878 loss: tensor(0.8973) acc: 0.66\n",
      "4879 loss: tensor(0.8973) acc: 0.66\n",
      "4880 loss: tensor(0.8972) acc: 0.66\n",
      "4881 loss: tensor(0.8972) acc: 0.66\n",
      "4882 loss: tensor(0.8972) acc: 0.66\n",
      "4883 loss: tensor(0.8971) acc: 0.66\n",
      "4884 loss: tensor(0.8971) acc: 0.66\n",
      "4885 loss: tensor(0.8970) acc: 0.66\n",
      "4886 loss: tensor(0.8970) acc: 0.66\n",
      "4887 loss: tensor(0.8970) acc: 0.66\n",
      "4888 loss: tensor(0.8969) acc: 0.66\n",
      "4889 loss: tensor(0.8969) acc: 0.66\n",
      "4890 loss: tensor(0.8968) acc: 0.66\n",
      "4891 loss: tensor(0.8968) acc: 0.66\n",
      "4892 loss: tensor(0.8968) acc: 0.66\n",
      "4893 loss: tensor(0.8967) acc: 0.66\n",
      "4894 loss: tensor(0.8967) acc: 0.66\n",
      "4895 loss: tensor(0.8966) acc: 0.66\n",
      "4896 loss: tensor(0.8966) acc: 0.66\n",
      "4897 loss: tensor(0.8966) acc: 0.66\n",
      "4898 loss: tensor(0.8965) acc: 0.66\n",
      "4899 loss: tensor(0.8965) acc: 0.66\n",
      "4900 loss: tensor(0.8965) acc: 0.66\n",
      "4901 loss: tensor(0.8964) acc: 0.66\n",
      "4902 loss: tensor(0.8964) acc: 0.66\n",
      "4903 loss: tensor(0.8963) acc: 0.66\n",
      "4904 loss: tensor(0.8963) acc: 0.66\n",
      "4905 loss: tensor(0.8963) acc: 0.66\n",
      "4906 loss: tensor(0.8962) acc: 0.66\n",
      "4907 loss: tensor(0.8962) acc: 0.66\n",
      "4908 loss: tensor(0.8961) acc: 0.66\n",
      "4909 loss: tensor(0.8961) acc: 0.66\n",
      "4910 loss: tensor(0.8961) acc: 0.66\n",
      "4911 loss: tensor(0.8960) acc: 0.66\n",
      "4912 loss: tensor(0.8960) acc: 0.66\n",
      "4913 loss: tensor(0.8960) acc: 0.66\n",
      "4914 loss: tensor(0.8959) acc: 0.66\n",
      "4915 loss: tensor(0.8959) acc: 0.66\n",
      "4916 loss: tensor(0.8958) acc: 0.66\n",
      "4917 loss: tensor(0.8958) acc: 0.66\n",
      "4918 loss: tensor(0.8958) acc: 0.66\n",
      "4919 loss: tensor(0.8957) acc: 0.66\n",
      "4920 loss: tensor(0.8957) acc: 0.66\n",
      "4921 loss: tensor(0.8957) acc: 0.66\n",
      "4922 loss: tensor(0.8956) acc: 0.66\n",
      "4923 loss: tensor(0.8956) acc: 0.66\n",
      "4924 loss: tensor(0.8955) acc: 0.66\n",
      "4925 loss: tensor(0.8955) acc: 0.66\n",
      "4926 loss: tensor(0.8955) acc: 0.66\n",
      "4927 loss: tensor(0.8954) acc: 0.66\n",
      "4928 loss: tensor(0.8954) acc: 0.66\n",
      "4929 loss: tensor(0.8953) acc: 0.66\n",
      "4930 loss: tensor(0.8953) acc: 0.66\n",
      "4931 loss: tensor(0.8953) acc: 0.66\n",
      "4932 loss: tensor(0.8952) acc: 0.66\n",
      "4933 loss: tensor(0.8952) acc: 0.66\n",
      "4934 loss: tensor(0.8952) acc: 0.66\n",
      "4935 loss: tensor(0.8951) acc: 0.66\n",
      "4936 loss: tensor(0.8951) acc: 0.66\n",
      "4937 loss: tensor(0.8950) acc: 0.66\n",
      "4938 loss: tensor(0.8950) acc: 0.66\n",
      "4939 loss: tensor(0.8950) acc: 0.66\n",
      "4940 loss: tensor(0.8949) acc: 0.66\n",
      "4941 loss: tensor(0.8949) acc: 0.66\n",
      "4942 loss: tensor(0.8949) acc: 0.66\n",
      "4943 loss: tensor(0.8948) acc: 0.66\n",
      "4944 loss: tensor(0.8948) acc: 0.66\n",
      "4945 loss: tensor(0.8947) acc: 0.66\n",
      "4946 loss: tensor(0.8947) acc: 0.66\n",
      "4947 loss: tensor(0.8947) acc: 0.66\n",
      "4948 loss: tensor(0.8946) acc: 0.66\n",
      "4949 loss: tensor(0.8946) acc: 0.66\n",
      "4950 loss: tensor(0.8946) acc: 0.66\n",
      "4951 loss: tensor(0.8945) acc: 0.66\n",
      "4952 loss: tensor(0.8945) acc: 0.66\n",
      "4953 loss: tensor(0.8944) acc: 0.66\n",
      "4954 loss: tensor(0.8944) acc: 0.66\n",
      "4955 loss: tensor(0.8944) acc: 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956 loss: tensor(0.8943) acc: 0.66\n",
      "4957 loss: tensor(0.8943) acc: 0.66\n",
      "4958 loss: tensor(0.8943) acc: 0.66\n",
      "4959 loss: tensor(0.8942) acc: 0.66\n",
      "4960 loss: tensor(0.8942) acc: 0.66\n",
      "4961 loss: tensor(0.8942) acc: 0.66\n",
      "4962 loss: tensor(0.8941) acc: 0.66\n",
      "4963 loss: tensor(0.8941) acc: 0.66\n",
      "4964 loss: tensor(0.8940) acc: 0.66\n",
      "4965 loss: tensor(0.8940) acc: 0.66\n",
      "4966 loss: tensor(0.8940) acc: 0.66\n",
      "4967 loss: tensor(0.8939) acc: 0.66\n",
      "4968 loss: tensor(0.8939) acc: 0.66\n",
      "4969 loss: tensor(0.8939) acc: 0.66\n",
      "4970 loss: tensor(0.8938) acc: 0.66\n",
      "4971 loss: tensor(0.8938) acc: 0.66\n",
      "4972 loss: tensor(0.8937) acc: 0.66\n",
      "4973 loss: tensor(0.8937) acc: 0.66\n",
      "4974 loss: tensor(0.8937) acc: 0.66\n",
      "4975 loss: tensor(0.8936) acc: 0.66\n",
      "4976 loss: tensor(0.8936) acc: 0.66\n",
      "4977 loss: tensor(0.8936) acc: 0.66\n",
      "4978 loss: tensor(0.8935) acc: 0.66\n",
      "4979 loss: tensor(0.8935) acc: 0.66\n",
      "4980 loss: tensor(0.8935) acc: 0.66\n",
      "4981 loss: tensor(0.8934) acc: 0.66\n",
      "4982 loss: tensor(0.8934) acc: 0.66\n",
      "4983 loss: tensor(0.8933) acc: 0.66\n",
      "4984 loss: tensor(0.8933) acc: 0.66\n",
      "4985 loss: tensor(0.8933) acc: 0.66\n",
      "4986 loss: tensor(0.8932) acc: 0.66\n",
      "4987 loss: tensor(0.8932) acc: 0.66\n",
      "4988 loss: tensor(0.8932) acc: 0.66\n",
      "4989 loss: tensor(0.8931) acc: 0.66\n",
      "4990 loss: tensor(0.8931) acc: 0.66\n",
      "4991 loss: tensor(0.8931) acc: 0.66\n",
      "4992 loss: tensor(0.8930) acc: 0.66\n",
      "4993 loss: tensor(0.8930) acc: 0.66\n",
      "4994 loss: tensor(0.8929) acc: 0.66\n",
      "4995 loss: tensor(0.8929) acc: 0.66\n",
      "4996 loss: tensor(0.8929) acc: 0.66\n",
      "4997 loss: tensor(0.8928) acc: 0.66\n",
      "4998 loss: tensor(0.8928) acc: 0.66\n",
      "4999 loss: tensor(0.8928) acc: 0.66\n",
      "5000 loss: tensor(0.8927) acc: 0.66\n",
      "5001 loss: tensor(0.8927) acc: 0.66\n",
      "5002 loss: tensor(0.8927) acc: 0.66\n",
      "5003 loss: tensor(0.8926) acc: 0.66\n",
      "5004 loss: tensor(0.8926) acc: 0.66\n",
      "5005 loss: tensor(0.8925) acc: 0.66\n",
      "5006 loss: tensor(0.8925) acc: 0.66\n",
      "5007 loss: tensor(0.8925) acc: 0.66\n",
      "5008 loss: tensor(0.8924) acc: 0.66\n",
      "5009 loss: tensor(0.8924) acc: 0.66\n",
      "5010 loss: tensor(0.8924) acc: 0.66\n",
      "5011 loss: tensor(0.8923) acc: 0.66\n",
      "5012 loss: tensor(0.8923) acc: 0.66\n",
      "5013 loss: tensor(0.8923) acc: 0.66\n",
      "5014 loss: tensor(0.8922) acc: 0.66\n",
      "5015 loss: tensor(0.8922) acc: 0.66\n",
      "5016 loss: tensor(0.8922) acc: 0.66\n",
      "5017 loss: tensor(0.8921) acc: 0.66\n",
      "5018 loss: tensor(0.8921) acc: 0.66\n",
      "5019 loss: tensor(0.8920) acc: 0.66\n",
      "5020 loss: tensor(0.8920) acc: 0.66\n",
      "5021 loss: tensor(0.8920) acc: 0.66\n",
      "5022 loss: tensor(0.8919) acc: 0.66\n",
      "5023 loss: tensor(0.8919) acc: 0.66\n",
      "5024 loss: tensor(0.8919) acc: 0.66\n",
      "5025 loss: tensor(0.8918) acc: 0.66\n",
      "5026 loss: tensor(0.8918) acc: 0.66\n",
      "5027 loss: tensor(0.8918) acc: 0.66\n",
      "5028 loss: tensor(0.8917) acc: 0.66\n",
      "5029 loss: tensor(0.8917) acc: 0.66\n",
      "5030 loss: tensor(0.8917) acc: 0.66\n",
      "5031 loss: tensor(0.8916) acc: 0.66\n",
      "5032 loss: tensor(0.8916) acc: 0.66\n",
      "5033 loss: tensor(0.8916) acc: 0.66\n",
      "5034 loss: tensor(0.8915) acc: 0.66\n",
      "5035 loss: tensor(0.8915) acc: 0.66\n",
      "5036 loss: tensor(0.8914) acc: 0.66\n",
      "5037 loss: tensor(0.8914) acc: 0.66\n",
      "5038 loss: tensor(0.8914) acc: 0.66\n",
      "5039 loss: tensor(0.8913) acc: 0.66\n",
      "5040 loss: tensor(0.8913) acc: 0.66\n",
      "5041 loss: tensor(0.8913) acc: 0.66\n",
      "5042 loss: tensor(0.8912) acc: 0.66\n",
      "5043 loss: tensor(0.8912) acc: 0.66\n",
      "5044 loss: tensor(0.8912) acc: 0.66\n",
      "5045 loss: tensor(0.8911) acc: 0.66\n",
      "5046 loss: tensor(0.8911) acc: 0.66\n",
      "5047 loss: tensor(0.8911) acc: 0.66\n",
      "5048 loss: tensor(0.8910) acc: 0.66\n",
      "5049 loss: tensor(0.8910) acc: 0.66\n",
      "5050 loss: tensor(0.8910) acc: 0.66\n",
      "5051 loss: tensor(0.8909) acc: 0.66\n",
      "5052 loss: tensor(0.8909) acc: 0.66\n",
      "5053 loss: tensor(0.8909) acc: 0.66\n",
      "5054 loss: tensor(0.8908) acc: 0.66\n",
      "5055 loss: tensor(0.8908) acc: 0.66\n",
      "5056 loss: tensor(0.8907) acc: 0.66\n",
      "5057 loss: tensor(0.8907) acc: 0.66\n",
      "5058 loss: tensor(0.8907) acc: 0.66\n",
      "5059 loss: tensor(0.8906) acc: 0.66\n",
      "5060 loss: tensor(0.8906) acc: 0.66\n",
      "5061 loss: tensor(0.8906) acc: 0.66\n",
      "5062 loss: tensor(0.8905) acc: 0.66\n",
      "5063 loss: tensor(0.8905) acc: 0.66\n",
      "5064 loss: tensor(0.8905) acc: 0.66\n",
      "5065 loss: tensor(0.8904) acc: 0.66\n",
      "5066 loss: tensor(0.8904) acc: 0.66\n",
      "5067 loss: tensor(0.8904) acc: 0.66\n",
      "5068 loss: tensor(0.8903) acc: 0.66\n",
      "5069 loss: tensor(0.8903) acc: 0.66\n",
      "5070 loss: tensor(0.8903) acc: 0.66\n",
      "5071 loss: tensor(0.8902) acc: 0.66\n",
      "5072 loss: tensor(0.8902) acc: 0.66\n",
      "5073 loss: tensor(0.8902) acc: 0.66\n",
      "5074 loss: tensor(0.8901) acc: 0.66\n",
      "5075 loss: tensor(0.8901) acc: 0.66\n",
      "5076 loss: tensor(0.8901) acc: 0.66\n",
      "5077 loss: tensor(0.8900) acc: 0.66\n",
      "5078 loss: tensor(0.8900) acc: 0.66\n",
      "5079 loss: tensor(0.8900) acc: 0.66\n",
      "5080 loss: tensor(0.8899) acc: 0.66\n",
      "5081 loss: tensor(0.8899) acc: 0.66\n",
      "5082 loss: tensor(0.8899) acc: 0.66\n",
      "5083 loss: tensor(0.8898) acc: 0.66\n",
      "5084 loss: tensor(0.8898) acc: 0.66\n",
      "5085 loss: tensor(0.8898) acc: 0.66\n",
      "5086 loss: tensor(0.8897) acc: 0.66\n",
      "5087 loss: tensor(0.8897) acc: 0.66\n",
      "5088 loss: tensor(0.8897) acc: 0.66\n",
      "5089 loss: tensor(0.8896) acc: 0.66\n",
      "5090 loss: tensor(0.8896) acc: 0.66\n",
      "5091 loss: tensor(0.8896) acc: 0.66\n",
      "5092 loss: tensor(0.8895) acc: 0.66\n",
      "5093 loss: tensor(0.8895) acc: 0.66\n",
      "5094 loss: tensor(0.8895) acc: 0.66\n",
      "5095 loss: tensor(0.8894) acc: 0.66\n",
      "5096 loss: tensor(0.8894) acc: 0.66\n",
      "5097 loss: tensor(0.8894) acc: 0.66\n",
      "5098 loss: tensor(0.8893) acc: 0.66\n",
      "5099 loss: tensor(0.8893) acc: 0.66\n",
      "5100 loss: tensor(0.8893) acc: 0.66\n",
      "5101 loss: tensor(0.8892) acc: 0.66\n",
      "5102 loss: tensor(0.8892) acc: 0.66\n",
      "5103 loss: tensor(0.8892) acc: 0.66\n",
      "5104 loss: tensor(0.8891) acc: 0.66\n",
      "5105 loss: tensor(0.8891) acc: 0.66\n",
      "5106 loss: tensor(0.8891) acc: 0.66\n",
      "5107 loss: tensor(0.8890) acc: 0.66\n",
      "5108 loss: tensor(0.8890) acc: 0.66\n",
      "5109 loss: tensor(0.8890) acc: 0.66\n",
      "5110 loss: tensor(0.8889) acc: 0.66\n",
      "5111 loss: tensor(0.8889) acc: 0.66\n",
      "5112 loss: tensor(0.8889) acc: 0.66\n",
      "5113 loss: tensor(0.8888) acc: 0.66\n",
      "5114 loss: tensor(0.8888) acc: 0.66\n",
      "5115 loss: tensor(0.8888) acc: 0.66\n",
      "5116 loss: tensor(0.8887) acc: 0.66\n",
      "5117 loss: tensor(0.8887) acc: 0.66\n",
      "5118 loss: tensor(0.8887) acc: 0.66\n",
      "5119 loss: tensor(0.8886) acc: 0.66\n",
      "5120 loss: tensor(0.8886) acc: 0.66\n",
      "5121 loss: tensor(0.8886) acc: 0.66\n",
      "5122 loss: tensor(0.8885) acc: 0.66\n",
      "5123 loss: tensor(0.8885) acc: 0.66\n",
      "5124 loss: tensor(0.8885) acc: 0.66\n",
      "5125 loss: tensor(0.8884) acc: 0.66\n",
      "5126 loss: tensor(0.8884) acc: 0.66\n",
      "5127 loss: tensor(0.8884) acc: 0.66\n",
      "5128 loss: tensor(0.8883) acc: 0.66\n",
      "5129 loss: tensor(0.8883) acc: 0.66\n",
      "5130 loss: tensor(0.8883) acc: 0.66\n",
      "5131 loss: tensor(0.8882) acc: 0.66\n",
      "5132 loss: tensor(0.8882) acc: 0.66\n",
      "5133 loss: tensor(0.8882) acc: 0.66\n",
      "5134 loss: tensor(0.8881) acc: 0.66\n",
      "5135 loss: tensor(0.8881) acc: 0.66\n",
      "5136 loss: tensor(0.8881) acc: 0.66\n",
      "5137 loss: tensor(0.8880) acc: 0.66\n",
      "5138 loss: tensor(0.8880) acc: 0.66\n",
      "5139 loss: tensor(0.8880) acc: 0.66\n",
      "5140 loss: tensor(0.8879) acc: 0.66\n",
      "5141 loss: tensor(0.8879) acc: 0.66\n",
      "5142 loss: tensor(0.8879) acc: 0.66\n",
      "5143 loss: tensor(0.8878) acc: 0.66\n",
      "5144 loss: tensor(0.8878) acc: 0.66\n",
      "5145 loss: tensor(0.8878) acc: 0.66\n",
      "5146 loss: tensor(0.8877) acc: 0.66\n",
      "5147 loss: tensor(0.8877) acc: 0.66\n",
      "5148 loss: tensor(0.8877) acc: 0.66\n",
      "5149 loss: tensor(0.8876) acc: 0.66\n",
      "5150 loss: tensor(0.8876) acc: 0.66\n",
      "5151 loss: tensor(0.8876) acc: 0.66\n",
      "5152 loss: tensor(0.8875) acc: 0.66\n",
      "5153 loss: tensor(0.8875) acc: 0.66\n",
      "5154 loss: tensor(0.8875) acc: 0.66\n",
      "5155 loss: tensor(0.8874) acc: 0.66\n",
      "5156 loss: tensor(0.8874) acc: 0.66\n",
      "5157 loss: tensor(0.8874) acc: 0.66\n",
      "5158 loss: tensor(0.8874) acc: 0.66\n",
      "5159 loss: tensor(0.8873) acc: 0.66\n",
      "5160 loss: tensor(0.8873) acc: 0.66\n",
      "5161 loss: tensor(0.8873) acc: 0.66\n",
      "5162 loss: tensor(0.8872) acc: 0.66\n",
      "5163 loss: tensor(0.8872) acc: 0.66\n",
      "5164 loss: tensor(0.8872) acc: 0.66\n",
      "5165 loss: tensor(0.8871) acc: 0.66\n",
      "5166 loss: tensor(0.8871) acc: 0.66\n",
      "5167 loss: tensor(0.8871) acc: 0.66\n",
      "5168 loss: tensor(0.8870) acc: 0.66\n",
      "5169 loss: tensor(0.8870) acc: 0.66\n",
      "5170 loss: tensor(0.8870) acc: 0.66\n",
      "5171 loss: tensor(0.8869) acc: 0.66\n",
      "5172 loss: tensor(0.8869) acc: 0.66\n",
      "5173 loss: tensor(0.8869) acc: 0.66\n",
      "5174 loss: tensor(0.8868) acc: 0.66\n",
      "5175 loss: tensor(0.8868) acc: 0.66\n",
      "5176 loss: tensor(0.8868) acc: 0.66\n",
      "5177 loss: tensor(0.8867) acc: 0.66\n",
      "5178 loss: tensor(0.8867) acc: 0.66\n",
      "5179 loss: tensor(0.8867) acc: 0.66\n",
      "5180 loss: tensor(0.8867) acc: 0.66\n",
      "5181 loss: tensor(0.8866) acc: 0.66\n",
      "5182 loss: tensor(0.8866) acc: 0.66\n",
      "5183 loss: tensor(0.8866) acc: 0.66\n",
      "5184 loss: tensor(0.8865) acc: 0.66\n",
      "5185 loss: tensor(0.8865) acc: 0.66\n",
      "5186 loss: tensor(0.8865) acc: 0.66\n",
      "5187 loss: tensor(0.8864) acc: 0.66\n",
      "5188 loss: tensor(0.8864) acc: 0.66\n",
      "5189 loss: tensor(0.8864) acc: 0.66\n",
      "5190 loss: tensor(0.8863) acc: 0.66\n",
      "5191 loss: tensor(0.8863) acc: 0.66\n",
      "5192 loss: tensor(0.8863) acc: 0.66\n",
      "5193 loss: tensor(0.8862) acc: 0.66\n",
      "5194 loss: tensor(0.8862) acc: 0.66\n",
      "5195 loss: tensor(0.8862) acc: 0.66\n",
      "5196 loss: tensor(0.8862) acc: 0.66\n",
      "5197 loss: tensor(0.8861) acc: 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5198 loss: tensor(0.8861) acc: 0.66\n",
      "5199 loss: tensor(0.8861) acc: 0.66\n",
      "5200 loss: tensor(0.8860) acc: 0.66\n",
      "5201 loss: tensor(0.8860) acc: 0.66\n",
      "5202 loss: tensor(0.8860) acc: 0.66\n",
      "5203 loss: tensor(0.8859) acc: 0.66\n",
      "5204 loss: tensor(0.8859) acc: 0.66\n",
      "5205 loss: tensor(0.8859) acc: 0.66\n",
      "5206 loss: tensor(0.8858) acc: 0.66\n",
      "5207 loss: tensor(0.8858) acc: 0.66\n",
      "5208 loss: tensor(0.8858) acc: 0.66\n",
      "5209 loss: tensor(0.8857) acc: 0.66\n",
      "5210 loss: tensor(0.8857) acc: 0.66\n",
      "5211 loss: tensor(0.8857) acc: 0.66\n",
      "5212 loss: tensor(0.8857) acc: 0.66\n",
      "5213 loss: tensor(0.8856) acc: 0.66\n",
      "5214 loss: tensor(0.8856) acc: 0.66\n",
      "5215 loss: tensor(0.8856) acc: 0.66\n",
      "5216 loss: tensor(0.8855) acc: 0.66\n",
      "5217 loss: tensor(0.8855) acc: 0.66\n",
      "5218 loss: tensor(0.8855) acc: 0.66\n",
      "5219 loss: tensor(0.8854) acc: 0.66\n",
      "5220 loss: tensor(0.8854) acc: 0.66\n",
      "5221 loss: tensor(0.8854) acc: 0.66\n",
      "5222 loss: tensor(0.8853) acc: 0.66\n",
      "5223 loss: tensor(0.8853) acc: 0.66\n",
      "5224 loss: tensor(0.8853) acc: 0.66\n",
      "5225 loss: tensor(0.8853) acc: 0.66\n",
      "5226 loss: tensor(0.8852) acc: 0.66\n",
      "5227 loss: tensor(0.8852) acc: 0.66\n",
      "5228 loss: tensor(0.8852) acc: 0.66\n",
      "5229 loss: tensor(0.8851) acc: 0.66\n",
      "5230 loss: tensor(0.8851) acc: 0.66\n",
      "5231 loss: tensor(0.8851) acc: 0.66\n",
      "5232 loss: tensor(0.8850) acc: 0.66\n",
      "5233 loss: tensor(0.8850) acc: 0.66\n",
      "5234 loss: tensor(0.8850) acc: 0.66\n",
      "5235 loss: tensor(0.8850) acc: 0.66\n",
      "5236 loss: tensor(0.8849) acc: 0.66\n",
      "5237 loss: tensor(0.8849) acc: 0.66\n",
      "5238 loss: tensor(0.8849) acc: 0.66\n",
      "5239 loss: tensor(0.8848) acc: 0.66\n",
      "5240 loss: tensor(0.8848) acc: 0.66\n",
      "5241 loss: tensor(0.8848) acc: 0.66\n",
      "5242 loss: tensor(0.8847) acc: 0.66\n",
      "5243 loss: tensor(0.8847) acc: 0.66\n",
      "5244 loss: tensor(0.8847) acc: 0.66\n",
      "5245 loss: tensor(0.8847) acc: 0.66\n",
      "5246 loss: tensor(0.8846) acc: 0.66\n",
      "5247 loss: tensor(0.8846) acc: 0.66\n",
      "5248 loss: tensor(0.8846) acc: 0.66\n",
      "5249 loss: tensor(0.8845) acc: 0.66\n",
      "5250 loss: tensor(0.8845) acc: 0.66\n",
      "5251 loss: tensor(0.8845) acc: 0.66\n",
      "5252 loss: tensor(0.8844) acc: 0.66\n",
      "5253 loss: tensor(0.8844) acc: 0.66\n",
      "5254 loss: tensor(0.8844) acc: 0.66\n",
      "5255 loss: tensor(0.8844) acc: 0.66\n",
      "5256 loss: tensor(0.8843) acc: 0.66\n",
      "5257 loss: tensor(0.8843) acc: 0.66\n",
      "5258 loss: tensor(0.8843) acc: 0.66\n",
      "5259 loss: tensor(0.8842) acc: 0.66\n",
      "5260 loss: tensor(0.8842) acc: 0.66\n",
      "5261 loss: tensor(0.8842) acc: 0.66\n",
      "5262 loss: tensor(0.8842) acc: 0.66\n",
      "5263 loss: tensor(0.8841) acc: 0.66\n",
      "5264 loss: tensor(0.8841) acc: 0.66\n",
      "5265 loss: tensor(0.8841) acc: 0.66\n",
      "5266 loss: tensor(0.8840) acc: 0.66\n",
      "5267 loss: tensor(0.8840) acc: 0.66\n",
      "5268 loss: tensor(0.8840) acc: 0.66\n",
      "5269 loss: tensor(0.8839) acc: 0.66\n",
      "5270 loss: tensor(0.8839) acc: 0.66\n",
      "5271 loss: tensor(0.8839) acc: 0.66\n",
      "5272 loss: tensor(0.8839) acc: 0.66\n",
      "5273 loss: tensor(0.8838) acc: 0.66\n",
      "5274 loss: tensor(0.8838) acc: 0.66\n",
      "5275 loss: tensor(0.8838) acc: 0.66\n",
      "5276 loss: tensor(0.8837) acc: 0.66\n",
      "5277 loss: tensor(0.8837) acc: 0.66\n",
      "5278 loss: tensor(0.8837) acc: 0.66\n",
      "5279 loss: tensor(0.8837) acc: 0.66\n",
      "5280 loss: tensor(0.8836) acc: 0.66\n",
      "5281 loss: tensor(0.8836) acc: 0.66\n",
      "5282 loss: tensor(0.8836) acc: 0.66\n",
      "5283 loss: tensor(0.8835) acc: 0.66\n",
      "5284 loss: tensor(0.8835) acc: 0.66\n",
      "5285 loss: tensor(0.8835) acc: 0.66\n",
      "5286 loss: tensor(0.8835) acc: 0.66\n",
      "5287 loss: tensor(0.8834) acc: 0.66\n",
      "5288 loss: tensor(0.8834) acc: 0.66\n",
      "5289 loss: tensor(0.8834) acc: 0.66\n",
      "5290 loss: tensor(0.8833) acc: 0.66\n",
      "5291 loss: tensor(0.8833) acc: 0.66\n",
      "5292 loss: tensor(0.8833) acc: 0.66\n",
      "5293 loss: tensor(0.8833) acc: 0.66\n",
      "5294 loss: tensor(0.8832) acc: 0.66\n",
      "5295 loss: tensor(0.8832) acc: 0.66\n",
      "5296 loss: tensor(0.8832) acc: 0.66\n",
      "5297 loss: tensor(0.8831) acc: 0.66\n",
      "5298 loss: tensor(0.8831) acc: 0.66\n",
      "5299 loss: tensor(0.8831) acc: 0.66\n",
      "5300 loss: tensor(0.8830) acc: 0.66\n",
      "5301 loss: tensor(0.8830) acc: 0.66\n",
      "5302 loss: tensor(0.8830) acc: 0.66\n",
      "5303 loss: tensor(0.8830) acc: 0.66\n",
      "5304 loss: tensor(0.8829) acc: 0.66\n",
      "5305 loss: tensor(0.8829) acc: 0.66\n",
      "5306 loss: tensor(0.8829) acc: 0.66\n",
      "5307 loss: tensor(0.8829) acc: 0.66\n",
      "5308 loss: tensor(0.8828) acc: 0.66\n",
      "5309 loss: tensor(0.8828) acc: 0.66\n",
      "5310 loss: tensor(0.8828) acc: 0.66\n",
      "5311 loss: tensor(0.8827) acc: 0.66\n",
      "5312 loss: tensor(0.8827) acc: 0.66\n",
      "5313 loss: tensor(0.8827) acc: 0.66\n",
      "5314 loss: tensor(0.8827) acc: 0.66\n",
      "5315 loss: tensor(0.8826) acc: 0.66\n",
      "5316 loss: tensor(0.8826) acc: 0.66\n",
      "5317 loss: tensor(0.8826) acc: 0.66\n",
      "5318 loss: tensor(0.8825) acc: 0.66\n",
      "5319 loss: tensor(0.8825) acc: 0.66\n",
      "5320 loss: tensor(0.8825) acc: 0.66\n",
      "5321 loss: tensor(0.8825) acc: 0.66\n",
      "5322 loss: tensor(0.8824) acc: 0.66\n",
      "5323 loss: tensor(0.8824) acc: 0.66\n",
      "5324 loss: tensor(0.8824) acc: 0.66\n",
      "5325 loss: tensor(0.8823) acc: 0.66\n",
      "5326 loss: tensor(0.8823) acc: 0.66\n",
      "5327 loss: tensor(0.8823) acc: 0.66\n",
      "5328 loss: tensor(0.8823) acc: 0.66\n",
      "5329 loss: tensor(0.8822) acc: 0.66\n",
      "5330 loss: tensor(0.8822) acc: 0.66\n",
      "5331 loss: tensor(0.8822) acc: 0.66\n",
      "5332 loss: tensor(0.8821) acc: 0.66\n",
      "5333 loss: tensor(0.8821) acc: 0.66\n",
      "5334 loss: tensor(0.8821) acc: 0.66\n",
      "5335 loss: tensor(0.8821) acc: 0.66\n",
      "5336 loss: tensor(0.8820) acc: 0.66\n",
      "5337 loss: tensor(0.8820) acc: 0.66\n",
      "5338 loss: tensor(0.8820) acc: 0.66\n",
      "5339 loss: tensor(0.8820) acc: 0.66\n",
      "5340 loss: tensor(0.8819) acc: 0.66\n",
      "5341 loss: tensor(0.8819) acc: 0.66\n",
      "5342 loss: tensor(0.8819) acc: 0.66\n",
      "5343 loss: tensor(0.8818) acc: 0.66\n",
      "5344 loss: tensor(0.8818) acc: 0.66\n",
      "5345 loss: tensor(0.8818) acc: 0.66\n",
      "5346 loss: tensor(0.8818) acc: 0.66\n",
      "5347 loss: tensor(0.8817) acc: 0.66\n",
      "5348 loss: tensor(0.8817) acc: 0.66\n",
      "5349 loss: tensor(0.8817) acc: 0.66\n",
      "5350 loss: tensor(0.8817) acc: 0.66\n",
      "5351 loss: tensor(0.8816) acc: 0.66\n",
      "5352 loss: tensor(0.8816) acc: 0.66\n",
      "5353 loss: tensor(0.8816) acc: 0.66\n",
      "5354 loss: tensor(0.8815) acc: 0.66\n",
      "5355 loss: tensor(0.8815) acc: 0.66\n",
      "5356 loss: tensor(0.8815) acc: 0.66\n",
      "5357 loss: tensor(0.8815) acc: 0.66\n",
      "5358 loss: tensor(0.8814) acc: 0.66\n",
      "5359 loss: tensor(0.8814) acc: 0.66\n",
      "5360 loss: tensor(0.8814) acc: 0.66\n",
      "5361 loss: tensor(0.8814) acc: 0.66\n",
      "5362 loss: tensor(0.8813) acc: 0.66\n",
      "5363 loss: tensor(0.8813) acc: 0.66\n",
      "5364 loss: tensor(0.8813) acc: 0.66\n",
      "5365 loss: tensor(0.8812) acc: 0.66\n",
      "5366 loss: tensor(0.8812) acc: 0.66\n",
      "5367 loss: tensor(0.8812) acc: 0.66\n",
      "5368 loss: tensor(0.8812) acc: 0.66\n",
      "5369 loss: tensor(0.8811) acc: 0.66\n",
      "5370 loss: tensor(0.8811) acc: 0.66\n",
      "5371 loss: tensor(0.8811) acc: 0.66\n",
      "5372 loss: tensor(0.8811) acc: 0.66\n",
      "5373 loss: tensor(0.8810) acc: 0.66\n",
      "5374 loss: tensor(0.8810) acc: 0.66\n",
      "5375 loss: tensor(0.8810) acc: 0.66\n",
      "5376 loss: tensor(0.8810) acc: 0.66\n",
      "5377 loss: tensor(0.8809) acc: 0.66\n",
      "5378 loss: tensor(0.8809) acc: 0.66\n",
      "5379 loss: tensor(0.8809) acc: 0.66\n",
      "5380 loss: tensor(0.8808) acc: 0.66\n",
      "5381 loss: tensor(0.8808) acc: 0.66\n",
      "5382 loss: tensor(0.8808) acc: 0.66\n",
      "5383 loss: tensor(0.8808) acc: 0.66\n",
      "5384 loss: tensor(0.8807) acc: 0.66\n",
      "5385 loss: tensor(0.8807) acc: 0.66\n",
      "5386 loss: tensor(0.8807) acc: 0.66\n",
      "5387 loss: tensor(0.8807) acc: 0.66\n",
      "5388 loss: tensor(0.8806) acc: 0.66\n",
      "5389 loss: tensor(0.8806) acc: 0.66\n",
      "5390 loss: tensor(0.8806) acc: 0.66\n",
      "5391 loss: tensor(0.8806) acc: 0.66\n",
      "5392 loss: tensor(0.8805) acc: 0.66\n",
      "5393 loss: tensor(0.8805) acc: 0.66\n",
      "5394 loss: tensor(0.8805) acc: 0.66\n",
      "5395 loss: tensor(0.8804) acc: 0.66\n",
      "5396 loss: tensor(0.8804) acc: 0.66\n",
      "5397 loss: tensor(0.8804) acc: 0.66\n",
      "5398 loss: tensor(0.8804) acc: 0.66\n",
      "5399 loss: tensor(0.8803) acc: 0.66\n",
      "5400 loss: tensor(0.8803) acc: 0.66\n",
      "5401 loss: tensor(0.8803) acc: 0.66\n",
      "5402 loss: tensor(0.8803) acc: 0.66\n",
      "5403 loss: tensor(0.8802) acc: 0.66\n",
      "5404 loss: tensor(0.8802) acc: 0.66\n",
      "5405 loss: tensor(0.8802) acc: 0.66\n",
      "5406 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "5407 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "5408 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "5409 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "5410 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "5411 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "5412 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "5413 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "5414 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "5415 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "5416 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "5417 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "5418 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "5419 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "5420 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "5421 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "5422 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "5423 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "5424 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "5425 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "5426 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "5427 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "5428 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "5429 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "5430 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "5431 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "5432 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "5433 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "5434 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "5435 loss: tensor(0.8794) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5436 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "5437 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "5438 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "5439 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "5440 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "5441 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "5442 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "5443 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "5444 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "5445 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "5446 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "5447 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "5448 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "5449 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "5450 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "5451 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "5452 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "5453 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "5454 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "5455 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "5456 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "5457 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "5458 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "5459 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "5460 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "5461 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "5462 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "5463 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "5464 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "5465 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "5466 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "5467 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "5468 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "5469 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "5470 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "5471 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "5472 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "5473 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "5474 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "5475 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "5476 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "5477 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "5478 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "5479 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "5480 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "5481 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "5482 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "5483 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "5484 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "5485 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "5486 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "5487 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "5488 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "5489 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "5490 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "5491 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "5492 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "5493 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "5494 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "5495 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "5496 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "5497 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "5498 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "5499 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "5500 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "5501 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "5502 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "5503 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "5504 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "5505 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "5506 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "5507 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "5508 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "5509 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "5510 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "5511 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "5512 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "5513 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "5514 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "5515 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "5516 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "5517 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "5518 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "5519 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "5520 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "5521 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "5522 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "5523 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "5524 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "5525 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "5526 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "5527 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "5528 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "5529 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "5530 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "5531 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "5532 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "5533 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "5534 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "5535 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "5536 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "5537 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "5538 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "5539 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "5540 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "5541 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "5542 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "5543 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "5544 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "5545 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "5546 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "5547 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "5548 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "5549 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "5550 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "5551 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "5552 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "5553 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "5554 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "5555 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "5556 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "5557 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "5558 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "5559 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "5560 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "5561 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "5562 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "5563 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "5564 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "5565 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "5566 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "5567 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "5568 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "5569 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "5570 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "5571 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "5572 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "5573 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "5574 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "5575 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "5576 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "5577 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "5578 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "5579 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "5580 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "5581 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "5582 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "5583 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "5584 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "5585 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "5586 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "5587 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "5588 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "5589 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "5590 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "5591 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "5592 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "5593 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "5594 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "5595 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "5596 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "5597 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "5598 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "5599 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "5600 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "5601 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "5602 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "5603 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "5604 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "5605 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "5606 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "5607 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "5608 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "5609 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "5610 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "5611 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "5612 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "5613 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "5614 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "5615 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "5616 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "5617 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "5618 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "5619 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "5620 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "5621 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "5622 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "5623 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "5624 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "5625 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "5626 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "5627 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "5628 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "5629 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "5630 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "5631 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "5632 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "5633 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "5634 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "5635 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "5636 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "5637 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "5638 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "5639 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "5640 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "5641 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "5642 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "5643 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "5644 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "5645 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "5646 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "5647 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "5648 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "5649 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "5650 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "5651 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "5652 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "5653 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "5654 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "5655 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "5656 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "5657 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "5658 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "5659 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "5660 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "5661 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "5662 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "5663 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "5664 loss: tensor(0.8742) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5665 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "5666 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "5667 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "5668 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "5669 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "5670 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "5671 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "5672 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "5673 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "5674 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "5675 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "5676 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "5677 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "5678 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "5679 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "5680 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "5681 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "5682 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "5683 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "5684 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "5685 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "5686 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "5687 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "5688 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "5689 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "5690 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "5691 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "5692 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "5693 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "5694 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "5695 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "5696 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "5697 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "5698 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "5699 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "5700 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "5701 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "5702 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "5703 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "5704 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "5705 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "5706 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "5707 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "5708 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "5709 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "5710 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "5711 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "5712 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "5713 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "5714 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "5715 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "5716 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "5717 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "5718 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "5719 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "5720 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "5721 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "5722 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "5723 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "5724 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "5725 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "5726 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "5727 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "5728 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "5729 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "5730 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "5731 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "5732 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "5733 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "5734 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "5735 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "5736 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "5737 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "5738 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "5739 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "5740 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "5741 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "5742 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "5743 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "5744 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "5745 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "5746 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "5747 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "5748 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "5749 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "5750 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "5751 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "5752 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "5753 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "5754 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "5755 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "5756 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "5757 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "5758 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "5759 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "5760 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "5761 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "5762 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "5763 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "5764 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "5765 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "5766 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "5767 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "5768 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "5769 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "5770 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "5771 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "5772 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "5773 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "5774 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "5775 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "5776 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "5777 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "5778 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "5779 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "5780 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "5781 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "5782 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "5783 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "5784 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "5785 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "5786 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "5787 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "5788 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "5789 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "5790 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "5791 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "5792 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "5793 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "5794 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "5795 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "5796 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "5797 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "5798 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "5799 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "5800 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "5801 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "5802 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "5803 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "5804 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "5805 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "5806 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "5807 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "5808 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "5809 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "5810 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "5811 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "5812 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "5813 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "5814 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "5815 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "5816 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "5817 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "5818 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "5819 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "5820 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "5821 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "5822 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "5823 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "5824 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "5825 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "5826 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "5827 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "5828 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "5829 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "5830 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "5831 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "5832 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "5833 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "5834 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "5835 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "5836 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "5837 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "5838 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "5839 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "5840 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "5841 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "5842 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "5843 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "5844 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "5845 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "5846 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "5847 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "5848 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "5849 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "5850 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "5851 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "5852 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "5853 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "5854 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "5855 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "5856 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "5857 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "5858 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "5859 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "5860 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "5861 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "5862 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "5863 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "5864 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "5865 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "5866 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "5867 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "5868 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "5869 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "5870 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "5871 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "5872 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "5873 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "5874 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "5875 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "5876 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "5877 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "5878 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "5879 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "5880 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "5881 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "5882 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "5883 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "5884 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "5885 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "5886 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "5887 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "5888 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "5889 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "5890 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "5891 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "5892 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "5893 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "5894 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "5895 loss: tensor(0.8700) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5896 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "5897 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "5898 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "5899 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "5900 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "5901 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "5902 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "5903 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "5904 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "5905 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "5906 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "5907 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "5908 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "5909 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "5910 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "5911 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "5912 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "5913 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "5914 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "5915 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "5916 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "5917 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "5918 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "5919 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "5920 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "5921 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "5922 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "5923 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "5924 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "5925 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "5926 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "5927 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "5928 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "5929 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "5930 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "5931 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "5932 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "5933 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "5934 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "5935 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "5936 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "5937 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "5938 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "5939 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "5940 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "5941 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "5942 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "5943 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "5944 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "5945 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "5946 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "5947 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "5948 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "5949 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "5950 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "5951 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "5952 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "5953 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "5954 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "5955 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "5956 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "5957 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "5958 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "5959 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "5960 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "5961 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "5962 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "5963 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "5964 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "5965 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "5966 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "5967 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "5968 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "5969 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "5970 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "5971 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "5972 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "5973 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "5974 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "5975 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "5976 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "5977 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "5978 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "5979 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "5980 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "5981 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "5982 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "5983 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "5984 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "5985 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "5986 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "5987 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "5988 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "5989 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "5990 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "5991 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "5992 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "5993 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "5994 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "5995 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "5996 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "5997 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "5998 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "5999 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "6000 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "6001 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "6002 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "6003 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "6004 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "6005 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "6006 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "6007 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "6008 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "6009 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "6010 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "6011 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "6012 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "6013 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "6014 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "6015 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "6016 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "6017 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "6018 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "6019 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "6020 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "6021 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "6022 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "6023 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "6024 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "6025 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "6026 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "6027 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6028 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6029 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6030 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6031 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6032 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6033 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6034 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "6035 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "6036 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "6037 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "6038 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "6039 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "6040 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "6041 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "6042 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "6043 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "6044 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "6045 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "6046 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "6047 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "6048 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "6049 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6050 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6051 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6052 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6053 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6054 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6055 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6056 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "6057 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "6058 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "6059 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "6060 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "6061 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "6062 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "6063 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "6064 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6065 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6066 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6067 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6068 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6069 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6070 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6071 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "6072 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "6073 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "6074 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "6075 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "6076 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "6077 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "6078 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "6079 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "6080 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "6081 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "6082 loss: tensor(0.8673) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6083 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "6084 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "6085 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "6086 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "6087 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6088 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6089 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6090 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6091 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6092 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6093 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6094 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "6095 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "6096 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "6097 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "6098 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "6099 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "6100 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "6101 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "6102 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6103 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6104 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6105 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6106 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6107 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6108 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6109 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "6110 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6111 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6112 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6113 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6114 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6115 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6116 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6117 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "6118 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6119 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6120 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6121 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6122 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6123 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6124 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6125 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "6126 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6127 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6128 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6129 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6130 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6131 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6132 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6133 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "6134 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6135 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6136 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6137 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6138 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6139 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6140 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6141 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6142 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "6143 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6144 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6145 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6146 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6147 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6148 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6149 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6150 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "6151 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6152 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6153 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6154 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6155 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6156 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6157 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6158 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "6159 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6160 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6161 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6162 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6163 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6164 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6165 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6166 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6167 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "6168 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6169 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6170 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6171 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6172 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6173 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6174 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6175 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "6176 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6177 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6178 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6179 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6180 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6181 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6182 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6183 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6184 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "6185 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6186 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6187 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6188 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6189 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6190 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6191 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6192 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "6193 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6194 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6195 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6196 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6197 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6198 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6199 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6200 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6201 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "6202 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6203 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6204 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6205 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6206 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6207 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6208 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6209 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6210 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "6211 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6212 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6213 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6214 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6215 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6216 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6217 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6218 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6219 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "6220 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6221 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6222 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6223 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6224 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6225 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6226 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6227 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6228 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "6229 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6230 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6231 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6232 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6233 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6234 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6235 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6236 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6237 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "6238 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6239 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6240 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6241 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6242 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6243 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6244 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6245 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6246 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "6247 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6248 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6249 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6250 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6251 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6252 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6253 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6254 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6255 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6256 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "6257 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6258 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6259 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6260 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6261 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6262 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6263 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6264 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6265 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "6266 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6267 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6268 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6269 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6270 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6271 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6272 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6273 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6274 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6275 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "6276 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6277 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6278 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6279 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6280 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6281 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6282 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6283 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6284 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "6285 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6286 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6287 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6288 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6289 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6290 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6291 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6292 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6293 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6294 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "6295 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6296 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6297 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6298 loss: tensor(0.8648) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6299 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6300 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6301 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6302 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6303 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6304 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "6305 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6306 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6307 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6308 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6309 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6310 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6311 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6312 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6313 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6314 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "6315 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6316 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6317 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6318 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6319 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6320 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6321 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6322 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6323 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6324 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "6325 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6326 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6327 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6328 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6329 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6330 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6331 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6332 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6333 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6334 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6335 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "6336 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6337 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6338 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6339 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6340 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6341 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6342 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6343 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6344 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6345 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "6346 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6347 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6348 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6349 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6350 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6351 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6352 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6353 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6354 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6355 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6356 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "6357 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6358 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6359 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6360 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6361 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6362 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6363 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6364 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6365 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6366 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "6367 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6368 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6369 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6370 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6371 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6372 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6373 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6374 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6375 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6376 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6377 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "6378 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6379 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6380 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6381 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6382 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6383 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6384 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6385 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6386 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6387 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6388 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "6389 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6390 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6391 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6392 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6393 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6394 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6395 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6396 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6397 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6398 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6399 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6400 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "6401 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6402 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6403 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6404 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6405 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6406 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6407 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6408 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6409 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6410 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6411 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "6412 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6413 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6414 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6415 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6416 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6417 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6418 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6419 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6420 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6421 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6422 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6423 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "6424 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6425 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6426 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6427 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6428 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6429 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6430 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6431 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6432 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6433 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6434 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "6435 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6436 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6437 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6438 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6439 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6440 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6441 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6442 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6443 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6444 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6445 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6446 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "6447 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6448 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6449 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6450 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6451 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6452 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6453 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6454 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6455 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6456 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6457 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6458 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6459 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "6460 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6461 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6462 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6463 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6464 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6465 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6466 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6467 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6468 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6469 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6470 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6471 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "6472 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6473 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6474 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6475 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6476 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6477 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6478 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6479 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6480 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6481 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6482 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6483 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6484 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "6485 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6486 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6487 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6488 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6489 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6490 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6491 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6492 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6493 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6494 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6495 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6496 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "6497 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6498 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6499 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6500 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6501 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6502 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6503 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6504 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6505 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6506 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6507 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6508 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6509 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6510 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "6511 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6512 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6513 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6514 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6515 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6516 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6517 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6518 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6519 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6520 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6521 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6522 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6523 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "6524 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6525 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6526 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6527 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6528 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6529 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6530 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6531 loss: tensor(0.8628) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6532 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6533 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6534 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6535 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6536 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6537 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "6538 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6539 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6540 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6541 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6542 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6543 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6544 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6545 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6546 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6547 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6548 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6549 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6550 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6551 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "6552 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6553 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6554 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6555 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6556 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6557 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6558 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6559 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6560 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6561 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6562 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6563 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6564 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6565 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "6566 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6567 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6568 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6569 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6570 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6571 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6572 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6573 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6574 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6575 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6576 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6577 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6578 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6579 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6580 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "6581 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6582 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6583 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6584 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6585 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6586 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6587 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6588 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6589 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6590 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6591 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6592 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6593 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6594 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6595 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "6596 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6597 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6598 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6599 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6600 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6601 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6602 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6603 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6604 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6605 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6606 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6607 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6608 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6609 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6610 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6611 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "6612 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6613 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6614 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6615 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6616 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6617 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6618 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6619 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6620 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6621 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6622 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6623 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6624 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6625 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6626 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6627 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "6628 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6629 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6630 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6631 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6632 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6633 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6634 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6635 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6636 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6637 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6638 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6639 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6640 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6641 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6642 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6643 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "6644 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6645 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6646 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6647 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6648 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6649 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6650 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6651 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6652 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6653 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6654 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6655 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6656 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6657 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6658 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6659 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6660 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "6661 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6662 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6663 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6664 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6665 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6666 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6667 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6668 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6669 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6670 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6671 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6672 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6673 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6674 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6675 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6676 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6677 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6678 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "6679 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6680 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6681 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6682 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6683 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6684 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6685 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6686 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6687 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6688 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6689 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6690 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6691 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6692 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6693 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6694 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6695 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6696 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "6697 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6698 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6699 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6700 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6701 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6702 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6703 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6704 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6705 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6706 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6707 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6708 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6709 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6710 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6711 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6712 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6713 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6714 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6715 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "6716 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6717 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6718 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6719 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6720 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6721 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6722 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6723 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6724 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6725 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6726 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6727 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6728 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6729 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6730 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6731 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6732 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6733 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6734 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6735 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "6736 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6737 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6738 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6739 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6740 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6741 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6742 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6743 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6744 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6745 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6746 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6747 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6748 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6749 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6750 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6751 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6752 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6753 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6754 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6755 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "6756 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6757 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6758 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6759 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6760 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6761 loss: tensor(0.8614) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6762 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6763 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6764 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6765 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6766 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6767 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6768 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6769 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6770 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6771 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6772 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6773 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6774 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6775 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6776 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6777 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "6778 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6779 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6780 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6781 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6782 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6783 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6784 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6785 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6786 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6787 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6788 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6789 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6790 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6791 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6792 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6793 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6794 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6795 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6796 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6797 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6798 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6799 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6800 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6801 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "6802 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6803 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6804 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6805 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6806 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6807 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6808 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6809 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6810 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6811 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6812 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6813 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6814 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6815 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6816 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6817 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6818 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6819 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6820 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6821 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6822 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6823 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6824 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6825 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6826 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "6827 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6828 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6829 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6830 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6831 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6832 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6833 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6834 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6835 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6836 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6837 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6838 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6839 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6840 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6841 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6842 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6843 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6844 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6845 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6846 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6847 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6848 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6849 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6850 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6851 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6852 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6853 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "6854 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6855 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6856 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6857 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6858 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6859 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6860 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6861 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6862 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6863 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6864 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6865 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6866 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6867 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6868 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6869 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6870 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6871 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6872 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6873 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6874 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6875 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6876 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6877 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6878 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6879 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6880 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6881 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6882 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "6883 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6884 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6885 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6886 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6887 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6888 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6889 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6890 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6891 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6892 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6893 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6894 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6895 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6896 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6897 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6898 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6899 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6900 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6901 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6902 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6903 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6904 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6905 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6906 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6907 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6908 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6909 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6910 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6911 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6912 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6913 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6914 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6915 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "6916 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6917 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6918 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6919 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6920 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6921 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6922 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6923 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6924 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6925 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6926 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6927 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6928 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6929 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6930 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6931 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6932 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6933 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6934 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6935 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6936 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6937 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6938 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6939 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6940 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6941 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6942 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6943 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6944 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6945 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6946 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6947 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6948 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6949 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6950 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6951 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6952 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6953 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6954 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "6955 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6956 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6957 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6958 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6959 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6960 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6961 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6962 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6963 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6964 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6965 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6966 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6967 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6968 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6969 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6970 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6971 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6972 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6973 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6974 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6975 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6976 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6977 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6978 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6979 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6980 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6981 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6982 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6983 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6984 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6985 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6986 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6987 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6988 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6989 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6990 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6991 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6992 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6993 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6994 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6995 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6996 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6997 loss: tensor(0.8607) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6998 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "6999 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7000 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7001 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7002 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7003 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7004 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7005 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7006 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7007 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7008 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7009 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7010 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7011 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7012 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7013 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7014 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7015 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7016 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7017 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7018 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7019 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7020 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7021 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7022 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7023 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7024 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7025 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7026 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7027 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7028 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7029 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7030 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7031 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7032 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7033 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7034 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7035 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7036 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7037 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7038 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7039 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7040 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7041 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7042 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7043 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7044 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7045 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7046 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7047 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7048 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7049 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7050 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7051 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7052 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7053 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7054 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7055 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7056 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7057 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7058 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7059 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7060 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7061 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7062 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7063 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7064 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7065 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7066 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7067 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7068 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7069 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7070 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7071 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7072 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7073 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7074 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7075 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7076 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7077 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7078 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7079 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7080 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7081 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7082 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7083 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7084 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7085 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7086 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7087 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7088 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7089 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7090 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7091 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7092 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7093 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7094 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7095 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7096 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7097 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7098 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7099 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7100 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7101 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7102 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7103 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7104 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7105 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7106 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7107 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7108 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7109 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7110 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7111 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7112 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7113 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7114 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7115 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7116 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7117 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7118 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7119 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7120 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7121 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7122 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7123 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7124 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7125 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7126 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7127 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7128 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7129 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7130 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7131 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7132 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7133 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7134 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7135 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7136 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7137 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7138 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7139 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7140 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7141 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7142 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7143 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7144 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7145 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7146 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7147 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7148 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7149 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7150 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7151 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7152 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7153 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7154 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7155 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7156 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7157 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7158 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7159 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7160 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7161 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7162 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7163 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7164 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7165 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7166 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7167 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7168 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7169 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7170 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7171 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7172 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7173 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7174 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7175 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7176 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7177 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7178 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7179 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7180 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7181 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7182 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7183 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7184 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7185 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7186 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7187 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7188 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7189 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7190 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7191 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7192 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7193 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7194 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7195 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7196 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7197 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7198 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7199 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7200 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7201 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7202 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7203 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7204 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7205 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7206 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7207 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7208 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7209 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7210 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7211 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7212 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7213 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7214 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7215 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7216 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7217 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7218 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7219 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7220 loss: tensor(0.8605) acc: 0.6666666666666666\n",
      "7221 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7222 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7223 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7224 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7225 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7226 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7227 loss: tensor(0.8606) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7228 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7229 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7230 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7231 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7232 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7233 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7234 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7235 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7236 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7237 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7238 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7239 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7240 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7241 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7242 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7243 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7244 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7245 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7246 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7247 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7248 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7249 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7250 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7251 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7252 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7253 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7254 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7255 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7256 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7257 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7258 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7259 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7260 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7261 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7262 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7263 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7264 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7265 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7266 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7267 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7268 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7269 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7270 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7271 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7272 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7273 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7274 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7275 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7276 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7277 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7278 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7279 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7280 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7281 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7282 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7283 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7284 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7285 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7286 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7287 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7288 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7289 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7290 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7291 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7292 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7293 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7294 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7295 loss: tensor(0.8606) acc: 0.6666666666666666\n",
      "7296 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7297 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7298 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7299 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7300 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7301 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7302 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7303 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7304 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7305 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7306 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7307 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7308 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7309 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7310 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7311 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7312 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7313 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7314 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7315 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7316 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7317 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7318 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7319 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7320 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7321 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7322 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7323 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7324 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7325 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7326 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7327 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7328 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7329 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7330 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7331 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7332 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7333 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7334 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7335 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7336 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7337 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7338 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7339 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7340 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7341 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7342 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7343 loss: tensor(0.8607) acc: 0.6666666666666666\n",
      "7344 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7345 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7346 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7347 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7348 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7349 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7350 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7351 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7352 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7353 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7354 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7355 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7356 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7357 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7358 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7359 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7360 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7361 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7362 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7363 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7364 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7365 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7366 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7367 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7368 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7369 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7370 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7371 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7372 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7373 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7374 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7375 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7376 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7377 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7378 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7379 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7380 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7381 loss: tensor(0.8608) acc: 0.6666666666666666\n",
      "7382 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7383 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7384 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7385 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7386 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7387 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7388 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7389 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7390 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7391 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7392 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7393 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7394 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7395 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7396 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7397 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7398 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7399 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7400 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7401 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7402 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7403 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7404 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7405 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7406 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7407 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7408 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7409 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7410 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7411 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7412 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7413 loss: tensor(0.8609) acc: 0.6666666666666666\n",
      "7414 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7415 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7416 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7417 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7418 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7419 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7420 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7421 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7422 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7423 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7424 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7425 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7426 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7427 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7428 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7429 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7430 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7431 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7432 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7433 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7434 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7435 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7436 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7437 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7438 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7439 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7440 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7441 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7442 loss: tensor(0.8610) acc: 0.6666666666666666\n",
      "7443 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7444 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7445 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7446 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7447 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7448 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7449 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7450 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7451 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7452 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7453 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7454 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7455 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7456 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7457 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7458 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7459 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7460 loss: tensor(0.8611) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7461 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7462 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7463 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7464 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7465 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7466 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7467 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7468 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7469 loss: tensor(0.8611) acc: 0.6666666666666666\n",
      "7470 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7471 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7472 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7473 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7474 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7475 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7476 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7477 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7478 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7479 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7480 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7481 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7482 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7483 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7484 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7485 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7486 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7487 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7488 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7489 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7490 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7491 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7492 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7493 loss: tensor(0.8612) acc: 0.6666666666666666\n",
      "7494 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7495 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7496 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7497 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7498 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7499 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7500 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7501 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7502 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7503 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7504 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7505 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7506 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7507 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7508 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7509 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7510 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7511 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7512 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7513 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7514 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7515 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7516 loss: tensor(0.8613) acc: 0.6666666666666666\n",
      "7517 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7518 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7519 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7520 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7521 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7522 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7523 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7524 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7525 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7526 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7527 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7528 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7529 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7530 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7531 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7532 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7533 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7534 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7535 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7536 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7537 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7538 loss: tensor(0.8614) acc: 0.6666666666666666\n",
      "7539 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7540 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7541 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7542 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7543 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7544 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7545 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7546 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7547 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7548 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7549 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7550 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7551 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7552 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7553 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7554 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7555 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7556 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7557 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7558 loss: tensor(0.8615) acc: 0.6666666666666666\n",
      "7559 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7560 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7561 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7562 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7563 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7564 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7565 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7566 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7567 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7568 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7569 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7570 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7571 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7572 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7573 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7574 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7575 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7576 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7577 loss: tensor(0.8616) acc: 0.6666666666666666\n",
      "7578 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7579 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7580 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7581 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7582 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7583 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7584 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7585 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7586 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7587 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7588 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7589 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7590 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7591 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7592 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7593 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7594 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7595 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7596 loss: tensor(0.8617) acc: 0.6666666666666666\n",
      "7597 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7598 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7599 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7600 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7601 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7602 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7603 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7604 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7605 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7606 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7607 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7608 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7609 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7610 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7611 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7612 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7613 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7614 loss: tensor(0.8618) acc: 0.6666666666666666\n",
      "7615 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7616 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7617 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7618 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7619 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7620 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7621 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7622 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7623 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7624 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7625 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7626 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7627 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7628 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7629 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7630 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7631 loss: tensor(0.8619) acc: 0.6666666666666666\n",
      "7632 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7633 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7634 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7635 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7636 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7637 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7638 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7639 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7640 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7641 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7642 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7643 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7644 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7645 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7646 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7647 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7648 loss: tensor(0.8620) acc: 0.6666666666666666\n",
      "7649 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7650 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7651 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7652 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7653 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7654 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7655 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7656 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7657 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7658 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7659 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7660 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7661 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7662 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7663 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7664 loss: tensor(0.8621) acc: 0.6666666666666666\n",
      "7665 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7666 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7667 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7668 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7669 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7670 loss: tensor(0.8622) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7671 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7672 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7673 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7674 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7675 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7676 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7677 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7678 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7679 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7680 loss: tensor(0.8622) acc: 0.6666666666666666\n",
      "7681 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7682 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7683 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7684 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7685 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7686 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7687 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7688 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7689 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7690 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7691 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7692 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7693 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7694 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7695 loss: tensor(0.8623) acc: 0.6666666666666666\n",
      "7696 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7697 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7698 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7699 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7700 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7701 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7702 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7703 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7704 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7705 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7706 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7707 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7708 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7709 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7710 loss: tensor(0.8624) acc: 0.6666666666666666\n",
      "7711 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7712 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7713 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7714 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7715 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7716 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7717 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7718 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7719 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7720 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7721 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7722 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7723 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7724 loss: tensor(0.8625) acc: 0.6666666666666666\n",
      "7725 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7726 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7727 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7728 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7729 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7730 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7731 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7732 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7733 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7734 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7735 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7736 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7737 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7738 loss: tensor(0.8626) acc: 0.6666666666666666\n",
      "7739 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7740 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7741 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7742 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7743 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7744 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7745 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7746 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7747 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7748 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7749 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7750 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7751 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7752 loss: tensor(0.8627) acc: 0.6666666666666666\n",
      "7753 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7754 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7755 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7756 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7757 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7758 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7759 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7760 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7761 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7762 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7763 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7764 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7765 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7766 loss: tensor(0.8628) acc: 0.6666666666666666\n",
      "7767 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7768 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7769 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7770 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7771 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7772 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7773 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7774 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7775 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7776 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7777 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7778 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7779 loss: tensor(0.8629) acc: 0.6666666666666666\n",
      "7780 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7781 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7782 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7783 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7784 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7785 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7786 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7787 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7788 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7789 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7790 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7791 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7792 loss: tensor(0.8630) acc: 0.6666666666666666\n",
      "7793 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7794 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7795 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7796 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7797 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7798 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7799 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7800 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7801 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7802 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7803 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7804 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7805 loss: tensor(0.8631) acc: 0.6666666666666666\n",
      "7806 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7807 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7808 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7809 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7810 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7811 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7812 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7813 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7814 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7815 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7816 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7817 loss: tensor(0.8632) acc: 0.6666666666666666\n",
      "7818 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7819 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7820 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7821 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7822 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7823 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7824 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7825 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7826 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7827 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7828 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7829 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7830 loss: tensor(0.8633) acc: 0.6666666666666666\n",
      "7831 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7832 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7833 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7834 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7835 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7836 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7837 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7838 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7839 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7840 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7841 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7842 loss: tensor(0.8634) acc: 0.6666666666666666\n",
      "7843 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7844 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7845 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7846 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7847 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7848 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7849 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7850 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7851 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7852 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7853 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7854 loss: tensor(0.8635) acc: 0.6666666666666666\n",
      "7855 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7856 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7857 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7858 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7859 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7860 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7861 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7862 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7863 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7864 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7865 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7866 loss: tensor(0.8636) acc: 0.6666666666666666\n",
      "7867 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7868 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7869 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7870 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7871 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7872 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7873 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7874 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7875 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7876 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7877 loss: tensor(0.8637) acc: 0.6666666666666666\n",
      "7878 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7879 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7880 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7881 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7882 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7883 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7884 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7885 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7886 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7887 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7888 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7889 loss: tensor(0.8638) acc: 0.6666666666666666\n",
      "7890 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7891 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7892 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7893 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7894 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7895 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7896 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7897 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7898 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7899 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7900 loss: tensor(0.8639) acc: 0.6666666666666666\n",
      "7901 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7902 loss: tensor(0.8640) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7903 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7904 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7905 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7906 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7907 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7908 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7909 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7910 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7911 loss: tensor(0.8640) acc: 0.6666666666666666\n",
      "7912 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7913 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7914 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7915 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7916 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7917 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7918 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7919 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7920 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7921 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7922 loss: tensor(0.8641) acc: 0.6666666666666666\n",
      "7923 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7924 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7925 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7926 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7927 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7928 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7929 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7930 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7931 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7932 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7933 loss: tensor(0.8642) acc: 0.6666666666666666\n",
      "7934 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7935 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7936 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7937 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7938 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7939 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7940 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7941 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7942 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7943 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7944 loss: tensor(0.8643) acc: 0.6666666666666666\n",
      "7945 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7946 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7947 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7948 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7949 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7950 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7951 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7952 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7953 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7954 loss: tensor(0.8644) acc: 0.6666666666666666\n",
      "7955 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7956 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7957 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7958 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7959 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7960 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7961 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7962 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7963 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7964 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7965 loss: tensor(0.8645) acc: 0.6666666666666666\n",
      "7966 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7967 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7968 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7969 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7970 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7971 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7972 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7973 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7974 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7975 loss: tensor(0.8646) acc: 0.6666666666666666\n",
      "7976 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7977 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7978 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7979 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7980 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7981 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7982 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7983 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7984 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7985 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7986 loss: tensor(0.8647) acc: 0.6666666666666666\n",
      "7987 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7988 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7989 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7990 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7991 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7992 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7993 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7994 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7995 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7996 loss: tensor(0.8648) acc: 0.6666666666666666\n",
      "7997 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "7998 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "7999 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8000 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8001 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8002 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8003 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8004 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8005 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8006 loss: tensor(0.8649) acc: 0.6666666666666666\n",
      "8007 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8008 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8009 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8010 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8011 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8012 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8013 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8014 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8015 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8016 loss: tensor(0.8650) acc: 0.6666666666666666\n",
      "8017 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8018 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8019 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8020 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8021 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8022 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8023 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8024 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8025 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8026 loss: tensor(0.8651) acc: 0.6666666666666666\n",
      "8027 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8028 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8029 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8030 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8031 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8032 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8033 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8034 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8035 loss: tensor(0.8652) acc: 0.6666666666666666\n",
      "8036 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8037 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8038 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8039 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8040 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8041 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8042 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8043 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8044 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8045 loss: tensor(0.8653) acc: 0.6666666666666666\n",
      "8046 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8047 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8048 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8049 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8050 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8051 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8052 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8053 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8054 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8055 loss: tensor(0.8654) acc: 0.6666666666666666\n",
      "8056 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8057 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8058 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8059 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8060 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8061 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8062 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8063 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8064 loss: tensor(0.8655) acc: 0.6666666666666666\n",
      "8065 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8066 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8067 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8068 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8069 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8070 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8071 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8072 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8073 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8074 loss: tensor(0.8656) acc: 0.6666666666666666\n",
      "8075 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8076 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8077 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8078 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8079 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8080 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8081 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8082 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8083 loss: tensor(0.8657) acc: 0.6666666666666666\n",
      "8084 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8085 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8086 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8087 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8088 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8089 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8090 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8091 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8092 loss: tensor(0.8658) acc: 0.6666666666666666\n",
      "8093 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8094 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8095 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8096 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8097 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8098 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8099 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8100 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8101 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8102 loss: tensor(0.8659) acc: 0.6666666666666666\n",
      "8103 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8104 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8105 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8106 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8107 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8108 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8109 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8110 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8111 loss: tensor(0.8660) acc: 0.6666666666666666\n",
      "8112 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8113 loss: tensor(0.8661) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8114 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8115 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8116 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8117 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8118 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8119 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8120 loss: tensor(0.8661) acc: 0.6666666666666666\n",
      "8121 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8122 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8123 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8124 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8125 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8126 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8127 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8128 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8129 loss: tensor(0.8662) acc: 0.6666666666666666\n",
      "8130 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8131 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8132 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8133 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8134 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8135 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8136 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8137 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8138 loss: tensor(0.8663) acc: 0.6666666666666666\n",
      "8139 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8140 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8141 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8142 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8143 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8144 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8145 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8146 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8147 loss: tensor(0.8664) acc: 0.6666666666666666\n",
      "8148 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8149 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8150 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8151 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8152 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8153 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8154 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8155 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8156 loss: tensor(0.8665) acc: 0.6666666666666666\n",
      "8157 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8158 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8159 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8160 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8161 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8162 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8163 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8164 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8165 loss: tensor(0.8666) acc: 0.6666666666666666\n",
      "8166 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8167 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8168 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8169 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8170 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8171 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8172 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8173 loss: tensor(0.8667) acc: 0.6666666666666666\n",
      "8174 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8175 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8176 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8177 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8178 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8179 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8180 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8181 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8182 loss: tensor(0.8668) acc: 0.6666666666666666\n",
      "8183 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8184 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8185 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8186 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8187 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8188 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8189 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8190 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8191 loss: tensor(0.8669) acc: 0.6666666666666666\n",
      "8192 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8193 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8194 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8195 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8196 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8197 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8198 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8199 loss: tensor(0.8670) acc: 0.6666666666666666\n",
      "8200 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8201 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8202 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8203 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8204 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8205 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8206 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8207 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8208 loss: tensor(0.8671) acc: 0.6666666666666666\n",
      "8209 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8210 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8211 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8212 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8213 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8214 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8215 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8216 loss: tensor(0.8672) acc: 0.6666666666666666\n",
      "8217 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8218 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8219 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8220 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8221 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8222 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8223 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8224 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8225 loss: tensor(0.8673) acc: 0.6666666666666666\n",
      "8226 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8227 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8228 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8229 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8230 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8231 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8232 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8233 loss: tensor(0.8674) acc: 0.6666666666666666\n",
      "8234 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8235 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8236 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8237 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8238 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8239 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8240 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8241 loss: tensor(0.8675) acc: 0.6666666666666666\n",
      "8242 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8243 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8244 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8245 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8246 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8247 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8248 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8249 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8250 loss: tensor(0.8676) acc: 0.6666666666666666\n",
      "8251 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8252 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8253 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8254 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8255 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8256 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8257 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8258 loss: tensor(0.8677) acc: 0.6666666666666666\n",
      "8259 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8260 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8261 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8262 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8263 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8264 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8265 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8266 loss: tensor(0.8678) acc: 0.6666666666666666\n",
      "8267 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8268 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8269 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8270 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8271 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8272 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8273 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8274 loss: tensor(0.8679) acc: 0.6666666666666666\n",
      "8275 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8276 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8277 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8278 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8279 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8280 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8281 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8282 loss: tensor(0.8680) acc: 0.6666666666666666\n",
      "8283 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8284 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8285 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8286 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8287 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8288 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8289 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8290 loss: tensor(0.8681) acc: 0.6666666666666666\n",
      "8291 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8292 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8293 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8294 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8295 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8296 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8297 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8298 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8299 loss: tensor(0.8682) acc: 0.6666666666666666\n",
      "8300 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8301 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8302 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8303 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8304 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8305 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8306 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8307 loss: tensor(0.8683) acc: 0.6666666666666666\n",
      "8308 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8309 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8310 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8311 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8312 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8313 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8314 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8315 loss: tensor(0.8684) acc: 0.6666666666666666\n",
      "8316 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "8317 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "8318 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "8319 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "8320 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "8321 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "8322 loss: tensor(0.8685) acc: 0.6666666666666666\n",
      "8323 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8324 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8325 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8326 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8327 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8328 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8329 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8330 loss: tensor(0.8686) acc: 0.6666666666666666\n",
      "8331 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "8332 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "8333 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "8334 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "8335 loss: tensor(0.8687) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8336 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "8337 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "8338 loss: tensor(0.8687) acc: 0.6666666666666666\n",
      "8339 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8340 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8341 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8342 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8343 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8344 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8345 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8346 loss: tensor(0.8688) acc: 0.6666666666666666\n",
      "8347 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8348 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8349 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8350 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8351 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8352 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8353 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8354 loss: tensor(0.8689) acc: 0.6666666666666666\n",
      "8355 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8356 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8357 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8358 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8359 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8360 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8361 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8362 loss: tensor(0.8690) acc: 0.6666666666666666\n",
      "8363 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "8364 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "8365 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "8366 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "8367 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "8368 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "8369 loss: tensor(0.8691) acc: 0.6666666666666666\n",
      "8370 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8371 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8372 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8373 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8374 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8375 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8376 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8377 loss: tensor(0.8692) acc: 0.6666666666666666\n",
      "8378 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8379 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8380 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8381 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8382 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8383 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8384 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8385 loss: tensor(0.8693) acc: 0.6666666666666666\n",
      "8386 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "8387 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "8388 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "8389 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "8390 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "8391 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "8392 loss: tensor(0.8694) acc: 0.6666666666666666\n",
      "8393 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8394 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8395 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8396 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8397 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8398 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8399 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8400 loss: tensor(0.8695) acc: 0.6666666666666666\n",
      "8401 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8402 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8403 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8404 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8405 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8406 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8407 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8408 loss: tensor(0.8696) acc: 0.6666666666666666\n",
      "8409 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "8410 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "8411 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "8412 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "8413 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "8414 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "8415 loss: tensor(0.8697) acc: 0.6666666666666666\n",
      "8416 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8417 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8418 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8419 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8420 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8421 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8422 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8423 loss: tensor(0.8698) acc: 0.6666666666666666\n",
      "8424 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "8425 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "8426 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "8427 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "8428 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "8429 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "8430 loss: tensor(0.8699) acc: 0.6666666666666666\n",
      "8431 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8432 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8433 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8434 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8435 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8436 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8437 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8438 loss: tensor(0.8700) acc: 0.6666666666666666\n",
      "8439 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "8440 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "8441 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "8442 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "8443 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "8444 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "8445 loss: tensor(0.8701) acc: 0.6666666666666666\n",
      "8446 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8447 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8448 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8449 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8450 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8451 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8452 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8453 loss: tensor(0.8702) acc: 0.6666666666666666\n",
      "8454 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "8455 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "8456 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "8457 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "8458 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "8459 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "8460 loss: tensor(0.8703) acc: 0.6666666666666666\n",
      "8461 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "8462 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "8463 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "8464 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "8465 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "8466 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "8467 loss: tensor(0.8704) acc: 0.6666666666666666\n",
      "8468 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8469 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8470 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8471 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8472 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8473 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8474 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8475 loss: tensor(0.8705) acc: 0.6666666666666666\n",
      "8476 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "8477 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "8478 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "8479 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "8480 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "8481 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "8482 loss: tensor(0.8706) acc: 0.6666666666666666\n",
      "8483 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8484 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8485 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8486 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8487 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8488 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8489 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8490 loss: tensor(0.8707) acc: 0.6666666666666666\n",
      "8491 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "8492 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "8493 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "8494 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "8495 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "8496 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "8497 loss: tensor(0.8708) acc: 0.6666666666666666\n",
      "8498 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "8499 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "8500 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "8501 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "8502 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "8503 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "8504 loss: tensor(0.8709) acc: 0.6666666666666666\n",
      "8505 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "8506 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "8507 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "8508 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "8509 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "8510 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "8511 loss: tensor(0.8710) acc: 0.6666666666666666\n",
      "8512 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8513 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8514 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8515 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8516 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8517 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8518 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8519 loss: tensor(0.8711) acc: 0.6666666666666666\n",
      "8520 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "8521 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "8522 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "8523 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "8524 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "8525 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "8526 loss: tensor(0.8712) acc: 0.6666666666666666\n",
      "8527 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "8528 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "8529 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "8530 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "8531 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "8532 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "8533 loss: tensor(0.8713) acc: 0.6666666666666666\n",
      "8534 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "8535 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "8536 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "8537 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "8538 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "8539 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "8540 loss: tensor(0.8714) acc: 0.6666666666666666\n",
      "8541 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "8542 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "8543 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "8544 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "8545 loss: tensor(0.8715) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8546 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "8547 loss: tensor(0.8715) acc: 0.6666666666666666\n",
      "8548 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8549 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8550 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8551 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8552 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8553 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8554 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8555 loss: tensor(0.8716) acc: 0.6666666666666666\n",
      "8556 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "8557 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "8558 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "8559 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "8560 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "8561 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "8562 loss: tensor(0.8717) acc: 0.6666666666666666\n",
      "8563 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "8564 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "8565 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "8566 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "8567 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "8568 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "8569 loss: tensor(0.8718) acc: 0.6666666666666666\n",
      "8570 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "8571 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "8572 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "8573 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "8574 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "8575 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "8576 loss: tensor(0.8719) acc: 0.6666666666666666\n",
      "8577 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "8578 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "8579 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "8580 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "8581 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "8582 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "8583 loss: tensor(0.8720) acc: 0.6666666666666666\n",
      "8584 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "8585 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "8586 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "8587 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "8588 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "8589 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "8590 loss: tensor(0.8721) acc: 0.6666666666666666\n",
      "8591 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "8592 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "8593 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "8594 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "8595 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "8596 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "8597 loss: tensor(0.8722) acc: 0.6666666666666666\n",
      "8598 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "8599 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "8600 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "8601 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "8602 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "8603 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "8604 loss: tensor(0.8723) acc: 0.6666666666666666\n",
      "8605 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "8606 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "8607 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "8608 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "8609 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "8610 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "8611 loss: tensor(0.8724) acc: 0.6666666666666666\n",
      "8612 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "8613 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "8614 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "8615 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "8616 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "8617 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "8618 loss: tensor(0.8725) acc: 0.6666666666666666\n",
      "8619 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "8620 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "8621 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "8622 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "8623 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "8624 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "8625 loss: tensor(0.8726) acc: 0.6666666666666666\n",
      "8626 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "8627 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "8628 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "8629 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "8630 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "8631 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "8632 loss: tensor(0.8727) acc: 0.6666666666666666\n",
      "8633 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "8634 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "8635 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "8636 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "8637 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "8638 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "8639 loss: tensor(0.8728) acc: 0.6666666666666666\n",
      "8640 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "8641 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "8642 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "8643 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "8644 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "8645 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "8646 loss: tensor(0.8729) acc: 0.6666666666666666\n",
      "8647 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "8648 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "8649 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "8650 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "8651 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "8652 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "8653 loss: tensor(0.8730) acc: 0.6666666666666666\n",
      "8654 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "8655 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "8656 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "8657 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "8658 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "8659 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "8660 loss: tensor(0.8731) acc: 0.6666666666666666\n",
      "8661 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "8662 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "8663 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "8664 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "8665 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "8666 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "8667 loss: tensor(0.8732) acc: 0.6666666666666666\n",
      "8668 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "8669 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "8670 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "8671 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "8672 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "8673 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "8674 loss: tensor(0.8733) acc: 0.6666666666666666\n",
      "8675 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "8676 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "8677 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "8678 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "8679 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "8680 loss: tensor(0.8734) acc: 0.6666666666666666\n",
      "8681 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "8682 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "8683 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "8684 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "8685 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "8686 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "8687 loss: tensor(0.8735) acc: 0.6666666666666666\n",
      "8688 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "8689 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "8690 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "8691 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "8692 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "8693 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "8694 loss: tensor(0.8736) acc: 0.6666666666666666\n",
      "8695 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "8696 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "8697 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "8698 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "8699 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "8700 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "8701 loss: tensor(0.8737) acc: 0.6666666666666666\n",
      "8702 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "8703 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "8704 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "8705 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "8706 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "8707 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "8708 loss: tensor(0.8738) acc: 0.6666666666666666\n",
      "8709 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "8710 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "8711 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "8712 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "8713 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "8714 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "8715 loss: tensor(0.8739) acc: 0.6666666666666666\n",
      "8716 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "8717 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "8718 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "8719 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "8720 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "8721 loss: tensor(0.8740) acc: 0.6666666666666666\n",
      "8722 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "8723 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "8724 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "8725 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "8726 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "8727 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "8728 loss: tensor(0.8741) acc: 0.6666666666666666\n",
      "8729 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "8730 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "8731 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "8732 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "8733 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "8734 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "8735 loss: tensor(0.8742) acc: 0.6666666666666666\n",
      "8736 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "8737 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "8738 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "8739 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "8740 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "8741 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "8742 loss: tensor(0.8743) acc: 0.6666666666666666\n",
      "8743 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "8744 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "8745 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "8746 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "8747 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "8748 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "8749 loss: tensor(0.8744) acc: 0.6666666666666666\n",
      "8750 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "8751 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "8752 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "8753 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "8754 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "8755 loss: tensor(0.8745) acc: 0.6666666666666666\n",
      "8756 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "8757 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "8758 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "8759 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "8760 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "8761 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "8762 loss: tensor(0.8746) acc: 0.6666666666666666\n",
      "8763 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "8764 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "8765 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "8766 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "8767 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "8768 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "8769 loss: tensor(0.8747) acc: 0.6666666666666666\n",
      "8770 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "8771 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "8772 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "8773 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "8774 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "8775 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "8776 loss: tensor(0.8748) acc: 0.6666666666666666\n",
      "8777 loss: tensor(0.8749) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8778 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "8779 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "8780 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "8781 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "8782 loss: tensor(0.8749) acc: 0.6666666666666666\n",
      "8783 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "8784 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "8785 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "8786 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "8787 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "8788 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "8789 loss: tensor(0.8750) acc: 0.6666666666666666\n",
      "8790 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "8791 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "8792 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "8793 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "8794 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "8795 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "8796 loss: tensor(0.8751) acc: 0.6666666666666666\n",
      "8797 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "8798 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "8799 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "8800 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "8801 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "8802 loss: tensor(0.8752) acc: 0.6666666666666666\n",
      "8803 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "8804 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "8805 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "8806 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "8807 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "8808 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "8809 loss: tensor(0.8753) acc: 0.6666666666666666\n",
      "8810 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "8811 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "8812 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "8813 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "8814 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "8815 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "8816 loss: tensor(0.8754) acc: 0.6666666666666666\n",
      "8817 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "8818 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "8819 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "8820 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "8821 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "8822 loss: tensor(0.8755) acc: 0.6666666666666666\n",
      "8823 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "8824 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "8825 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "8826 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "8827 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "8828 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "8829 loss: tensor(0.8756) acc: 0.6666666666666666\n",
      "8830 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "8831 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "8832 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "8833 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "8834 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "8835 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "8836 loss: tensor(0.8757) acc: 0.6666666666666666\n",
      "8837 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "8838 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "8839 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "8840 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "8841 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "8842 loss: tensor(0.8758) acc: 0.6666666666666666\n",
      "8843 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "8844 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "8845 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "8846 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "8847 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "8848 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "8849 loss: tensor(0.8759) acc: 0.6666666666666666\n",
      "8850 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "8851 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "8852 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "8853 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "8854 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "8855 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "8856 loss: tensor(0.8760) acc: 0.6666666666666666\n",
      "8857 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "8858 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "8859 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "8860 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "8861 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "8862 loss: tensor(0.8761) acc: 0.6666666666666666\n",
      "8863 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "8864 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "8865 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "8866 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "8867 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "8868 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "8869 loss: tensor(0.8762) acc: 0.6666666666666666\n",
      "8870 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "8871 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "8872 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "8873 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "8874 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "8875 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "8876 loss: tensor(0.8763) acc: 0.6666666666666666\n",
      "8877 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "8878 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "8879 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "8880 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "8881 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "8882 loss: tensor(0.8764) acc: 0.6666666666666666\n",
      "8883 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "8884 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "8885 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "8886 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "8887 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "8888 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "8889 loss: tensor(0.8765) acc: 0.6666666666666666\n",
      "8890 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "8891 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "8892 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "8893 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "8894 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "8895 loss: tensor(0.8766) acc: 0.6666666666666666\n",
      "8896 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "8897 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "8898 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "8899 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "8900 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "8901 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "8902 loss: tensor(0.8767) acc: 0.6666666666666666\n",
      "8903 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "8904 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "8905 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "8906 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "8907 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "8908 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "8909 loss: tensor(0.8768) acc: 0.6666666666666666\n",
      "8910 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "8911 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "8912 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "8913 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "8914 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "8915 loss: tensor(0.8769) acc: 0.6666666666666666\n",
      "8916 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "8917 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "8918 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "8919 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "8920 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "8921 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "8922 loss: tensor(0.8770) acc: 0.6666666666666666\n",
      "8923 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "8924 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "8925 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "8926 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "8927 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "8928 loss: tensor(0.8771) acc: 0.6666666666666666\n",
      "8929 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "8930 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "8931 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "8932 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "8933 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "8934 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "8935 loss: tensor(0.8772) acc: 0.6666666666666666\n",
      "8936 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "8937 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "8938 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "8939 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "8940 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "8941 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "8942 loss: tensor(0.8773) acc: 0.6666666666666666\n",
      "8943 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "8944 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "8945 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "8946 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "8947 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "8948 loss: tensor(0.8774) acc: 0.6666666666666666\n",
      "8949 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "8950 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "8951 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "8952 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "8953 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "8954 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "8955 loss: tensor(0.8775) acc: 0.6666666666666666\n",
      "8956 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "8957 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "8958 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "8959 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "8960 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "8961 loss: tensor(0.8776) acc: 0.6666666666666666\n",
      "8962 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "8963 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "8964 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "8965 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "8966 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "8967 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "8968 loss: tensor(0.8777) acc: 0.6666666666666666\n",
      "8969 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "8970 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "8971 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "8972 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "8973 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "8974 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "8975 loss: tensor(0.8778) acc: 0.6666666666666666\n",
      "8976 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "8977 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "8978 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "8979 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "8980 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "8981 loss: tensor(0.8779) acc: 0.6666666666666666\n",
      "8982 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "8983 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "8984 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "8985 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "8986 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "8987 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "8988 loss: tensor(0.8780) acc: 0.6666666666666666\n",
      "8989 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "8990 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "8991 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "8992 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "8993 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "8994 loss: tensor(0.8781) acc: 0.6666666666666666\n",
      "8995 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "8996 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "8997 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "8998 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "8999 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "9000 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "9001 loss: tensor(0.8782) acc: 0.6666666666666666\n",
      "9002 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "9003 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "9004 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "9005 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "9006 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "9007 loss: tensor(0.8783) acc: 0.6666666666666666\n",
      "9008 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "9009 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "9010 loss: tensor(0.8784) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9011 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "9012 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "9013 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "9014 loss: tensor(0.8784) acc: 0.6666666666666666\n",
      "9015 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "9016 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "9017 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "9018 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "9019 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "9020 loss: tensor(0.8785) acc: 0.6666666666666666\n",
      "9021 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "9022 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "9023 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "9024 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "9025 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "9026 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "9027 loss: tensor(0.8786) acc: 0.6666666666666666\n",
      "9028 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "9029 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "9030 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "9031 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "9032 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "9033 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "9034 loss: tensor(0.8787) acc: 0.6666666666666666\n",
      "9035 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "9036 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "9037 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "9038 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "9039 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "9040 loss: tensor(0.8788) acc: 0.6666666666666666\n",
      "9041 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "9042 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "9043 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "9044 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "9045 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "9046 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "9047 loss: tensor(0.8789) acc: 0.6666666666666666\n",
      "9048 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "9049 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "9050 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "9051 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "9052 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "9053 loss: tensor(0.8790) acc: 0.6666666666666666\n",
      "9054 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "9055 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "9056 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "9057 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "9058 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "9059 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "9060 loss: tensor(0.8791) acc: 0.6666666666666666\n",
      "9061 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "9062 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "9063 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "9064 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "9065 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "9066 loss: tensor(0.8792) acc: 0.6666666666666666\n",
      "9067 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "9068 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "9069 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "9070 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "9071 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "9072 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "9073 loss: tensor(0.8793) acc: 0.6666666666666666\n",
      "9074 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "9075 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "9076 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "9077 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "9078 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "9079 loss: tensor(0.8794) acc: 0.6666666666666666\n",
      "9080 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "9081 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "9082 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "9083 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "9084 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "9085 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "9086 loss: tensor(0.8795) acc: 0.6666666666666666\n",
      "9087 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "9088 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "9089 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "9090 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "9091 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "9092 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "9093 loss: tensor(0.8796) acc: 0.6666666666666666\n",
      "9094 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "9095 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "9096 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "9097 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "9098 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "9099 loss: tensor(0.8797) acc: 0.6666666666666666\n",
      "9100 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "9101 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "9102 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "9103 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "9104 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "9105 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "9106 loss: tensor(0.8798) acc: 0.6666666666666666\n",
      "9107 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "9108 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "9109 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "9110 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "9111 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "9112 loss: tensor(0.8799) acc: 0.6666666666666666\n",
      "9113 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "9114 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "9115 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "9116 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "9117 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "9118 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "9119 loss: tensor(0.8800) acc: 0.6666666666666666\n",
      "9120 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "9121 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "9122 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "9123 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "9124 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "9125 loss: tensor(0.8801) acc: 0.6666666666666666\n",
      "9126 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "9127 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "9128 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "9129 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "9130 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "9131 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "9132 loss: tensor(0.8802) acc: 0.6666666666666666\n",
      "9133 loss: tensor(0.8803) acc: 0.6666666666666666\n",
      "9134 loss: tensor(0.8803) acc: 0.6666666666666666\n",
      "9135 loss: tensor(0.8803) acc: 0.6666666666666666\n",
      "9136 loss: tensor(0.8803) acc: 0.6666666666666666\n",
      "9137 loss: tensor(0.8803) acc: 0.6666666666666666\n",
      "9138 loss: tensor(0.8803) acc: 0.6666666666666666\n",
      "9139 loss: tensor(0.8803) acc: 0.6666666666666666\n",
      "9140 loss: tensor(0.8804) acc: 0.6666666666666666\n",
      "9141 loss: tensor(0.8804) acc: 0.6666666666666666\n",
      "9142 loss: tensor(0.8804) acc: 0.6666666666666666\n",
      "9143 loss: tensor(0.8804) acc: 0.6666666666666666\n",
      "9144 loss: tensor(0.8804) acc: 0.6666666666666666\n",
      "9145 loss: tensor(0.8804) acc: 0.6666666666666666\n",
      "9146 loss: tensor(0.8805) acc: 0.6666666666666666\n",
      "9147 loss: tensor(0.8805) acc: 0.6666666666666666\n",
      "9148 loss: tensor(0.8805) acc: 0.6666666666666666\n",
      "9149 loss: tensor(0.8805) acc: 0.6666666666666666\n",
      "9150 loss: tensor(0.8805) acc: 0.6666666666666666\n",
      "9151 loss: tensor(0.8805) acc: 0.6666666666666666\n",
      "9152 loss: tensor(0.8805) acc: 0.6666666666666666\n",
      "9153 loss: tensor(0.8806) acc: 0.6666666666666666\n",
      "9154 loss: tensor(0.8806) acc: 0.6666666666666666\n",
      "9155 loss: tensor(0.8806) acc: 0.6666666666666666\n",
      "9156 loss: tensor(0.8806) acc: 0.6666666666666666\n",
      "9157 loss: tensor(0.8806) acc: 0.6666666666666666\n",
      "9158 loss: tensor(0.8806) acc: 0.6666666666666666\n",
      "9159 loss: tensor(0.8807) acc: 0.6666666666666666\n",
      "9160 loss: tensor(0.8807) acc: 0.6666666666666666\n",
      "9161 loss: tensor(0.8807) acc: 0.6666666666666666\n",
      "9162 loss: tensor(0.8807) acc: 0.6666666666666666\n",
      "9163 loss: tensor(0.8807) acc: 0.6666666666666666\n",
      "9164 loss: tensor(0.8807) acc: 0.6666666666666666\n",
      "9165 loss: tensor(0.8807) acc: 0.6666666666666666\n",
      "9166 loss: tensor(0.8808) acc: 0.6666666666666666\n",
      "9167 loss: tensor(0.8808) acc: 0.6666666666666666\n",
      "9168 loss: tensor(0.8808) acc: 0.6666666666666666\n",
      "9169 loss: tensor(0.8808) acc: 0.6666666666666666\n",
      "9170 loss: tensor(0.8808) acc: 0.6666666666666666\n",
      "9171 loss: tensor(0.8808) acc: 0.6666666666666666\n",
      "9172 loss: tensor(0.8808) acc: 0.6666666666666666\n",
      "9173 loss: tensor(0.8809) acc: 0.6666666666666666\n",
      "9174 loss: tensor(0.8809) acc: 0.6666666666666666\n",
      "9175 loss: tensor(0.8809) acc: 0.6666666666666666\n",
      "9176 loss: tensor(0.8809) acc: 0.6666666666666666\n",
      "9177 loss: tensor(0.8809) acc: 0.6666666666666666\n",
      "9178 loss: tensor(0.8809) acc: 0.6666666666666666\n",
      "9179 loss: tensor(0.8810) acc: 0.6666666666666666\n",
      "9180 loss: tensor(0.8810) acc: 0.6666666666666666\n",
      "9181 loss: tensor(0.8810) acc: 0.6666666666666666\n",
      "9182 loss: tensor(0.8810) acc: 0.6666666666666666\n",
      "9183 loss: tensor(0.8810) acc: 0.6666666666666666\n",
      "9184 loss: tensor(0.8810) acc: 0.6666666666666666\n",
      "9185 loss: tensor(0.8810) acc: 0.6666666666666666\n",
      "9186 loss: tensor(0.8811) acc: 0.6666666666666666\n",
      "9187 loss: tensor(0.8811) acc: 0.6666666666666666\n",
      "9188 loss: tensor(0.8811) acc: 0.6666666666666666\n",
      "9189 loss: tensor(0.8811) acc: 0.6666666666666666\n",
      "9190 loss: tensor(0.8811) acc: 0.6666666666666666\n",
      "9191 loss: tensor(0.8811) acc: 0.6666666666666666\n",
      "9192 loss: tensor(0.8811) acc: 0.6666666666666666\n",
      "9193 loss: tensor(0.8812) acc: 0.6666666666666666\n",
      "9194 loss: tensor(0.8812) acc: 0.6666666666666666\n",
      "9195 loss: tensor(0.8812) acc: 0.6666666666666666\n",
      "9196 loss: tensor(0.8812) acc: 0.6666666666666666\n",
      "9197 loss: tensor(0.8812) acc: 0.6666666666666666\n",
      "9198 loss: tensor(0.8812) acc: 0.6666666666666666\n",
      "9199 loss: tensor(0.8813) acc: 0.6666666666666666\n",
      "9200 loss: tensor(0.8813) acc: 0.6666666666666666\n",
      "9201 loss: tensor(0.8813) acc: 0.6666666666666666\n",
      "9202 loss: tensor(0.8813) acc: 0.6666666666666666\n",
      "9203 loss: tensor(0.8813) acc: 0.6666666666666666\n",
      "9204 loss: tensor(0.8813) acc: 0.6666666666666666\n",
      "9205 loss: tensor(0.8813) acc: 0.6666666666666666\n",
      "9206 loss: tensor(0.8814) acc: 0.6666666666666666\n",
      "9207 loss: tensor(0.8814) acc: 0.6666666666666666\n",
      "9208 loss: tensor(0.8814) acc: 0.6666666666666666\n",
      "9209 loss: tensor(0.8814) acc: 0.6666666666666666\n",
      "9210 loss: tensor(0.8814) acc: 0.6666666666666666\n",
      "9211 loss: tensor(0.8814) acc: 0.6666666666666666\n",
      "9212 loss: tensor(0.8815) acc: 0.6666666666666666\n",
      "9213 loss: tensor(0.8815) acc: 0.6666666666666666\n",
      "9214 loss: tensor(0.8815) acc: 0.6666666666666666\n",
      "9215 loss: tensor(0.8815) acc: 0.6666666666666666\n",
      "9216 loss: tensor(0.8815) acc: 0.6666666666666666\n",
      "9217 loss: tensor(0.8815) acc: 0.6666666666666666\n",
      "9218 loss: tensor(0.8815) acc: 0.6666666666666666\n",
      "9219 loss: tensor(0.8816) acc: 0.6666666666666666\n",
      "9220 loss: tensor(0.8816) acc: 0.6666666666666666\n",
      "9221 loss: tensor(0.8816) acc: 0.6666666666666666\n",
      "9222 loss: tensor(0.8816) acc: 0.6666666666666666\n",
      "9223 loss: tensor(0.8816) acc: 0.6666666666666666\n",
      "9224 loss: tensor(0.8816) acc: 0.6666666666666666\n",
      "9225 loss: tensor(0.8816) acc: 0.6666666666666666\n",
      "9226 loss: tensor(0.8817) acc: 0.6666666666666666\n",
      "9227 loss: tensor(0.8817) acc: 0.6666666666666666\n",
      "9228 loss: tensor(0.8817) acc: 0.6666666666666666\n",
      "9229 loss: tensor(0.8817) acc: 0.6666666666666666\n",
      "9230 loss: tensor(0.8817) acc: 0.6666666666666666\n",
      "9231 loss: tensor(0.8817) acc: 0.6666666666666666\n",
      "9232 loss: tensor(0.8818) acc: 0.6666666666666666\n",
      "9233 loss: tensor(0.8818) acc: 0.6666666666666666\n",
      "9234 loss: tensor(0.8818) acc: 0.6666666666666666\n",
      "9235 loss: tensor(0.8818) acc: 0.6666666666666666\n",
      "9236 loss: tensor(0.8818) acc: 0.6666666666666666\n",
      "9237 loss: tensor(0.8818) acc: 0.6666666666666666\n",
      "9238 loss: tensor(0.8818) acc: 0.6666666666666666\n",
      "9239 loss: tensor(0.8819) acc: 0.6666666666666666\n",
      "9240 loss: tensor(0.8819) acc: 0.6666666666666666\n",
      "9241 loss: tensor(0.8819) acc: 0.6666666666666666\n",
      "9242 loss: tensor(0.8819) acc: 0.6666666666666666\n",
      "9243 loss: tensor(0.8819) acc: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9244 loss: tensor(0.8819) acc: 0.6666666666666666\n",
      "9245 loss: tensor(0.8819) acc: 0.6666666666666666\n",
      "9246 loss: tensor(0.8820) acc: 0.6666666666666666\n",
      "9247 loss: tensor(0.8820) acc: 0.6666666666666666\n",
      "9248 loss: tensor(0.8820) acc: 0.6666666666666666\n",
      "9249 loss: tensor(0.8820) acc: 0.6666666666666666\n",
      "9250 loss: tensor(0.8820) acc: 0.6666666666666666\n",
      "9251 loss: tensor(0.8820) acc: 0.6666666666666666\n",
      "9252 loss: tensor(0.8820) acc: 0.6666666666666666\n",
      "9253 loss: tensor(0.8821) acc: 0.6666666666666666\n",
      "9254 loss: tensor(0.8821) acc: 0.6666666666666666\n",
      "9255 loss: tensor(0.8821) acc: 0.6666666666666666\n",
      "9256 loss: tensor(0.8821) acc: 0.6666666666666666\n",
      "9257 loss: tensor(0.8821) acc: 0.6666666666666666\n",
      "9258 loss: tensor(0.8821) acc: 0.6666666666666666\n",
      "9259 loss: tensor(0.8822) acc: 0.6666666666666666\n",
      "9260 loss: tensor(0.8822) acc: 0.6666666666666666\n",
      "9261 loss: tensor(0.8822) acc: 0.6666666666666666\n",
      "9262 loss: tensor(0.8822) acc: 0.6666666666666666\n",
      "9263 loss: tensor(0.8822) acc: 0.6666666666666666\n",
      "9264 loss: tensor(0.8822) acc: 0.6666666666666666\n",
      "9265 loss: tensor(0.8822) acc: 0.6666666666666666\n",
      "9266 loss: tensor(0.8823) acc: 0.6666666666666666\n",
      "9267 loss: tensor(0.8823) acc: 0.6666666666666666\n",
      "9268 loss: tensor(0.8823) acc: 0.6666666666666666\n",
      "9269 loss: tensor(0.8823) acc: 0.6666666666666666\n",
      "9270 loss: tensor(0.8823) acc: 0.6666666666666666\n",
      "9271 loss: tensor(0.8823) acc: 0.6666666666666666\n",
      "9272 loss: tensor(0.8823) acc: 0.6666666666666666\n",
      "9273 loss: tensor(0.8824) acc: 0.6666666666666666\n",
      "9274 loss: tensor(0.8824) acc: 0.6666666666666666\n",
      "9275 loss: tensor(0.8824) acc: 0.6666666666666666\n",
      "9276 loss: tensor(0.8824) acc: 0.6666666666666666\n",
      "9277 loss: tensor(0.8824) acc: 0.6666666666666666\n",
      "9278 loss: tensor(0.8824) acc: 0.6666666666666666\n",
      "9279 loss: tensor(0.8825) acc: 0.6666666666666666\n",
      "9280 loss: tensor(0.8825) acc: 0.6666666666666666\n",
      "9281 loss: tensor(0.8825) acc: 0.6666666666666666\n",
      "9282 loss: tensor(0.8825) acc: 0.6666666666666666\n",
      "9283 loss: tensor(0.8825) acc: 0.6666666666666666\n",
      "9284 loss: tensor(0.8825) acc: 0.6666666666666666\n",
      "9285 loss: tensor(0.8825) acc: 0.6666666666666666\n",
      "9286 loss: tensor(0.8826) acc: 0.6666666666666666\n",
      "9287 loss: tensor(0.8826) acc: 0.6666666666666666\n",
      "9288 loss: tensor(0.8826) acc: 0.6666666666666666\n",
      "9289 loss: tensor(0.8826) acc: 0.6666666666666666\n",
      "9290 loss: tensor(0.8826) acc: 0.6666666666666666\n",
      "9291 loss: tensor(0.8826) acc: 0.6666666666666666\n",
      "9292 loss: tensor(0.8826) acc: 0.6666666666666666\n",
      "9293 loss: tensor(0.8827) acc: 0.6666666666666666\n",
      "9294 loss: tensor(0.8827) acc: 0.6666666666666666\n",
      "9295 loss: tensor(0.8827) acc: 0.6666666666666666\n",
      "9296 loss: tensor(0.8827) acc: 0.6666666666666666\n",
      "9297 loss: tensor(0.8827) acc: 0.6666666666666666\n",
      "9298 loss: tensor(0.8827) acc: 0.6666666666666666\n",
      "9299 loss: tensor(0.8827) acc: 0.6666666666666666\n",
      "9300 loss: tensor(0.8828) acc: 0.6666666666666666\n",
      "9301 loss: tensor(0.8828) acc: 0.6666666666666666\n",
      "9302 loss: tensor(0.8828) acc: 0.6666666666666666\n",
      "9303 loss: tensor(0.8828) acc: 0.6666666666666666\n",
      "9304 loss: tensor(0.8828) acc: 0.6666666666666666\n",
      "9305 loss: tensor(0.8828) acc: 0.6666666666666666\n",
      "9306 loss: tensor(0.8828) acc: 0.6666666666666666\n",
      "9307 loss: tensor(0.8829) acc: 0.6666666666666666\n",
      "9308 loss: tensor(0.8829) acc: 0.6666666666666666\n",
      "9309 loss: tensor(0.8829) acc: 0.6666666666666666\n",
      "9310 loss: tensor(0.8829) acc: 0.6666666666666666\n",
      "9311 loss: tensor(0.8829) acc: 0.6666666666666666\n",
      "9312 loss: tensor(0.8829) acc: 0.6666666666666666\n",
      "9313 loss: tensor(0.8830) acc: 0.6666666666666666\n",
      "9314 loss: tensor(0.8830) acc: 0.6666666666666666\n",
      "9315 loss: tensor(0.8830) acc: 0.6666666666666666\n",
      "9316 loss: tensor(0.8830) acc: 0.6666666666666666\n",
      "9317 loss: tensor(0.8830) acc: 0.6666666666666666\n",
      "9318 loss: tensor(0.8830) acc: 0.6666666666666666\n",
      "9319 loss: tensor(0.8830) acc: 0.6666666666666666\n",
      "9320 loss: tensor(0.8831) acc: 0.6666666666666666\n",
      "9321 loss: tensor(0.8831) acc: 0.6666666666666666\n",
      "9322 loss: tensor(0.8831) acc: 0.6666666666666666\n",
      "9323 loss: tensor(0.8831) acc: 0.6666666666666666\n",
      "9324 loss: tensor(0.8831) acc: 0.6666666666666666\n",
      "9325 loss: tensor(0.8831) acc: 0.6666666666666666\n",
      "9326 loss: tensor(0.8831) acc: 0.6666666666666666\n",
      "9327 loss: tensor(0.8832) acc: 0.6666666666666666\n",
      "9328 loss: tensor(0.8832) acc: 0.6666666666666666\n",
      "9329 loss: tensor(0.8832) acc: 0.6666666666666666\n",
      "9330 loss: tensor(0.8832) acc: 0.6666666666666666\n",
      "9331 loss: tensor(0.8832) acc: 0.6666666666666666\n",
      "9332 loss: tensor(0.8832) acc: 0.6666666666666666\n",
      "9333 loss: tensor(0.8832) acc: 0.6666666666666666\n",
      "9334 loss: tensor(0.8833) acc: 0.6666666666666666\n",
      "9335 loss: tensor(0.8833) acc: 0.6666666666666666\n",
      "9336 loss: tensor(0.8833) acc: 0.6666666666666666\n",
      "9337 loss: tensor(0.8833) acc: 0.6666666666666666\n",
      "9338 loss: tensor(0.8833) acc: 0.6666666666666666\n",
      "9339 loss: tensor(0.8833) acc: 0.6666666666666666\n",
      "9340 loss: tensor(0.8833) acc: 0.6666666666666666\n",
      "9341 loss: tensor(0.8834) acc: 0.6666666666666666\n",
      "9342 loss: tensor(0.8834) acc: 0.6666666666666666\n",
      "9343 loss: tensor(0.8834) acc: 0.6666666666666666\n",
      "9344 loss: tensor(0.8834) acc: 0.6666666666666666\n",
      "9345 loss: tensor(0.8834) acc: 0.6666666666666666\n",
      "9346 loss: tensor(0.8834) acc: 0.6666666666666666\n",
      "9347 loss: tensor(0.8834) acc: 0.6666666666666666\n",
      "9348 loss: tensor(0.8835) acc: 0.6666666666666666\n",
      "9349 loss: tensor(0.8835) acc: 0.6666666666666666\n",
      "9350 loss: tensor(0.8835) acc: 0.6666666666666666\n",
      "9351 loss: tensor(0.8835) acc: 0.6666666666666666\n",
      "9352 loss: tensor(0.8835) acc: 0.66\n",
      "9353 loss: tensor(0.8835) acc: 0.66\n",
      "9354 loss: tensor(0.8835) acc: 0.66\n",
      "9355 loss: tensor(0.8836) acc: 0.66\n",
      "9356 loss: tensor(0.8836) acc: 0.66\n",
      "9357 loss: tensor(0.8836) acc: 0.66\n",
      "9358 loss: tensor(0.8836) acc: 0.66\n",
      "9359 loss: tensor(0.8836) acc: 0.66\n",
      "9360 loss: tensor(0.8836) acc: 0.66\n",
      "9361 loss: tensor(0.8836) acc: 0.66\n",
      "9362 loss: tensor(0.8837) acc: 0.66\n",
      "9363 loss: tensor(0.8837) acc: 0.66\n",
      "9364 loss: tensor(0.8837) acc: 0.66\n",
      "9365 loss: tensor(0.8837) acc: 0.66\n",
      "9366 loss: tensor(0.8837) acc: 0.66\n",
      "9367 loss: tensor(0.8837) acc: 0.66\n",
      "9368 loss: tensor(0.8838) acc: 0.66\n",
      "9369 loss: tensor(0.8838) acc: 0.66\n",
      "9370 loss: tensor(0.8838) acc: 0.66\n",
      "9371 loss: tensor(0.8838) acc: 0.66\n",
      "9372 loss: tensor(0.8838) acc: 0.66\n",
      "9373 loss: tensor(0.8838) acc: 0.66\n",
      "9374 loss: tensor(0.8838) acc: 0.66\n",
      "9375 loss: tensor(0.8839) acc: 0.66\n",
      "9376 loss: tensor(0.8839) acc: 0.66\n",
      "9377 loss: tensor(0.8839) acc: 0.66\n",
      "9378 loss: tensor(0.8839) acc: 0.66\n",
      "9379 loss: tensor(0.8839) acc: 0.66\n",
      "9380 loss: tensor(0.8839) acc: 0.66\n",
      "9381 loss: tensor(0.8839) acc: 0.66\n",
      "9382 loss: tensor(0.8840) acc: 0.66\n",
      "9383 loss: tensor(0.8840) acc: 0.66\n",
      "9384 loss: tensor(0.8840) acc: 0.66\n",
      "9385 loss: tensor(0.8840) acc: 0.66\n",
      "9386 loss: tensor(0.8840) acc: 0.66\n",
      "9387 loss: tensor(0.8840) acc: 0.66\n",
      "9388 loss: tensor(0.8840) acc: 0.66\n",
      "9389 loss: tensor(0.8841) acc: 0.66\n",
      "9390 loss: tensor(0.8841) acc: 0.66\n",
      "9391 loss: tensor(0.8841) acc: 0.66\n",
      "9392 loss: tensor(0.8841) acc: 0.66\n",
      "9393 loss: tensor(0.8841) acc: 0.66\n",
      "9394 loss: tensor(0.8841) acc: 0.66\n",
      "9395 loss: tensor(0.8841) acc: 0.66\n",
      "9396 loss: tensor(0.8842) acc: 0.66\n",
      "9397 loss: tensor(0.8842) acc: 0.66\n",
      "9398 loss: tensor(0.8842) acc: 0.66\n",
      "9399 loss: tensor(0.8842) acc: 0.66\n",
      "9400 loss: tensor(0.8842) acc: 0.66\n",
      "9401 loss: tensor(0.8842) acc: 0.66\n",
      "9402 loss: tensor(0.8842) acc: 0.66\n",
      "9403 loss: tensor(0.8843) acc: 0.66\n",
      "9404 loss: tensor(0.8843) acc: 0.66\n",
      "9405 loss: tensor(0.8843) acc: 0.66\n",
      "9406 loss: tensor(0.8843) acc: 0.66\n",
      "9407 loss: tensor(0.8843) acc: 0.66\n",
      "9408 loss: tensor(0.8843) acc: 0.66\n",
      "9409 loss: tensor(0.8843) acc: 0.66\n",
      "9410 loss: tensor(0.8843) acc: 0.66\n",
      "9411 loss: tensor(0.8844) acc: 0.66\n",
      "9412 loss: tensor(0.8844) acc: 0.66\n",
      "9413 loss: tensor(0.8844) acc: 0.66\n",
      "9414 loss: tensor(0.8844) acc: 0.66\n",
      "9415 loss: tensor(0.8844) acc: 0.66\n",
      "9416 loss: tensor(0.8844) acc: 0.66\n",
      "9417 loss: tensor(0.8844) acc: 0.66\n",
      "9418 loss: tensor(0.8845) acc: 0.66\n",
      "9419 loss: tensor(0.8845) acc: 0.66\n",
      "9420 loss: tensor(0.8845) acc: 0.66\n",
      "9421 loss: tensor(0.8845) acc: 0.66\n",
      "9422 loss: tensor(0.8845) acc: 0.66\n",
      "9423 loss: tensor(0.8845) acc: 0.66\n",
      "9424 loss: tensor(0.8845) acc: 0.66\n",
      "9425 loss: tensor(0.8846) acc: 0.66\n",
      "9426 loss: tensor(0.8846) acc: 0.66\n",
      "9427 loss: tensor(0.8846) acc: 0.66\n",
      "9428 loss: tensor(0.8846) acc: 0.66\n",
      "9429 loss: tensor(0.8846) acc: 0.66\n",
      "9430 loss: tensor(0.8846) acc: 0.66\n",
      "9431 loss: tensor(0.8846) acc: 0.66\n",
      "9432 loss: tensor(0.8847) acc: 0.66\n",
      "9433 loss: tensor(0.8847) acc: 0.66\n",
      "9434 loss: tensor(0.8847) acc: 0.66\n",
      "9435 loss: tensor(0.8847) acc: 0.66\n",
      "9436 loss: tensor(0.8847) acc: 0.66\n",
      "9437 loss: tensor(0.8847) acc: 0.66\n",
      "9438 loss: tensor(0.8847) acc: 0.66\n",
      "9439 loss: tensor(0.8848) acc: 0.66\n",
      "9440 loss: tensor(0.8848) acc: 0.66\n",
      "9441 loss: tensor(0.8848) acc: 0.66\n",
      "9442 loss: tensor(0.8848) acc: 0.66\n",
      "9443 loss: tensor(0.8848) acc: 0.66\n",
      "9444 loss: tensor(0.8848) acc: 0.66\n",
      "9445 loss: tensor(0.8848) acc: 0.66\n",
      "9446 loss: tensor(0.8849) acc: 0.66\n",
      "9447 loss: tensor(0.8849) acc: 0.66\n",
      "9448 loss: tensor(0.8849) acc: 0.66\n",
      "9449 loss: tensor(0.8849) acc: 0.66\n",
      "9450 loss: tensor(0.8849) acc: 0.66\n",
      "9451 loss: tensor(0.8849) acc: 0.66\n",
      "9452 loss: tensor(0.8849) acc: 0.66\n",
      "9453 loss: tensor(0.8850) acc: 0.66\n",
      "9454 loss: tensor(0.8850) acc: 0.66\n",
      "9455 loss: tensor(0.8850) acc: 0.66\n",
      "9456 loss: tensor(0.8850) acc: 0.66\n",
      "9457 loss: tensor(0.8850) acc: 0.66\n",
      "9458 loss: tensor(0.8850) acc: 0.66\n",
      "9459 loss: tensor(0.8850) acc: 0.66\n",
      "9460 loss: tensor(0.8850) acc: 0.66\n",
      "9461 loss: tensor(0.8851) acc: 0.66\n",
      "9462 loss: tensor(0.8851) acc: 0.66\n",
      "9463 loss: tensor(0.8851) acc: 0.66\n",
      "9464 loss: tensor(0.8851) acc: 0.66\n",
      "9465 loss: tensor(0.8851) acc: 0.66\n",
      "9466 loss: tensor(0.8851) acc: 0.66\n",
      "9467 loss: tensor(0.8851) acc: 0.66\n",
      "9468 loss: tensor(0.8852) acc: 0.66\n",
      "9469 loss: tensor(0.8852) acc: 0.66\n",
      "9470 loss: tensor(0.8852) acc: 0.66\n",
      "9471 loss: tensor(0.8852) acc: 0.66\n",
      "9472 loss: tensor(0.8852) acc: 0.66\n",
      "9473 loss: tensor(0.8852) acc: 0.66\n",
      "9474 loss: tensor(0.8852) acc: 0.66\n",
      "9475 loss: tensor(0.8853) acc: 0.66\n",
      "9476 loss: tensor(0.8853) acc: 0.66\n",
      "9477 loss: tensor(0.8853) acc: 0.66\n",
      "9478 loss: tensor(0.8853) acc: 0.66\n",
      "9479 loss: tensor(0.8853) acc: 0.66\n",
      "9480 loss: tensor(0.8853) acc: 0.66\n",
      "9481 loss: tensor(0.8853) acc: 0.66\n",
      "9482 loss: tensor(0.8853) acc: 0.66\n",
      "9483 loss: tensor(0.8854) acc: 0.66\n",
      "9484 loss: tensor(0.8854) acc: 0.66\n",
      "9485 loss: tensor(0.8854) acc: 0.66\n",
      "9486 loss: tensor(0.8854) acc: 0.66\n",
      "9487 loss: tensor(0.8854) acc: 0.66\n",
      "9488 loss: tensor(0.8854) acc: 0.66\n",
      "9489 loss: tensor(0.8854) acc: 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9490 loss: tensor(0.8855) acc: 0.66\n",
      "9491 loss: tensor(0.8855) acc: 0.66\n",
      "9492 loss: tensor(0.8855) acc: 0.66\n",
      "9493 loss: tensor(0.8855) acc: 0.66\n",
      "9494 loss: tensor(0.8855) acc: 0.66\n",
      "9495 loss: tensor(0.8855) acc: 0.66\n",
      "9496 loss: tensor(0.8855) acc: 0.66\n",
      "9497 loss: tensor(0.8855) acc: 0.66\n",
      "9498 loss: tensor(0.8856) acc: 0.66\n",
      "9499 loss: tensor(0.8856) acc: 0.66\n",
      "9500 loss: tensor(0.8856) acc: 0.66\n",
      "9501 loss: tensor(0.8856) acc: 0.66\n",
      "9502 loss: tensor(0.8856) acc: 0.66\n",
      "9503 loss: tensor(0.8856) acc: 0.66\n",
      "9504 loss: tensor(0.8856) acc: 0.66\n",
      "9505 loss: tensor(0.8857) acc: 0.66\n",
      "9506 loss: tensor(0.8857) acc: 0.66\n",
      "9507 loss: tensor(0.8857) acc: 0.66\n",
      "9508 loss: tensor(0.8857) acc: 0.66\n",
      "9509 loss: tensor(0.8857) acc: 0.66\n",
      "9510 loss: tensor(0.8857) acc: 0.66\n",
      "9511 loss: tensor(0.8857) acc: 0.66\n",
      "9512 loss: tensor(0.8858) acc: 0.66\n",
      "9513 loss: tensor(0.8858) acc: 0.66\n",
      "9514 loss: tensor(0.8858) acc: 0.66\n",
      "9515 loss: tensor(0.8858) acc: 0.6533333333333333\n",
      "9516 loss: tensor(0.8858) acc: 0.6533333333333333\n",
      "9517 loss: tensor(0.8858) acc: 0.6533333333333333\n",
      "9518 loss: tensor(0.8858) acc: 0.6533333333333333\n",
      "9519 loss: tensor(0.8858) acc: 0.6533333333333333\n",
      "9520 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9521 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9522 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9523 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9524 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9525 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9526 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9527 loss: tensor(0.8859) acc: 0.6533333333333333\n",
      "9528 loss: tensor(0.8860) acc: 0.6533333333333333\n",
      "9529 loss: tensor(0.8860) acc: 0.6533333333333333\n",
      "9530 loss: tensor(0.8860) acc: 0.6533333333333333\n",
      "9531 loss: tensor(0.8860) acc: 0.6533333333333333\n",
      "9532 loss: tensor(0.8860) acc: 0.6533333333333333\n",
      "9533 loss: tensor(0.8860) acc: 0.6533333333333333\n",
      "9534 loss: tensor(0.8860) acc: 0.6533333333333333\n",
      "9535 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9536 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9537 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9538 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9539 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9540 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9541 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9542 loss: tensor(0.8861) acc: 0.6533333333333333\n",
      "9543 loss: tensor(0.8862) acc: 0.6533333333333333\n",
      "9544 loss: tensor(0.8862) acc: 0.6533333333333333\n",
      "9545 loss: tensor(0.8862) acc: 0.6533333333333333\n",
      "9546 loss: tensor(0.8862) acc: 0.6466666666666666\n",
      "9547 loss: tensor(0.8862) acc: 0.6466666666666666\n",
      "9548 loss: tensor(0.8862) acc: 0.6466666666666666\n",
      "9549 loss: tensor(0.8862) acc: 0.6466666666666666\n",
      "9550 loss: tensor(0.8862) acc: 0.6466666666666666\n",
      "9551 loss: tensor(0.8863) acc: 0.6466666666666666\n",
      "9552 loss: tensor(0.8863) acc: 0.6466666666666666\n",
      "9553 loss: tensor(0.8863) acc: 0.6466666666666666\n",
      "9554 loss: tensor(0.8863) acc: 0.6466666666666666\n",
      "9555 loss: tensor(0.8863) acc: 0.6466666666666666\n",
      "9556 loss: tensor(0.8863) acc: 0.6466666666666666\n",
      "9557 loss: tensor(0.8863) acc: 0.6466666666666666\n",
      "9558 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9559 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9560 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9561 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9562 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9563 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9564 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9565 loss: tensor(0.8864) acc: 0.6466666666666666\n",
      "9566 loss: tensor(0.8865) acc: 0.6466666666666666\n",
      "9567 loss: tensor(0.8865) acc: 0.6466666666666666\n",
      "9568 loss: tensor(0.8865) acc: 0.6466666666666666\n",
      "9569 loss: tensor(0.8865) acc: 0.6466666666666666\n",
      "9570 loss: tensor(0.8865) acc: 0.64\n",
      "9571 loss: tensor(0.8865) acc: 0.64\n",
      "9572 loss: tensor(0.8865) acc: 0.64\n",
      "9573 loss: tensor(0.8865) acc: 0.64\n",
      "9574 loss: tensor(0.8866) acc: 0.64\n",
      "9575 loss: tensor(0.8866) acc: 0.64\n",
      "9576 loss: tensor(0.8866) acc: 0.64\n",
      "9577 loss: tensor(0.8866) acc: 0.64\n",
      "9578 loss: tensor(0.8866) acc: 0.64\n",
      "9579 loss: tensor(0.8866) acc: 0.64\n",
      "9580 loss: tensor(0.8866) acc: 0.64\n",
      "9581 loss: tensor(0.8866) acc: 0.64\n",
      "9582 loss: tensor(0.8867) acc: 0.64\n",
      "9583 loss: tensor(0.8867) acc: 0.64\n",
      "9584 loss: tensor(0.8867) acc: 0.64\n",
      "9585 loss: tensor(0.8867) acc: 0.64\n",
      "9586 loss: tensor(0.8867) acc: 0.64\n",
      "9587 loss: tensor(0.8867) acc: 0.64\n",
      "9588 loss: tensor(0.8867) acc: 0.64\n",
      "9589 loss: tensor(0.8867) acc: 0.64\n",
      "9590 loss: tensor(0.8868) acc: 0.64\n",
      "9591 loss: tensor(0.8868) acc: 0.64\n",
      "9592 loss: tensor(0.8868) acc: 0.64\n",
      "9593 loss: tensor(0.8868) acc: 0.64\n",
      "9594 loss: tensor(0.8868) acc: 0.6333333333333333\n",
      "9595 loss: tensor(0.8868) acc: 0.6333333333333333\n",
      "9596 loss: tensor(0.8868) acc: 0.6333333333333333\n",
      "9597 loss: tensor(0.8868) acc: 0.6333333333333333\n",
      "9598 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9599 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9600 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9601 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9602 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9603 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9604 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9605 loss: tensor(0.8869) acc: 0.6333333333333333\n",
      "9606 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9607 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9608 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9609 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9610 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9611 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9612 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9613 loss: tensor(0.8870) acc: 0.6333333333333333\n",
      "9614 loss: tensor(0.8871) acc: 0.6333333333333333\n",
      "9615 loss: tensor(0.8871) acc: 0.6333333333333333\n",
      "9616 loss: tensor(0.8871) acc: 0.6333333333333333\n",
      "9617 loss: tensor(0.8871) acc: 0.6266666666666667\n",
      "9618 loss: tensor(0.8871) acc: 0.6266666666666667\n",
      "9619 loss: tensor(0.8871) acc: 0.6266666666666667\n",
      "9620 loss: tensor(0.8871) acc: 0.6266666666666667\n",
      "9621 loss: tensor(0.8871) acc: 0.6266666666666667\n",
      "9622 loss: tensor(0.8871) acc: 0.6266666666666667\n",
      "9623 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9624 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9625 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9626 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9627 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9628 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9629 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9630 loss: tensor(0.8872) acc: 0.6266666666666667\n",
      "9631 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9632 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9633 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9634 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9635 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9636 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9637 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9638 loss: tensor(0.8873) acc: 0.6266666666666667\n",
      "9639 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9640 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9641 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9642 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9643 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9644 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9645 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9646 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9647 loss: tensor(0.8874) acc: 0.6266666666666667\n",
      "9648 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9649 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9650 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9651 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9652 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9653 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9654 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9655 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9656 loss: tensor(0.8875) acc: 0.6266666666666667\n",
      "9657 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9658 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9659 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9660 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9661 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9662 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9663 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9664 loss: tensor(0.8876) acc: 0.6266666666666667\n",
      "9665 loss: tensor(0.8877) acc: 0.6266666666666667\n",
      "9666 loss: tensor(0.8877) acc: 0.6266666666666667\n",
      "9667 loss: tensor(0.8877) acc: 0.6266666666666667\n",
      "9668 loss: tensor(0.8877) acc: 0.6266666666666667\n",
      "9669 loss: tensor(0.8877) acc: 0.6266666666666667\n",
      "9670 loss: tensor(0.8877) acc: 0.6266666666666667\n",
      "9671 loss: tensor(0.8877) acc: 0.6266666666666667\n",
      "9672 loss: tensor(0.8877) acc: 0.62\n",
      "9673 loss: tensor(0.8877) acc: 0.62\n",
      "9674 loss: tensor(0.8878) acc: 0.62\n",
      "9675 loss: tensor(0.8878) acc: 0.62\n",
      "9676 loss: tensor(0.8878) acc: 0.62\n",
      "9677 loss: tensor(0.8878) acc: 0.62\n",
      "9678 loss: tensor(0.8878) acc: 0.62\n",
      "9679 loss: tensor(0.8878) acc: 0.62\n",
      "9680 loss: tensor(0.8878) acc: 0.62\n",
      "9681 loss: tensor(0.8878) acc: 0.62\n",
      "9682 loss: tensor(0.8878) acc: 0.62\n",
      "9683 loss: tensor(0.8879) acc: 0.62\n",
      "9684 loss: tensor(0.8879) acc: 0.62\n",
      "9685 loss: tensor(0.8879) acc: 0.62\n",
      "9686 loss: tensor(0.8879) acc: 0.62\n",
      "9687 loss: tensor(0.8879) acc: 0.62\n",
      "9688 loss: tensor(0.8879) acc: 0.62\n",
      "9689 loss: tensor(0.8879) acc: 0.62\n",
      "9690 loss: tensor(0.8879) acc: 0.62\n",
      "9691 loss: tensor(0.8879) acc: 0.62\n",
      "9692 loss: tensor(0.8880) acc: 0.62\n",
      "9693 loss: tensor(0.8880) acc: 0.62\n",
      "9694 loss: tensor(0.8880) acc: 0.62\n",
      "9695 loss: tensor(0.8880) acc: 0.62\n",
      "9696 loss: tensor(0.8880) acc: 0.62\n",
      "9697 loss: tensor(0.8880) acc: 0.62\n",
      "9698 loss: tensor(0.8880) acc: 0.62\n",
      "9699 loss: tensor(0.8880) acc: 0.62\n",
      "9700 loss: tensor(0.8880) acc: 0.62\n",
      "9701 loss: tensor(0.8881) acc: 0.62\n",
      "9702 loss: tensor(0.8881) acc: 0.62\n",
      "9703 loss: tensor(0.8881) acc: 0.62\n",
      "9704 loss: tensor(0.8881) acc: 0.62\n",
      "9705 loss: tensor(0.8881) acc: 0.62\n",
      "9706 loss: tensor(0.8881) acc: 0.62\n",
      "9707 loss: tensor(0.8881) acc: 0.62\n",
      "9708 loss: tensor(0.8881) acc: 0.62\n",
      "9709 loss: tensor(0.8881) acc: 0.62\n",
      "9710 loss: tensor(0.8882) acc: 0.62\n",
      "9711 loss: tensor(0.8882) acc: 0.62\n",
      "9712 loss: tensor(0.8882) acc: 0.62\n",
      "9713 loss: tensor(0.8882) acc: 0.62\n",
      "9714 loss: tensor(0.8882) acc: 0.62\n",
      "9715 loss: tensor(0.8882) acc: 0.62\n",
      "9716 loss: tensor(0.8882) acc: 0.62\n",
      "9717 loss: tensor(0.8882) acc: 0.62\n",
      "9718 loss: tensor(0.8882) acc: 0.62\n",
      "9719 loss: tensor(0.8882) acc: 0.62\n",
      "9720 loss: tensor(0.8883) acc: 0.62\n",
      "9721 loss: tensor(0.8883) acc: 0.62\n",
      "9722 loss: tensor(0.8883) acc: 0.62\n",
      "9723 loss: tensor(0.8883) acc: 0.62\n",
      "9724 loss: tensor(0.8883) acc: 0.62\n",
      "9725 loss: tensor(0.8883) acc: 0.62\n",
      "9726 loss: tensor(0.8883) acc: 0.62\n",
      "9727 loss: tensor(0.8883) acc: 0.62\n",
      "9728 loss: tensor(0.8883) acc: 0.62\n",
      "9729 loss: tensor(0.8884) acc: 0.62\n",
      "9730 loss: tensor(0.8884) acc: 0.62\n",
      "9731 loss: tensor(0.8884) acc: 0.62\n",
      "9732 loss: tensor(0.8884) acc: 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9733 loss: tensor(0.8884) acc: 0.62\n",
      "9734 loss: tensor(0.8884) acc: 0.62\n",
      "9735 loss: tensor(0.8884) acc: 0.62\n",
      "9736 loss: tensor(0.8884) acc: 0.62\n",
      "9737 loss: tensor(0.8884) acc: 0.62\n",
      "9738 loss: tensor(0.8884) acc: 0.62\n",
      "9739 loss: tensor(0.8885) acc: 0.62\n",
      "9740 loss: tensor(0.8885) acc: 0.62\n",
      "9741 loss: tensor(0.8885) acc: 0.62\n",
      "9742 loss: tensor(0.8885) acc: 0.62\n",
      "9743 loss: tensor(0.8885) acc: 0.62\n",
      "9744 loss: tensor(0.8885) acc: 0.62\n",
      "9745 loss: tensor(0.8885) acc: 0.6133333333333333\n",
      "9746 loss: tensor(0.8885) acc: 0.6133333333333333\n",
      "9747 loss: tensor(0.8885) acc: 0.6133333333333333\n",
      "9748 loss: tensor(0.8885) acc: 0.6133333333333333\n",
      "9749 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9750 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9751 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9752 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9753 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9754 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9755 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9756 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9757 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9758 loss: tensor(0.8886) acc: 0.6133333333333333\n",
      "9759 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9760 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9761 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9762 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9763 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9764 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9765 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9766 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9767 loss: tensor(0.8887) acc: 0.6133333333333333\n",
      "9768 loss: tensor(0.8887) acc: 0.6066666666666667\n",
      "9769 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9770 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9771 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9772 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9773 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9774 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9775 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9776 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9777 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9778 loss: tensor(0.8888) acc: 0.6066666666666667\n",
      "9779 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9780 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9781 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9782 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9783 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9784 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9785 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9786 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9787 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9788 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9789 loss: tensor(0.8889) acc: 0.6066666666666667\n",
      "9790 loss: tensor(0.8890) acc: 0.6066666666666667\n",
      "9791 loss: tensor(0.8890) acc: 0.6\n",
      "9792 loss: tensor(0.8890) acc: 0.6\n",
      "9793 loss: tensor(0.8890) acc: 0.6\n",
      "9794 loss: tensor(0.8890) acc: 0.6\n",
      "9795 loss: tensor(0.8890) acc: 0.6\n",
      "9796 loss: tensor(0.8890) acc: 0.6\n",
      "9797 loss: tensor(0.8890) acc: 0.6\n",
      "9798 loss: tensor(0.8890) acc: 0.6\n",
      "9799 loss: tensor(0.8890) acc: 0.6\n",
      "9800 loss: tensor(0.8890) acc: 0.6\n",
      "9801 loss: tensor(0.8891) acc: 0.6\n",
      "9802 loss: tensor(0.8891) acc: 0.6\n",
      "9803 loss: tensor(0.8891) acc: 0.6\n",
      "9804 loss: tensor(0.8891) acc: 0.6\n",
      "9805 loss: tensor(0.8891) acc: 0.6\n",
      "9806 loss: tensor(0.8891) acc: 0.6\n",
      "9807 loss: tensor(0.8891) acc: 0.6\n",
      "9808 loss: tensor(0.8891) acc: 0.6\n",
      "9809 loss: tensor(0.8891) acc: 0.6\n",
      "9810 loss: tensor(0.8891) acc: 0.6\n",
      "9811 loss: tensor(0.8891) acc: 0.6\n",
      "9812 loss: tensor(0.8892) acc: 0.6\n",
      "9813 loss: tensor(0.8892) acc: 0.6\n",
      "9814 loss: tensor(0.8892) acc: 0.6\n",
      "9815 loss: tensor(0.8892) acc: 0.6\n",
      "9816 loss: tensor(0.8892) acc: 0.6\n",
      "9817 loss: tensor(0.8892) acc: 0.6\n",
      "9818 loss: tensor(0.8892) acc: 0.6\n",
      "9819 loss: tensor(0.8892) acc: 0.5933333333333334\n",
      "9820 loss: tensor(0.8892) acc: 0.5933333333333334\n",
      "9821 loss: tensor(0.8892) acc: 0.5933333333333334\n",
      "9822 loss: tensor(0.8892) acc: 0.5933333333333334\n",
      "9823 loss: tensor(0.8893) acc: 0.5933333333333334\n",
      "9824 loss: tensor(0.8893) acc: 0.5933333333333334\n",
      "9825 loss: tensor(0.8893) acc: 0.5933333333333334\n",
      "9826 loss: tensor(0.8893) acc: 0.5933333333333334\n",
      "9827 loss: tensor(0.8893) acc: 0.5933333333333334\n",
      "9828 loss: tensor(0.8893) acc: 0.5933333333333334\n",
      "9829 loss: tensor(0.8893) acc: 0.5866666666666667\n",
      "9830 loss: tensor(0.8893) acc: 0.5866666666666667\n",
      "9831 loss: tensor(0.8893) acc: 0.5866666666666667\n",
      "9832 loss: tensor(0.8893) acc: 0.5866666666666667\n",
      "9833 loss: tensor(0.8893) acc: 0.5866666666666667\n",
      "9834 loss: tensor(0.8893) acc: 0.58\n",
      "9835 loss: tensor(0.8894) acc: 0.58\n",
      "9836 loss: tensor(0.8894) acc: 0.5733333333333334\n",
      "9837 loss: tensor(0.8894) acc: 0.5733333333333334\n",
      "9838 loss: tensor(0.8894) acc: 0.5733333333333334\n",
      "9839 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9840 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9841 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9842 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9843 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9844 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9845 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9846 loss: tensor(0.8894) acc: 0.5666666666666667\n",
      "9847 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9848 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9849 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9850 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9851 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9852 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9853 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9854 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9855 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9856 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9857 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9858 loss: tensor(0.8895) acc: 0.5666666666666667\n",
      "9859 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9860 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9861 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9862 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9863 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9864 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9865 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9866 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9867 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9868 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9869 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9870 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9871 loss: tensor(0.8896) acc: 0.5666666666666667\n",
      "9872 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9873 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9874 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9875 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9876 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9877 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9878 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9879 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9880 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9881 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9882 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9883 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9884 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9885 loss: tensor(0.8897) acc: 0.5666666666666667\n",
      "9886 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9887 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9888 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9889 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9890 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9891 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9892 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9893 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9894 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9895 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9896 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9897 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9898 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9899 loss: tensor(0.8898) acc: 0.5666666666666667\n",
      "9900 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9901 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9902 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9903 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9904 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9905 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9906 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9907 loss: tensor(0.8899) acc: 0.5666666666666667\n",
      "9908 loss: tensor(0.8899) acc: 0.5733333333333334\n",
      "9909 loss: tensor(0.8899) acc: 0.5733333333333334\n",
      "9910 loss: tensor(0.8899) acc: 0.5733333333333334\n",
      "9911 loss: tensor(0.8899) acc: 0.5733333333333334\n",
      "9912 loss: tensor(0.8899) acc: 0.5733333333333334\n",
      "9913 loss: tensor(0.8899) acc: 0.5733333333333334\n",
      "9914 loss: tensor(0.8899) acc: 0.5733333333333334\n",
      "9915 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9916 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9917 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9918 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9919 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9920 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9921 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9922 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9923 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9924 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9925 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9926 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9927 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9928 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9929 loss: tensor(0.8900) acc: 0.5733333333333334\n",
      "9930 loss: tensor(0.8901) acc: 0.5733333333333334\n",
      "9931 loss: tensor(0.8901) acc: 0.5733333333333334\n",
      "9932 loss: tensor(0.8901) acc: 0.5733333333333334\n",
      "9933 loss: tensor(0.8901) acc: 0.5733333333333334\n",
      "9934 loss: tensor(0.8901) acc: 0.5733333333333334\n",
      "9935 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9936 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9937 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9938 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9939 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9940 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9941 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9942 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9943 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9944 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9945 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9946 loss: tensor(0.8901) acc: 0.5666666666666667\n",
      "9947 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9948 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9949 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9950 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9951 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9952 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9953 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9954 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9955 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9956 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9957 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9958 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9959 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9960 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9961 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9962 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9963 loss: tensor(0.8902) acc: 0.5666666666666667\n",
      "9964 loss: tensor(0.8902) acc: 0.56\n",
      "9965 loss: tensor(0.8903) acc: 0.56\n",
      "9966 loss: tensor(0.8903) acc: 0.56\n",
      "9967 loss: tensor(0.8903) acc: 0.56\n",
      "9968 loss: tensor(0.8903) acc: 0.56\n",
      "9969 loss: tensor(0.8903) acc: 0.56\n",
      "9970 loss: tensor(0.8903) acc: 0.56\n",
      "9971 loss: tensor(0.8903) acc: 0.56\n",
      "9972 loss: tensor(0.8903) acc: 0.56\n",
      "9973 loss: tensor(0.8903) acc: 0.56\n",
      "9974 loss: tensor(0.8903) acc: 0.56\n",
      "9975 loss: tensor(0.8903) acc: 0.56\n",
      "9976 loss: tensor(0.8903) acc: 0.56\n",
      "9977 loss: tensor(0.8903) acc: 0.56\n",
      "9978 loss: tensor(0.8903) acc: 0.56\n",
      "9979 loss: tensor(0.8903) acc: 0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980 loss: tensor(0.8903) acc: 0.56\n",
      "9981 loss: tensor(0.8903) acc: 0.56\n",
      "9982 loss: tensor(0.8903) acc: 0.56\n",
      "9983 loss: tensor(0.8903) acc: 0.56\n",
      "9984 loss: tensor(0.8904) acc: 0.56\n",
      "9985 loss: tensor(0.8904) acc: 0.56\n",
      "9986 loss: tensor(0.8904) acc: 0.56\n",
      "9987 loss: tensor(0.8904) acc: 0.56\n",
      "9988 loss: tensor(0.8904) acc: 0.56\n",
      "9989 loss: tensor(0.8904) acc: 0.56\n",
      "9990 loss: tensor(0.8904) acc: 0.56\n",
      "9991 loss: tensor(0.8904) acc: 0.56\n",
      "9992 loss: tensor(0.8904) acc: 0.5533333333333333\n",
      "9993 loss: tensor(0.8904) acc: 0.5533333333333333\n",
      "9994 loss: tensor(0.8904) acc: 0.5533333333333333\n",
      "9995 loss: tensor(0.8904) acc: 0.5533333333333333\n",
      "9996 loss: tensor(0.8904) acc: 0.5533333333333333\n",
      "9997 loss: tensor(0.8904) acc: 0.5466666666666666\n",
      "9998 loss: tensor(0.8904) acc: 0.5466666666666666\n",
      "9999 loss: tensor(0.8904) acc: 0.5466666666666666\n",
      "10000 loss: tensor(0.8904) acc: 0.5466666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mlp.train(X, y, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('loss')\n",
    "plt.plot(mlp.hist['loss'])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('acc')\n",
    "plt.plot(mlp.hist['acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-learning",
   "language": "python",
   "name": "pytorch-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
